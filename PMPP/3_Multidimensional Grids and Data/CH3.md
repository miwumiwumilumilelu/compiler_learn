# CH3 Multidimensional Grids and Data (多维网格与数据)



### **3.1 Multidimensional Grid Organization (多维网格组织)**

**Q1: 在 CUDA 中，dim3 结构体的作用是什么？如果只初始化了部分维度，未初始化的维度默认值是多少？**

A:

- **作用:** `dim3` 是一个基于 `uint3` 的向量类型，专门用于配置 Grid（网格）和 Block（线程块）的维度（x, y, z）。
- **默认值:** 未被显式初始化的维度默认值为 **1**。例如，`dim3 block(32, 16)` 实际上等于 `(32, 16, 1)`。

**Q2: 为什么 CUDA 允许使用多维（2D 或 3D）的 Grid 和 Block？这只是为了语法糖吗？**

A:

不仅仅是语法糖。多维结构的主要目的是为了直观性和简化编程。

现实世界的数据通常是多维的（如 2D 图像、3D 空间体积）。使用与数据维度匹配的 Grid（例如用 2D Block 覆盖 2D 图像），可以让线程索引 (threadIdx.x, threadIdx.y) 直接对应数据的几何坐标，从而避免程序员手动进行复杂的下标换算。

**Q3: 在配置 dimBlock 时，必须遵守哪条极其重要的硬件限制？**

A:

1024 线程限制。

一个 Thread Block 内所有维度大小的乘积（$x \times y \times z$）绝对不能超过 1024。

- *合法示例:* `dim3(32, 32, 1)` -> $1024$ 线程。
- *非法示例:* `dim3(32, 32, 2)` -> $2048$ 线程（会导致 Kernel 启动失败）。

------

### **3.2 Mapping Threads to Multidimensional Data (线程与多维数据的映射)**

**Q4: 解释“行主序” (Row-Major Layout) 及其在 CUDA 中的索引计算公式。**

A:

- **定义:** 在 C/C++ 和 CUDA 中，多维数组在物理内存中是线性存储的。存储顺序是先存满第 0 行，再存第 1 行，以此类推。

- 公式: 假设我们要访问第 row 行、第 col 列的元素，其 1D 内存偏移量为：

  

  $$Offset = row \times Width + col$$

  

  (注意：千万不要混淆成列主序的 col * Height + row)。

**Q5: 为什么在处理图像的 Kernel 中，通常需要 if (col < width && row < height) 这样的边界检查？**

A:

这是为了处理 Grid 尺寸与图像尺寸不匹配 的问题。

Block 的大小通常是固定的（如 16x16）。当图像尺寸不是 Block 尺寸的整数倍时，边缘的 Block 会超出图像边界。这些超出的线程被称为 Ghost Threads。如果不加 if 检查，它们会读取或写入非法内存地址，导致程序崩溃或数据损坏。

**Q6: 如何确定 Grid 的维度 (gridDim) 以确保覆盖整个图像？（请给出公式）**

A:

使用 向上取整 (Ceiling) 策略。

假设图像宽度为 W，Block 宽度为 B，Grid 的宽度应为：



$$(W + B - 1) / B$$



或者利用整数除法特性写为：ceil((float)W / B)。这保证了即使不能整除，也有足够的 Block 覆盖剩余的像素。

------

### **3.3 Image Blur: A More Complex Kernel (图像模糊：更复杂的内核)**

**Q7: 图像模糊算法代表了哪种并行计算模式？它与简单的像素变换（如灰度化）有何本质区别？**

A:

- **模式:** 代表了 **Stencil (模板/邻域)** 模式。
- **区别:**
  - **Map (灰度化):** 1对1。一个线程只读一个输入像素，写一个输出像素，完全独立。
  - **Stencil (模糊):** 多对1。一个线程需要读取周围邻域（Patch）内的多个像素来计算一个输出像素。这引入了**数据依赖**和**复杂的边界处理**问题。

**Q8: 在模糊算法中，如何优雅地处理图像边缘像素（例如左上角像素，其左边和上边没有邻居）？**

A:

使用 动态有效性检查。

在遍历邻域 Patch 的循环内部，检查当前邻居坐标 (curRow, curCol) 是否在图像范围内：

- 如果**在范围内**：累加该像素值，并增加计数器 `pixels++`。

- 如果越界：直接跳过（视为不存在），既不累加数值也不增加计数器。

  最后计算平均值时，除以的是实际有效的邻居数量 (pixels)，而不是固定的 Patch 大小。

------

### **3.4 Matrix Multiplication (矩阵乘法)**

**Q9: 在基础的矩阵乘法 Kernel 中，采用了什么样的“线程-数据映射”策略？**

A:

One Thread per Output Element (一个线程负责一个输出元素)。

Grid 中的每个线程负责计算结果矩阵 $P$ 中的一个元素 $P_{row,col}$。该线程需要独立读取矩阵 $M$ 的第 row 行和矩阵 $N$ 的第 col 列，完成点积运算。

**Q10: 基础矩阵乘法 Kernel 最大的性能缺陷是什么？（面试高频）**

A:

全局内存带宽瓶颈 (Memory Bandwidth Bound)。

在这种实现中，数据没有被重用。

- 为了计算 $P$ 的一行，矩阵 $M$ 的对应行会被这一行所有的线程重复读取 $N$ 次。
- 对于 $N \times N$ 的矩阵，总的全局内存读取次数高达 $2N^3$。
- 这意味着大量的时间浪费在从慢速的 Global Memory 搬运重复数据上。

**Q11: 在矩阵乘法中，访问矩阵 M 和矩阵 N 的内存模式有何不同？哪个效率更低？**

A:

- **访问 M (行):** `M[row * Width + k]`。随着 `k` 增加，访问是连续的内存地址（Coalesced），效率较高。
- **访问 N (列):** `N[k * Width + col]`。随着 `k` 增加，每次访问的内存地址都要跳跃 `Width` 个单位（Strided Access）。这种大跨度的跳跃访问会严重降低内存带宽利用率，效率较低。

------

### **3.5 Exercises & Advanced Concepts (练习与进阶)**

**Q12: 如果将矩阵乘法改为“一个线程计算一行输出”(One Thread per Row)，性能会如何变化？为什么？**

A:

性能通常会大幅下降。

虽然每个线程的工作量变大了，但这导致了并行度（Parallelism）的剧烈降低。

例如对于 $1000 \times 1000$ 的矩阵：

- **原版:** 1,000,000 个线程并行（GPU 满载）。
- **行模式:** 只有 1,000 个线程并行。这不足以填满 GPU 的数千个核心，导致大部分硬件资源空闲。

**Q13: 给定一个 3D 张量（宽 W, 高 H, 深 D），按照行主序存储。请写出坐标 (x, y, z) 对应的 1D 索引公式。**

A:

假设维度顺序为 Depth(z) -> Height(y) -> Width(x)：



$$Index = z \times (H \times W) + y \times W + x$$