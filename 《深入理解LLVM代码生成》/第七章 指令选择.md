# 第七章 指令选择

**将高级语言映射成目标架构指令**的过程称为指令选择

映射可能一对一，也可能多对一



指令选择需要解决模式匹配和模式选择两个子问题

**模式匹配：**单指令匹配、树匹配、DAG匹配和图匹配

**模式选择：**以最短运行时间和最小内存开销为目标

处理方式：

1. **分开处理：**先匹配后选择，**可以取到最优**

2. **两阶段合并处理：(启发式算法) **一边匹配一边判断是否为当前最优，最终可以得到**一个相对好的匹配结果，处理时间较前一种更短**



## 7.1 指令选择的处理流程

1. 指令选择模块在后端实现，但它并不是后端第一个Pass，而在其之前还会进行LLVM IR的相关工作：
   1. **进一步降低LLVM IR 和后端IR的语义差异**，方便后续进行后端IR的变换
   2. **进行一些功能的处理**，如异常处理和`inrinsic`处理
2. 指令选择执行完成之后，**还会有`Finalize Isel`的过程来完成指令选择相关的一些事情**

综上所述，将指令选择分为3个阶段：**指令选择预处理阶段、指令选择阶段、指令选择后处理阶段**



* 指令选择预处理阶段相关Pass：
  * `PreISelIntrinsicLowering`：**对LLVM内置函数进行降级——即将一个高级、抽象的内置函数，转换为一个由更简单、更基础的IR指令组成的等价实现，或者直接转换成一个对标准库函数的调用**
    * 将两类`inrinsic`指令（LLVM内部定义的特殊指令），以及`llvm.load.relative` 和 `llvm.objc.*`分别转换为相应的LLVM IR指令
  * `ExpandLargeDivRem`：**由于硬件能力限制无法支持超过目标架构可用位数长度的除法或者取余操作，故将其展开，转换成可用位数范围内的除法或者取余替代指令。当前最小支持位数是32位**
  * `CodeGenPrepare`: **主要用于配置元数据和对LLVM IR进行窥孔优化**
  * `ExceptionHandling`: **用于生成异常处理代码，根据不同的异常约定生成相应的代码。如果不需要支持异常，则此Pass不需开启**
  * `IselPrepare`: **主要是两个栈安全相关的功能实现——安全栈和栈保护，用于防止栈溢出或栈被破坏带来的安全漏洞**
* 指令选择阶段：**将LLVM IR 翻译成MIR**
* 指令选择后处理阶段：
  * `Finalize Isel`：**指令选择之后紧跟的Pass，有些目标架构自定义的伪指令会在这个阶段展开成机器指令**



**LLVM后端支持多芯片指令集导致了多后端冗余问题**——即多种指令集之间会存在相似的指令，如果每个架构都分开独立地去翻译这些指令，就会产生很多冗余的代码

**因此相关指令选择算法采取引入新的中间表示（共享框架）来进行LLVM IR到MIR的过渡**（如DAG IR 和 GMIR）



## 7.2 SelectionDAGISel 算法分析

局部指令选择算法，**以函数中的基本块为粒度，不考虑跨基本块的指令处理，只针对基本块内的LLVM IR生成最优的MIR指令**

算法实现将指令分成两类处理：

1. 以基本块为粒度，对基本块内的指令（忽略ø函数）进行指令选择
2. 针对ø函数处理基本块之间的关系，在基本块完成指令选择之后，再为基本块之间重构汇聚关系（再次添加ø函数）



1.第一类处理

**SelectionDAGISel针对基本块进行指令选择流程：**

**LLVM IR先初始化（紧跟合并优化），后进行类型合法化（紧跟合并优化）、向量合法化、类型合法化（紧跟合并优化）、操作合法化（紧跟合并优化）的合法化操作，最后进行指令选择、指令调度和MIR发射得到最终MIR**

* 其中**合并优化**基本都是一些窥孔优化：**目的是清理上一环节可能产生的冗余DAG表达，用单个节点替换同功能的多个节点组合，减轻下一个环节需要处理的节点数量**
* **类型合法化**执行了两次：**第一次是对所有的节点类型进行处理，确保处理后的数据类型都是后端架构可以支持的，然后判断基于这些数据类型的操作是否合法**；**第二次则是因为合法化处理过程中，可能会重新产生架构不支持的数据类型**，因此需要再一次处理，对新产生的数据类型清理干净

2.第二类处理

基本块之间的ø函数处理：基本块内指令处理完毕后即处理到最后一条LLVM IR即Terminator指令，**根据CFG获取后继基本块的第一条指令**。若该指令是ø函数，说明后继基本块需要重**构ø函数依赖，编译器会先记录如ø函数位置、使用变量等相关信息，在所有基本块都执行完指令选择后再重构ø函数**



引入DAG数据结构，采用SDnode节点，**抽象指令格式为一组操作码和操作数，以此屏蔽不同处理器架构和指令集之间的差异**



7.2.1 SDNode 分类

SDNode包含节点编号、操作数信息（包括操作数序列、操作数个数）、**使用者序列**、**节点对应源码在源文件中的位置**等信息，并提供获取信息的接口

SDNode输入可以是叶子节点也可以是另一个SDNode的输出
SDNode输出也称为“值”，有两种：1.标识数据流 2.标识控制流

* 标识数据流的SDNode
  * **值是数据运算操作产生的结果**，这些操作节点接受多个入参
  * 参数可以是数据流类型值，也可以是控制流类型值
* 标识控制流SDNode
  * **值用于描述节点与节点之间的关系**
  * 常见chain和glue：chain用于表示多个节点之间的顺序执行关系，glue则用于表示两个节点之间不能穿插其他的节点；其中LLVM工具输出图用红色虚线表示chain，用红色实线表示glue
  * 为什么SDNode要引入控制流关系描述？
    * 若先store写内存后load读内存，先写后读时，没有chain控制流，那么先后顺序无法确定，会引起内存读取错误；加入chain后，其作为入参也可以作为输出，即store的输出的chain用作后续load的入参
    * 对于需要进行顺序执行的操作指令同时也被称为**具有边界效应(side effect)的操作**，还有如函数调用和函数返回



### 7.2.2 LLVM IR 到 SDNode 的转换(初始化)

对单个基本块的每一条指令进行处理时，将其转换为对应的SDNode节点（LLVM IR对应一个或多个），整个基本块处理完成后即可生成对应的DAG

当所有的基本块转换完成后再处理ø函数

举例：

```c
long callee(long a, long b) {
    long c = a + b;
    return c;
}
int caller() {
    long d = 1;
    long e = 2;
    int f = callee(d, e);
    return f;
}
```

以**BPF64后端**为例，调用约定——`r1~r5`寄存器进行参数传递，`r0`寄存器存储函数返回值，且此架构中规定只有64位数据为合法数据

`clang -O0 -S -emit-llvm xx.c -o xx.ll`进行编译

```ll
define dso_local i64 @callee(i64 noundef %a, i64 noundef %b) {
entry:
  %a.addr = alloca i64, align 8
  %b.addr = alloca i64, align 8
  %c = alloca i64, align 8
  store i64 %a, ptr %a.addr, align 8
  store i64 %b, ptr %b.addr, align 8
  %0 = load i64, ptr %a.addr, align 8
  %1 = load i64, ptr %b.addr, align 8
  %add = add nsw i64 %0, %1
  store i64 %add, ptr %c, align 8
  %2 = load i64, ptr %c, align 8
  ret i64 %2
}

declare void @llvm.dbg.declare(metadata, metadata, metadata) #1

define dso_local i32 @caller() {
entry:
  %d = alloca i64, align 8
  %e = alloca i64, align 8
  %f = alloca i32, align 4
  store i64 1, ptr %d, align 8
  store i64 2, ptr %e, align 8
  %0 = load i64, ptr %d, align 8
  %1 = load i64, ptr %e, align 8
  %call = call i64 @callee(i64 noundef %0, i64 noundef %1)
  %conv = trunc i64 %call to i32
  store i32 %conv, ptr %f, align 4
  %2 = load i32, ptr %f, align 4
  ret i32 %2
}
```



下面分别介绍不同类IR到SDNode的转换

* **运算类IR——>SDNode**

  `c = a + b`对应`%add = add nsw i64 %0, %1`

  其中`nsw`是一个符号扩展标记，**表示需要进行有符号数溢出检查**

  LLVM IR指令的操作数替换为相应的SDNode 的值

  指令操作码映射为相应SDNode 的指令操作码

  `%add = add nsw i64 %0, %1`对应SDNode表达：`t13 : i64 = add nsw t11, t12`

* **类型转换类IR——>SDNode**

  LLVM IR中有显式truncate指令进行类型截断或bitcast进行位转换

  如caller函数调用callee，callee返回值类型i64，但caller用i32进行接收，此时LLVM IR会使用一个truncate指令进行返回值的截断

  `%conv = trunc i64 %call to i32`

  对应SDNode`t24 : i32= truncate t23`
  
  当需要进行扩展时，在SDNode中会增加一些类型转换节点，如`any_extend、sign_extend、zero_extend`，如本例BPF64架构仅支持64位数据类型，其中callee返回值为i64，但是f返回值为i32，存在i32到i64的隐式类型转换需求，`t28: i64 = any_extend t27`
  
* **访存类IR——>SDNode**

  以callee中第一条store指令为例

  `store i64 %a, ptr %a.addr, align 8`

  对应SDNode为`t8: ch = store<(store (s64) into %ir.a.addr)> t0, t2, FrameIndex:i64<0>, undef:i64`

  `t2`:
  
  **引入CopyFromReg，而不是直接使用物理寄存器%a**——有利于**保持**当前IR的SSA形式，**解耦**指令选择和寄存器分配阶段，**屏蔽**大部分的后端架构差异，更有利于指令选择、指令调度和寄存器分配的执行。
  
  是因为调用约定通常会要求使用物理寄存器——%a为callee函数的第一个入参，需要从物理寄存器r0中读取，此处引入t2这样的赋值指令**可将物理寄存器赋值到虚拟寄存器中**
  
  `FrameIndex<0>`:
  
  **表示栈中第0个槽位的栈变量**，即目的地址`ptr %a.addr`
  
  `undef:i64`:
  
  **描述相对目的地址的偏移量**。默认情况下store和load的最后一个输入也都是Undef，它仅仅是一个占位符
  
  **引入其主要是为了在指令选择中对store和load进行优化**：`indexed load/store 访存格式`包括一个基地址和一个偏移量。在默认情况下，load和store都不会使用最后一个字段，如果编译器发现多条指令符合该访存格式，会将这些指令转换成一条`indexed load/store`指令
  
* **函数调用相关IR——>SDNode**

  函数调用与后端架构设计密切相关，所以各个架构需要根据自身调用约定从3个方面处理相应的函数调用LLVM IR：**入参处理、函数调用、函数返回**

  **函数调用交互：**调用过程移交控制和传递参数给被调用者，被调用者返回结果和控制给调用过程

  * **callee被调用前：**

    * 准备参数给callee，将待传递参数存放在适当的寄存器或者栈单元中
    * 使用物理寄存器传参，后端调用规定可用于传参的寄存器个数，超出寄存器个数的参数会被放到栈上
  
    ```c
    %call = call i64 @callee(i64 noundef %0, i64 noundef %1)
    ```
  
    **引入CopyToReg节点来处理调用约定**，通过CopyToReg节点将两个变量的值分别赋值到物理寄存器r1和r2中，然后将r1、r2作为BPFISD::CALL(BPF架构定义的函数调用SDNode节点)的参数
  
    实际call类型还会引入伪指令节点：
  
    * **TokenFactor节点:**
      * 接收多个操作数并只产生一个操作数作为输出，其多个输入操作数关联的操作是相互独立的，即访存操作相互独立
      * TokenFactor作为call指令入参和其本身(或可以说是前置节点callseq_star)之间的节点，输出ch保证了在call指令执行前，已经全部处理完相关的参数
    * **callseq_star、callseq_end:**
      * 分别位于call指令前后，进行**动态栈分配**，**以此准确确定栈的大小和对象的位置**
    * **r2和r1之间的依赖节点(t16和t18):**
      * 使用CopyToReg节点连接load节点和对应物理寄存器
      * r1、r2之间有glue依赖，即两个CopyToReg节点用glue相连——为了保证callee执行之前，所有参数不受干扰地准备完成，再进行下一步。相应的，glue顺序没有要求，可以先r1后r2，也可以先r2后r1
  
  * **callee被调用执行：**
  
    * callee从相应寄存器或者栈单元取得参数并开始运行
  
    * 本例采用O0编译优化
  
      `clang -O0 -S -emit-llvm xx.c -o xx.ll`
  
      所有参数、局部变量都会存放在栈内存中，因此编译器会使用alloca为变量分配独立内存空间，就会有很多load/store指令进行读写（相应O2 优化则会尽量将变量存入寄存器而不是内存中，提升程序执行效率同时优化代码大小）
  
  * **callee执行结束：**
  
    * 将返回值根据调用约定放在相应的寄存器单元并移交控制权给caller
    * callee的返回指令`ret i64 %2`与call指令一样都是后端相关的
  
  * **callee被调用完成：**
  
    * caller重新获得控制权，从返回值寄存器单元中获取返回值，并继续执行
  
* **Phi指令处理**

  * 当基本块处理完毕后，发现后继基本块有ø函数，则会**创建一个虚拟寄存器**存放与之对应的**ø函数中的操作数**——**对应为该在基本块中生成CopyToReg节点，将ø函数中的操作数赋值到分配的虚拟寄存器**

  * 当所有基本块完成指令选择后，再对ø函数进行处理——LLVM IR包含**ø函数位置信息**，然后对**ø函数添加寄存器和对应作为操作数的基本块**

    * 如SDNode节点表示：`%0:gpr = PHI %2:gpr, %bb.0, %5:gpr, %bb.1`
    * %2,%5为分配的虚拟寄存器；%bb.0,%bb.1为对应基本块
  



经过以上初始化流程后，由于是为了兼容后端而设计的SDNode生成过程，导致DAG中存在大量冗余节点以及特定架构不支持的数据类型和操作类型。因此SelectionDAG初始化完成以后会先进行一次**SDNode节点合并操作**，以优化DAG图，然后会进入合法化处理阶段——**消除架构中无法处理的节点，生成可供架构进行指令选择使用的合法DAG**





### 7.2.3 SDNode 合法化

数据是操作的基础。所以**合法化过程会首先根据TD文件，对DAG中各个节点的数据类型进行校验**。如果遇到架构不支持的数据类型，需要对其进行处理，使之成为目标架构可以支持的数据类型

* **类型合法化**

  * **最小合法类型：**架构支持的多个合法类型中，**位长度最短的**；最大合法类型相反
  * **寄存器描述(在TD文件中)设计中**定义了什么数据类型是合法的
  * LLVM中存在**Legal、Promote、Expand、Soften**这4种主要的标量数据类型合法化方式。Legal即合法不需要额外处理，另外3种需要特定的处理，将不合法的数据类型转变为合法的数据类型。
    * 若以上方式都无法将非法数据类型合法化，编译器会抛出错误error而终止运行
    * 除了以上合法化方式，还有Scalarize(将数组标量化)、Split(将数组拆分)、Widen(扩展为更长的数组)等合法化方式
  * **在合法化操作之前，编译器会根据TD文件（设计者设计的寄存器描述）获得该架构支持的所有合法数据类型，并计算得到LLVM中所有数据类型对应目标架构的合法化方式**
    * 根据TD定义的寄存器类型，找到架构中支持的最大整数类型(LargestInt)，如架构仅支持32位和64位的整形寄存器，则架构支持的最大整型为64位。**所有超过最大整型的类型，都使用LargestInt为基础类型，标记为Expand，使用多个（个数满足2<sup>n</sup>）基础类型的寄存器组合来表示**
    * **所有比LargestInt最大整型小的数据类型，首先需要判断是否为后端支持的合法类型，如果不是就标记为Promote，并将该类型提升为<最近>的一个合法类型**。例如，int64为LargestInt，int32为一个合法类型，int16为非法类型，会将int16提升到int32而非int64
    * 如f128，f64，f32不合法情况下，会被转成i128，i64，i32，这种合法化方式被称为Soften
  * BPF64架构仅64位数据类型是合法的，即64位数据类型既是后端的最大整型，也是最小/最大合法类型
    * any_extend高32位是未定义的，只有低32位数据具有存在意义。Promote会把操作数类型小于目标架构的最小合法类型提升到最小合法类型(也是其最近的)。对于BPF64来说，i32需要被提升至i64，因此初始化会被引入any_extend节点，但是**Promote合法化会将any_extend节点省去，而是直接把计算的各个操作数强制转变至64位长度**，最终计算结果不需要any_extend扩展了，而是顺理成章的成为i64。即`i32 + i32 = i64 (any_extend) ——> i64 + i64 = i64`
    * 如`%add = add nsw i128 %0, %1`两个i28均超过了最大合法类型，采用Expand合法化。**将t17、t18拆分为两个内存上连续的i64类型，即原来t17、t18各自的高64位和低64位**，高低64位各自进行add操作，**最终进行进位操作**，并将低64位操作结果进位到高64位中，**最终同样取两个连续64位长度空间存放结果的高低64位**，即产生输出——t19
    * Soften合法化：`%add = fadd float %0, %1`在被初始化为SDNode时，会产生bitcast节点，将float32位输出转换成32位整型；再通过any_extend节点提升位64位整型。但由于BPF64后端并不支持f32数据类型，故而在类型合法化操作时，发现f32类型的合法化方式为Soften——**将f32类型转化为同长度i32类型，再触发Promote操作，提升至i64类型，最终获得两个i64参数，对这两个参数会再调用LLVM内嵌的浮点加法运算——_addsf3（已经在LLVM中声明，需要在架构后端进行实现）**,这样就省去了bitcast和any_extend节点

* **操作合法化**

  * 将所有的节点进行拓扑排序，从后往前逆序依次处理（即下层节点在上层节点之后，先处理上层节点）

    * **逆序遍历好处**：当下层节点发生变化的时候，上层节点可以增量式更新，避免重新计算整个DAG图的全量节点
    * 在节点合法化操作之前，**首先判断是不是有别的节点使用了当前节点，若没有则冗余**，会直接删除，不参与合法化过程

  * LLVM操作合法化主要以下几类：

    * Legal、Promote、Expand、LibCall、Custom

    * Expand尝试将操作扩展为别的操作，如果失败就会转为LibCall的方式

      * 举例：

        ```c
        #include <stdint.h>
        
        int16_t add(int16_t a, int16_t b) {
            return a + b;
        }
        ```

        其中参数和返回值类型都是i16，在初始化时会产生sign_extend_inreg节点，用于将a+b的i16结果转成i64类型(后续再复制到r0寄存器中作为返回)

        **sign_extend_inreg对应的指令操作后端并没有，故会进行Expand操作，先生成shl（左移48位）后生成sra（右移48位）的节点序列，通过将原操作扩展为位移操作来实现同样功能**

      * 举例：

        ```c
        void func()
        {
            double a = 3.14;
            double b = a / 4;
        }
        
        .ll: %div = fdiv double %0,4.000000e+00
        ```

        由于BPF64结构没有浮点除法指令，fdiv节点被替换为对LLVM内嵌函数_divf3的调用

        同时因为a的数据类型为double(f64)，不是BPF64支持的合法数据类型，所以也被转变成了合法类型i64再使用

    * Custom：**采取目标架构自定义的实现来完成该操作，这些实现可以是合法化操作的组合，也可以是设计者自己编写的代码**

      * 书中例子太抽象了不举例了，p115——开发者才会知道为什么要这么做以及怎么做，这是自定义的实现

      * 其中值得提到一点的是，当和小于其中一个入参时，进位标志设置为1

        如:

        ```
              1  (进位链)
              1010   (A=10)
            + 0111   (B=7)
            --------
            1 0001   (数学结果是17)
            ^ ^
            | |
            | +---- 4位结果 (R=1)
            +------ 进位输出 (Carry-out=1)
        ```

  * 在操作合法化过程中，会存在一些优化以及数据拆分操作，可能会产生新的节点以及未被校验是否合法的数据类型，**因此在操作合法化处理完成后，还会再进行一次数据类型合法化**，以确保DAG中节点的数据类型都是可以处理的

* 向量合法化

  * 由于一些CPU架构位了加速数据处理能力，推出了可以并行处理多个数据的指令——SIMD(单指令多数据)，即一条指令可以处理多个数据。如一条指令处理4个i64类型加法操作，操作数类型从i64变为v4i64的向量类型
  * 在编译器中增加了对向量数据类型的处理，因此不可避免地会产生后端无法支持的向量数据类型，因此也需要进行类型合法化和操作合法化。在具体情况下，可将向量转变为标量



### 7.2.4 机器指令选择

经过初始化和合法化操作后，接下来需要为这些SDNode寻找与之对应的架构指令，即“指令选择”

**SelectionDAGIsel算法会从DAG的根节点开始自底向上进行**（根节点位于DAG的出口），对每个SDNode节点进行遍历处理，为其寻找对应架构指令

LLVM会先判断被遍历节点是否被其他节点使用，**若没有则标记为冗余节点，直接跳过匹配选择，并删除该节点**



指令选择过程中，大部分SDNode节点**是依赖基于TD文件生成的匹配表MatcherTable自动完成指令选择的**。但有些特殊节点（如具有多个输出的节点）是无法通过匹配表来完成匹配的——这就需要开发者遍历这些节点，自行编写相关逻辑来完成指令的匹配



1. 匹配表介绍

   在编译构建LLVM过程中，LLVM并不是最早开始被编译的，**工程首先会构建llvm-tblgen工具，并使用该工具将TD文件解析成C/C++风格的.inc头文件**

   以BPF后端为例，**后端代码在`llvm/lib/Target/BPF`目录下的TD文件中，`llvm-tblgen`处理这些代码以后，会在构建目录`build/lib/Target/BPF`下生成相应的.inc文件**，指令选择过程中使用的inc文件名为`xxxGenDAGISel.inc`，**其中包含的静态表项MatcherTable在指令匹配选择中扮演至关重要的角色**

   

   以BPF后端生成的BPFGenDAGISel.inc文件为例，介绍匹配表MatcherTable代码片段：`p118-121`

   **匹配表中数字**——字节偏移

   **/* 0*/**——元素在数组中的索引

   **OPC_SwitchOpcode**——数组中的第一项为OPC_SwitchOpcode,表示这是一个处理SDNode的匹配表

   **/* 36 cases*/**——表示该SDNode匹配有36种情况

   **21|128,1/* 149*/**——表示当前匹配表的大小。由变长的编码存储数据的方式知，用最高位来表示下一个数据是否属于当前的数据一部分，如`21｜128`最高位为1，表示后面的数据1也是属于当前的数据一部分。最终得到`( 1 << 7 ) + 21 = 149 `刚好是注释里的内容。

   **// —>154**——LLVM会记录每个SDNode对应匹配片段在整张匹配表中的起始位置，如匹配表第一行尾部的`// —>154`，表示从154字节处开始定义一个新的匹配节点，即`ISD::STORE`。通**过OPC_Scope记录的节点可以实现接下来不匹配的直接跳转，因为匹配表非常庞大，这样可以加速指令匹配过程**

   **OPC_xxx**——对应匹配流程的行为

   

2. 匹配演示过程 p122-123

   这个debug模式的编译器处理日志非常清晰



指令选择结束后，只有伪指令节点没有匹配为真实后端指令，如`EntryToken、CopyToReg、CopyFromReg`。**这样保留部分伪指令有利于后续寄存器分配、编译优化的工作，另一方面当前阶段编译器确实无法得知这些伪节点如何被硬件执行**。这些节点一般被保留在MIR中，在后续工作中进行处理



### 7.2.5 从DAG到MIR

代码表达经过机器匹配后仍然是DAG的形式（机器DAG，边用于存储依赖关系，不变，而节点均被机器指令匹配了），之后编译器需要遍历每个SDNode节点，生成与之对应的MIR。在进行生成MIR之前，编译器会先对DAG的节点进行优化，chain和glue等会在调度过程中被使用并最终消除，最终产生的MIR中将不携带这些信息。



**DAG的SDNode节点发射生成MIR两种情况：**

* SDNode在指令选择阶段已经匹配到了机器指令，直接生成相应的MIR，并放入与MIR对应的MBB（机器基本块）中，生成MIR过程如下：
  * 根据指令选择结果**新建相应的MIR**
  * 将原SDNode节点相关的**操作数、数据结构**中的节点属性等信息，相应地复制到MIR节点和数据结构中
  * 将MIR**插入**到MBB中的相应位置
* 一些特殊节点是**架构无关的且一般会存在控制流依赖**，后端架构中并不能通过指令选择找到与这些节点对应的汇编指令，如之前提到的伪指令节点。其会被转为相关伪指令放入到MBB中，如`CopyToReg、CopyFromReg伪指令节点——>COPY伪指令`，在后续优化会被消除或转换为真实机器指令



举例：

指令选择后callee DAG表达

```
Selected Selection DAG: %bb.0 'func:entry'
SelectionDAG has 20 nodes:
	t0: ch = EntryToken
		t4: i64, ch = CopyFromReg t0, Register:i64 %1
			t2: i64, ch = CopyFromReg t0, Register:i64 %0
		t8: ch = STRICT_STK_MEM:i64:store t0, TargetConstant:i64<0>, t2
	t10: ch = STRICT_STK_MEM:i64:store (s64) into %ir.a.addr> t4, TargetFrameIndex:i64<1>, 	TargetConstant:i64<0>, t8
	t12: i64, ch = LDDKMem:i64:dereferenceable load (s64) from %ir.b.addr> TargetFrameIndex:i64<1>, TargetConstant:i64<0>, t10
	t11: i64, ch = LDDKMem:i64:dereferenceable load (s64) from %ir.a.addr> TargetFrameIndex:i64<0>, TargetConstant:i64<0>, t10
		t13: i64 = ADD_rr nsw t11, t12
		t15: ch = TokenFactor t11:1, t12:1
	t16: ch = STRICT_MEM:i64:store (s64) into %ir.c> t13, TargetFrameIndex:i64<2>, TargetConstant:i64<0>, t15
		t17: i64, ch = LDDKMem:i64:dereferenceable load (s64) from %ir.c> TargetFrameIndex:i64<2>, TargetConstant:i64<0>, t16
	t19: ch,glue = CopyToReg t16, Register:i64 $t0, t17
	t20: ch = RET Register:i64 $t0, t19, t19:1
```

在经过MIR生成处理后：

```ll
Function Live Ins: $r1 in %0, $r2 in %1

bb.0.entry:
  liveins: $r1, $r2

  %0:gpr = COPY $r1
  %1:gpr = COPY $r2
  STD %1:gpr, %stack.0.a.addr, 0 :: (store (s64) into %ir.a.addr)
  STD %0:gpr, %stack.1.b.addr, 0 :: (store (s64) into %ir.b.addr)
  %2:gpr = LDD %stack.0.a.addr, 0 :: (dereferenceable load (s64) from %ir.a.addr)
  %3:gpr = LDD %stack.1.b.addr, 0 :: (dereferenceable load (s64) from %ir.b.addr)
  %4:gpr = nsw ADD_rr %2:gpr(tied-def 0), killed %3:gpr
  STD killed %4:gpr, %stack.2.c, 0 :: (store (s64) into %ir.c)
  %5:gpr = LDD %stack.2.c, 0 :: (dereferenceable load (s64) from %ir.c)
  $r0 = COPY %5:gpr
  RET implicit $r0

# End machine code for function func.
```



SDNode——MIR后，控制流依赖的chain和glue会被完全消除，所有指令都变成了线性的机器指令。

由于还没有确定用哪些寄存器来存储值，即还依赖“寄存器分配”；并且这一阶段指令并不是最高效的，还需经过后端优化。因此不能直接映射成机器汇编运行



## 7.3 快速指令选择算法分析

`SelectionDAGISel`算法经过LLVM IR的DAG化（初始化）、合法化、匹配表查找等复杂过程，会消耗大量时间

为了提高指令选择速度，LLVM实现了`FastISel`

`FastISel`算法只适用于部分后端的O0优化，**通过牺牲指令选择的质量来换取编译时间**



**`FastISel`原则是：尽可能快速地选择尽可能多的指令**

其允许指令选择失败——**当失败时会进入SelectionDAGIsel指令选择流程继续选择**(这使得其可以复用`SelectionDAGIsel`算法的实现逻辑，避免重复实现)

指令选择中涉及的一些复杂工作，如合法化、优化等，在`FastISel`中并不会处理，其只处理数据类型合法的简单操作。并认为其他数据类型和指令操作会失败，相应切换到`SelectionDAGIsel`进行处理.



`FastISel`也使用TableGen工具链：TD文件中的指令描述—（翻译）—>一个或多个函数调用

即将TD文件中的指令定义直接翻译成LLVM IR指令对应的MIR指令序列

具体参见第6章，**TD——记录——根据记录中pattern字段提取匹配信息，生成匹配模板校验函数(如下函数，只进行了返回值校验) C++——MIR**

**校验函数没有对操作数类型进行判断是否是寄存器类型，因为其可以作为多条指令的共性问题，通过框架中定义的函数`fastEmitInst_rr()`来配合实现**

```cpp
unsigned fastEmit_ISD_ADD_MVT_i64_rr (MVT RetVT, unsigned Op0, unsigned Op1)
{
	if (RetVT.SimpleTy != MVT::i64)
		return 0;
	return fastEmitInst_rr (Aarch64::ADDXrr, &Aarch64::GPR64RegClass, Op0, Op1);
}
```



`FastIsel`并不所有架构都支持



## 7.4 全局指令选择算法原理与实现

`SelectionDAGISel`有以下三个问题：

1. 代码维护成本高——如许多合并优化和合法化优化与指令选择并不强相关，但都被放入了指令选择阶段中
2. 增加生成最优代码难度——以基本块为粒度，跨基本块模式难以匹配上
3. DAG IR是图结构，需要指令调度才能生成线性MIR，这会增加编译时间，且他本身输入的LLVM IR本身是线性结构，如果中间没有图结构，那么指令调度可以去掉



由于其架构设计无法进行简单修补来完善，所以2015年LLVM社区提出了`GlobalISel`



### 7.4.1 全局指令选择阶段

使用新的中间表示`GMIR`，**其是线性的，且与MIR共用数据结构，除了操作码不同之外，指令表示方式等都是相同的**

GMIR操作码架构无关，用于支持不同架构的指令转换

第一阶段——使用宏展开算法将LLVM IR转成GMIR，接着基于GMIR进行指令合法化和寄存器类型分配，并在高优化场景下进行合并类的窥孔优化

第二阶段——表驱动算法来生成相应MIR



**采用多Pass设计，将两阶段涉及的功能进行解耦，每个能独立拆分出的功能都实现为单独的Pass**



### 7.4.2 GMIR生成

第一阶段的第一个Pass，宏展开算法**每次转换一条LLVM IR** 

由于GMIR**操作码具有通用性且LLVM IR架构无关**，所以转成的大部分GMIR指令都是架构无关的

但是GMIR也会包含一些目标架构相关的信息，如函数调用、形式参数处理，**需要目标架构提供调用约定才能处理**，需要将这部分LLVM IR转换成架构相关的GMIR



**GMIR以函数为粒度**，因为**函数可以分为函数头（形参信息）和函数体**，函数体又有基本块等表示，所以我们按处理的函数信息不同，将执行过程分为4个主要的阶段

1. 基本块创建

   遍历LLVM IR中的基本块，**为每一个基本块创建一个GMIR基本块**，并且**保留相关控制流信息，形成初始的控制流图**。该阶段还会**为每个函数添加一个额外的基本块(EntryBB)作为函数入口**

2. 形参处理

   根据架构提供的调用约定处理函数的入参，**为每一个入参生成一条从传参寄存器到虚拟寄存器的GMIR复制指令或者是从栈上到虚拟寄存器的GMIR加载指令**，并将指令放入EntryBB中

3. 函数体指令转换

   采用**逆后序遍历遍历函数的控制流图**，以**自顶向下的顺序将基本块里每条指令**转换成一组GMIR指令

4. 控制流图更新



举例说明以上4个阶段

```c++
int test(int a, int b) {
    return a + b;
}
```

`clang --target=Aarch64 -S -mllvm --global-isel -O2`进行编译，可以得到GMIR生成处理前的IR：

```ll
define dso_local noundef i32 @test(int, int)(i32 noundef %a,i32 noundef %b)
		local_unnamed_addr {
entry:
		%add = add nsw i32 %b %a
		ret i32 %add
}
```

1. **基本块创建**

   建立一个EntryBB作为**存放入参处理指令的基本块**，记为bb.0

   ```
   bb.0:
   ```

   接着处理函数的基本块，因为该函数**只有一个基本块，所以只需要建立一个GMIR基本块**，记为bb.1.entry

   ```
   bb.0:
   		successors: %bb.1(0x80000000); %bb.1(100.00%)
   bb.1.entry:
   ; predecessors: %bb.0
   ```

   `successors: %bb.1(0x80000000); %bb.1(100.00%)`	说明了bb.0唯一可以到达的是bb.1

   `; predecessors: %bb.0`	说明了bb.0是bb.1.entry的唯一前置基本块

   二者共同说明了bb.0和bb.1.entry 中没有其余分支，唯一相连

2. **形参处理**

   为形参创建虚拟寄存器，有两个形参创建两个，记为%0,%1

   根据目标架构调用约定（ABI），生成复制指令或加载指令

   ```
   Function Live Ins: $w0, $w1
   bb.0:
   		successors: %bb.1(0x80000000); %bb.1(100.00%)
   		liveins: $w0, $w1
   		%0:_(s32) = COPY $w0
   		%1:_(s32) = COPY $w1
   		
   bb.1.entry:
   ; predecessors: %bb.0
   ```

   `liveins: $w0, $w1`传入参数

   `%0:_(s32) = COPY $w0`
   `%1:_(s32) = COPY $w1`

   使用复制指令，给虚拟寄存器

3. **指令转换**

   add 和 ret指令需要进行转化

   add展开生成G_ADD指令（GMIR中定义的加法操作）,使用三个虚拟寄存器和G_ADD操作码共同组成一条GMIR加法指令

   ```
   Function Live Ins: $w0, $w1
   bb.0:
   		successors: %bb.1(0x80000000); %bb.1(100.00%)
   		liveins: $w0, $w1
   		%0:_(s32) = COPY $w0
   		%1:_(s32) = COPY $w1
   		
   bb.1.entry:
   ; predecessors: %bb.0
   		%2:_(s32) = nsw G_ADD %1:_, %0:_
   ```

   接着是ret指令，展开成返回值处理指令和返回指令，根据ABI判断返回值应该放入栈上还是物理寄存器。先获取返回值的虚拟寄存器，根据AArch64的调用约定，应该直接放入w0这个物理寄存器，所以只需一条复制指令即可，然后生成一条ret的返回指令

   ```
   Function Live Ins: $w0, $w1
   bb.0:
   		successors: %bb.1(0x80000000); %bb.1(100.00%)
   		liveins: $w0, $w1
   		%0:_(s32) = COPY $w0
   		%1:_(s32) = COPY $w1
   		
   bb.1.entry:
   ; predecessors: %bb.0
   		%2:_(s32) = nsw G_ADD %1:_, %0:_
   		$w0 = COPY %2:_(s32)
   		RET_ReallyLR implicit $w0
   ```

4. **控制流更新**

   该用例没有额外新增基本块，不需要进行函数体控制流的调整

   但是bb.0到下一个基本块(bb.1.entry)没有分支，**所以可以直接将bb.0直接合并到bb.1.entry中**

   最后得到的GMIR：

   ```
   Function Live Ins: $w0, $w1
   bb.1.entry:
   		liveins: $w0, $w1
   		%0:_(s32) = COPY $w0
   		%1:_(s32) = COPY $w1
   		%2:_(s32) = nsw G_ADD %1:_, %0:_
   		$w0 = COPY %2:_(s32)
   		RET_ReallyLR implicit $w0
   ```



### 7.4.3 指令合法化

之前说过大部分GMIR是架构无关的，经过IRtranstor转换后得到的GMIR有部分会存在目标架构不支持的情况。如16位字长的目标架构无法直接表示单条64位的加法。

为了处理这样的非法指令，GlobalISel算法实现了**一个独立的Pass，这个Pass会引入目标架构相关的指令信息**，并根据这些指令信息将函数中的非法GMIR指令替换成合法的

**以函数为粒度，以逆后序遍历从函数入口开始遍历基本块，在基本块中自顶向下遍历指令**

两个子问题：1. 判断是否是非法指令 2. 转换为合法GMIR

1. **当一个目标架构确定后，设置每个GMIR操作码的合法化属性**（根据这个属性就可以判断一条GMIR指令是否合法，以及不合法时需要选择的合法化操作）
2. 三种方法：
   1. 向上扩展或者向下拆分（类型转换指令： TRUNC 、 ANTEXT，发现和SelectionDAGISel合法化很像）
   2. lib库函数调用
   3. 定制化实现，直接替换一组MIR指令



**对于冗余指令需要进行合并优化删除，如对一个32位指令先截断后扩展**



### 7.4.4 寄存器类型选择

合法化处理后的GMIR指令仍然没有目标架构寄存器信息

指令里虚拟寄存器操作数**只有一个数据类型**，用于表示其类型（指针、标量还是向量）和位数大小，比如指令`%2:_(s32) = nsw G_ADD %1:_,%0:_` 	**此处仅表示`%2`是一个32位寄存器，但没有明确其是整型还是浮点以及是通用寄存器还是栈指针寄存器等这些寄存器类型。因此G_ADD无法明确后续可以使用的物理寄存器**

所以需要一个Pass来决定相应生成的GMIR待分配寄存器类型的功能，即寄存器类型选择Pass



**为什么不能直接在GMIR生成阶段为操作数加上寄存器类型的信息？**

**答：由于GMIR生成阶段还没完全转成GMIR，无法利用GMIR指令之间的关系，因此无法进行择优寄存器类型**，寄存器类型选择Pass则会利用目标架构的寄存器信息为GMIR指令的虚拟寄存器操作数分配合适的寄存器类型，且还可以利用GMIR指令之间的关系选取一个较优的寄存器类型



**以函数为粒度，RPOT方式，自顶向下**

寄存器类型分配后，**重写指令**，为指令的每个虚拟寄存器填上相应的寄存器类型

过程中可能会出现虚拟寄存器操作数**分配到的寄存器类型和定义的类型不一致的情况**——这时候要重新生成一个新类型的虚拟寄存器操作数，使用COPY指令进行复制给新的虚拟寄存器操作数，来替换原来的虚拟寄存器操作数



Pass分为3个子模块：

* **寄存器类型管理模块**
  * 用于**管理引入的目标架构寄存器类型信息**，并**提供通过数据类型获取寄存器类型的接口**
  * 新增一个新的寄存器概念——**RegBank**，它比MIR的RegisterClass寄存器概念更粗粒度
    * 只对目标架构寄存器进行简单划分，RegBank 可能一对多个 RegisterClass
    * 这样做，是因为GMIR和MIR对寄存器类型要求不同，GMIR期望简单，这样做到相关目标架构无关，避免因寄存器类型限制了GMIR指令可转换的MIR指令类型，保证后续MIR生成质量；而MIR是架构相关的，不同指令用的寄存器可能不同，因此需要更细致的寄存器类型
* **指令寄存器操作数类型分配模块**
  * 利用寄存器类型管理模块中的寄存器类型信息，为每条GMIR指令的虚拟寄存器操作数分配寄存器类型
  * 每条指令在分配后会对应相关的寄存器类型组，和操作数是一一对应的，如G_ADD指令对应(gpr、gpr、gpr),一一对应三个操作数都是gpr寄存器类型
  * 两种分配算法，不同优化
    * Fast：只寻找指令默认可用的寄存器类型组合
    * Greedy：先寻找指令默认可用的组合，再找目标架构允许的其他所有可用组合；最后计算每组成本，选出一组成本最低的组合
* 指令重写模块
  * 根据分配到的寄存器类型组**重写GMIR指令**，并**逐个判断寄存器操作数是否含有寄存器类型**
    * 如果没有则直接填上相应的寄存器类型
    * 如果有则判断寄存器类型是否与定义一致
      * 一致则不变
      * 不一致则根据寄存器组类型信息生成一个新的寄存器操作数，使用COPY复制指令替换旧的



**举例：G_OR**

```cpp
int test(int a, int b) {
    return a | b;
}
```

寄存器类型选择Pass对应源码GMIR部分

```
Function Live Ins: $w0, $w1
bb.1.entry:
		liveins: $w0, $w1
		%0:_(s32) = COPY $w0
		%1:_(s32) = COPY $w1
		%2:_(s32) = G_OR %1:_, %0:_
		$w0 = COPY %2:_(s32)
		RET_ReallyLR implicit $w0
```

采用Greedy算法进行分配，先找默认，再找可用所有，最后进行计算成本，选出最优

* `%0:_(s32) = COPY $w0`

  源操作数是整型，所以默认寄存器类型组合是GPRRegBank

  AArch64中COPY指令无其他额外提供的寄存器类型组合

  `%0:gpr32 = COPY $w0`

* `%1:_(s32) = COPY $w1`同理

* `%2:_(s32) = G_OR %1:gpr32, %0:gpr32`

  注意！由于前两个指令已经给两个源操作数分配了GPRRegBank了

  因此找到的默认寄存器类型组合就是%2:GPRRegBank，%1:GPRRegBank，%0:GPRRegBank，即三个整型寄存器

  再找组合——因为AArch64有"整型或"和"浮点或"指令，对应提供了两种额外的寄存器类型组合，这里第一二种一样，所以省去，只给出第三种：%2:FPRRegBank，%1:FPRRegBank，%0:FPRRegBank

  

  成本计算公式：p140 略

  算出三个整型寄存器组合的成本最低

  `%2:gpr32 = G_OR %1:gpr32, %0:gpr32`

* `$w0 = COPY %2:gpr32`已经确定，无须任何操作

最终得到Pass后的GMIR

```
Function Live Ins: $w0, $w1
bb.1.entry:
		liveins: $w0, $w1
		%0:gpr32 = COPY $w0
		%1:gpr32 = COPY $w1
		%2:gpr32 = G_OR %1:gpr32, %0:gpr32
		$w0 = COPY %2:gpr32
		RET_ReallyLR implicit $w0
```



### 7.4.5 机器指令选择

GMIR转换成目标MIR的一个Pass

**以函数为单位，使用基于树覆盖的指令选择算法**，只产生一种成功匹配的树模式，因此可以直接生成对应的MIR序列

两种：1. 基于表驱动的自动状态机进行的自动覆盖方式 2. 固定模式的手动覆盖方式

**指令选择过程会从函数底部开始逆序遍历基本块，然后自底向上处理基本块中每一条GMIR指令**

* 判断是否已经生成MIR指令
  * 若没有，则以指令为根节点，执行自动匹配模块和手动匹配模块，进行树覆盖匹配
    * 匹配成功，生成MIR指令
    * 匹配失败，报错
  * 若有，则不做处理，继续遍历，迭代到所有GMIR都转换成MIR或者报错



Pass分为3个模块：

* 自动匹配模块
  * 分两个阶段
    * 构建自动匹配状态机，编译器生成的时候由TableGen构建
    * 使用自动匹配状态机
    * 参考7.2.4介绍
  * TD文件中定义的一个新记录——GINodeEquiv
    * 为了减少SelectionDAGISel迁移到全局指令选择阶段的工作量
    * **通过它可以实现操作码的关联，达到复用效果**
      * 如`def : GINodeEquiv<G_ADD, add>;`可以把G_ADD和对应的ISD操作码——add关联起来，然后TableGen就可以根据add的模式来获得G_ADD的模式，从而生成相应的匹配状态机
* 手动匹配模块
  * 需要通过手动编写C++函数的形式，编写每个待匹配树模式匹配目标架构指令的实现代码
  * 手动匹配模块可以拆分为一二，也可以不拆分的选择放在自动匹配模块前后，依据能否生成质量较优的代码指令而定
* 指令生成模块



### 7.4.6 合并优化

全局指令选择无法处理共用节点、多输出和控制流等**图属性的场景**，因为其是基于树匹配模式的算法，如对两棵树共用的多输出的节点处理时，它会先分别处理两棵树，将共用节点进行复制，这样会产生冗余指令，影响代码质量

优化框架：

1. 基础设施——待优化GMIR指令的遍历以及所有可以优化模式的管理
2. 优化模式匹配规则——定义了每个优化模式的匹配规则，待优化指令需要满足特定优化模式规则才可以使用该模式
3. 优化模式重写——将待优化指令改写成特定优化模式对应的指令序列



？？？

全局指令选择相较于SelectionDAGISel，算法不够完善，汇编质量差，且当前支持目标架构不够丰富

但实现了高内聚低耦合设计，多个独立Pass。同时减少了MIR转换成本，又GMIR和MIR共用基础设施数据结构，降低了代码维护成本

