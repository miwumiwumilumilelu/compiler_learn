# 第十一章 函数栈帧生成和非SSA形式的编译优化

主要讨论在寄存器分配后、代码生成前所做的工作

1. 函数的栈帧生成及其相关优化
2. 针对MIR的编译优化
3. 指令变换和调度
4. 机器码生成前优化

此时做的优化不再考虑寄存器压力等因素，因为寄存器已经分配完毕



## 11.1 函数栈帧生成及其相关优化

函数栈帧生成——为满足后端调用约定，**在函数调用时为函数生成执行栈**，以确保程序执行的正确性

在函数栈帧最终确定前可以进行代码下沉和栈帧范围收缩优化

### 11.1.1 栈帧生成

栈帧生成的最重要的3个任务：

1. 对CSR进行处理：这是达到调用约定所需的最主要工作之一
2. 完成栈帧布局：在栈帧布局确定之前，通过栈索引来访问栈对象（假定栈对象存放在一个数组中）；当栈帧布局确定后，可基于栈寄存器的偏移来访问栈对象
3. 函数前言/后序生成：前言通常是为函数建立新的栈帧，后序则是为了销毁函数栈帧

主要工作如下：

1. 计算Save、Restore位置，默认Save和Restore分别位于函数的入口和函数的出口（函数的出口可能有多个，所以每个出口位置都需要进行栈帧销毁）

   当栈帧范围收缩时，可以重新调整Save、Restore位置

2. 根据后端约定计算函数使用的CSR（需要遍历函数，**函数中修改的CSR才需要保存**）以及为CSR分配对应栈槽，如果函数没有使用CSR则不需要分配栈槽

3. 在Save和Restore基本块中为需要保存的CSR插入COPY指令，用于保存和恢复CSR，同时更新路径中CSR影响到的基本块

4. 根据栈使用的方向、对齐粒度等，为栈对象计算真实的偏移值

5. 插入函数的前言和后序代码，**主要是为了保存和恢复栈寄存器**

6. 将栈对象的偏移值和栈寄存器关联，栈对象则可以都通过栈寄存器访问得到



### 11.1.2 代码下沉

LLVM共有4个代码优化，两个在中端，一个在基于SSA形式MIR的寄存器分配前，一个在基于非SSA形式MIR的寄存器分配后

此时为基于非SSA形式MIR的寄存器分配后阶段，**LLVM仅会尝试下沉COPY指令**，可能会在后续的栈帧范围收缩或者复制传播环节带来新的优化机会

* 接下来介绍允许代码下沉场景：

  当前基本块的COPY指令定义的寄存器

  1. 在当前基本块的唯一后继基本块中活跃
  2. 有两个后继基本块，且其中一个唯一活跃
  3. 有两个基本块，其中一个后继基本块的后继基本块是当前节点，构成一个循环，且其中一个唯一活跃

* 禁止代码下沉的场景：

  当前基本块的COPY指令定义的寄存器

  1. 有两个后继基本块，且同时活跃
  2. 有两个后继基本块，且它们的后继汇聚同一个基本块D，这两个后继都不活跃，但在基本块D中活跃
  3. 其后继基本块有多个前驱，有可能执行来自于其他分支

**代码下沉算法**

以基本块为粒度进行处理

1. **从下往上**依次遍历基本块的指令，遇到Call指令时终止下沉（无法确定Call之前的指令是否会受到Call指令影响），然后处理下一个基本块

2. 当指令不是COPY，通过记录指令定义和使用的寄存器来处理下一条指令

3. 如果是COPY，当COPY定义的**寄存器不可以重命名时**（不可重命名的寄存器一般是为了满足后端约束而指定的寄存器），通过记录指令定义和使用的寄存器来处理下一条指令

4. 判断COPY指令是否和已经遍历的指令**存在寄存器依赖**，如果当前COPY指令中定义的寄存器被后序的指令（已经遍历过的指令）使用或重新定义，则不能下沉，需要转而处理下一条指令

5. 经过前4步判断处理，COPY可能可以下沉了，还需要为下沉的COPY指令寻找一个基本块

   对COPY指令定义的寄存器进行分析，根据之前介绍情况进行判定

   下沉或者继续处理下一条

6. 一般来说，下沉到基本块的第一条指令处。但如果存在调用约定前序指令，那么下沉COPY指令不能和相关指令的寄存器存在读写依赖，则进行特殊处理

7. **COPY指令下沉后需要更新下沉基本块的LiveIn信息，将COPY指令定义的寄存器从LiveIn中删除（此寄存器会在下沉基本块中重新定义），并将COPY指令使用的寄存器增加到LiveIn中**（也就是当前基本块COPY定义的寄存器，不再是下一个基本块的LiveIn了，而是在下一个基本块中才定义）

**中后端代码下沉比较**

|          下沉方式          | 功能                                                         |
| :------------------------: | :----------------------------------------------------------- |
|          **Sink**          | 属于中端优化，针对有多个后继节点的基本块（分支和循环）进行下沉优化。代码下沉后，有的分支可能不再被执行，从而达到减少代码执行的效果。除了特殊指令（指调用函数、边界指令、异常指令等）外，其他代码在中端优化都可以进行下沉，下沉时寻找一个位置，该位置能支配所有Use下沉指令。目前，在LLVM中执行中端代码下沉时，如果目的基本块中存在关键边，则不会对关键边拆分（如果不进行关键边拆分，则会导致代码错误），直接放弃下沉。 |
|       **Loop Sink**        | 属于中端优化，针对循环进行代码下沉。是和中端优化LICM相反的优化动作。在对循环代码下沉时，为了保证进行中的代码下沉不增加代码的执行成本，只会选择执行频率低的基本块作为下沉目的地，同时要求下沉目的地的执行成本小于循环头的执行成本，否则不会进行下沉。 |
|    **Machine Sinking**     | 属于后端优化，针对有多个后继节点的基本块（分支和循环）进行下沉。通过代码下沉，有的分支可能不再被执行，从而可以减少代码的执行。它并不是中端优化Sink的替代，而是其补充。 |
| **PostRA Machine Sinking** | 属于后端优化，仅仅针对COPY指令下沉，以帮助复制传播和栈帧收缩产生新的优化机会。 |



### 11.1.3 栈帧范围收缩

指的是**优化函数前言和后序的位置**，以便降低执行成本

一般来说，函数前言插入在entry基本块中，函数后序插入在一个或多个返回基本块中

并非最优，可以进行插入优化

**Save (序言)**：位于代码执行的**上游**。为了保证安全，它必须位于所有CSR使用点**之前**（支配它们）

**Restore (结语)**：位于代码执行的**下游**。为了保证安全，它必须位于所有CSR使用点**之后**（逆支配它们）

**实现：**

1. 针对基本块，以**PROT顺序遍历**基本块中的每一条指令，保证优先遍历叶子节点
   1. 如果指令没有使用CSR或者栈对象，则处理下一条指令
   2. 否则说明基本块是候选的函数前言/后序的插入位置，可以尝试更新save、restore指令的位置，依赖于以下判定：
      * save应该支配基本块，所以save会更新为**支配当前基本块和原来save**的基本块（第一次执行save为空时，直接赋值当前基本块）
      * restore应该逆支配基本块，所以restore会更新为**逆支配当前基本块和原来store**的基本块
      * save也应该支配restore，否则save应该更新为支配原来save和restore的基本块
      * restore也应该逆支配save，否则restore应该更新为逆支配save和原来restore的基本块
      * 如果save和restore处于循环中，他们应该位于同一个循环体
2. 当处理完所有基本块后，得到最后的save和restore，save和restore的执行成本应该低于entry基本块、exit基本块的执行成本，否则还需要更新save和restore，更新方法如下：
   1. 如果save的基本块的执行成本高于entry，**将save中的基本块更新为支配所有前驱的基本块**，同时要求基本块的执行成本低于entry基本块的执行成本
   2. 如果restore的基本块的执行成本高于exit，**将restore中的基本块更新为逆支配所有后驱的基本块**，同时要求基本块的执行成本低于exit基本块的执行成本

**上述实现算法的限制：**

1. 算法尽可能地寻找唯一的save/restore执行点，分别用于存放函数前言和后序，复杂的函数结构计算得到的save和restore中保存的基本块与entry/exit基本块的执行成本相同
2. 算法并未针对CSR、栈操作分别处理，也导致丧失优化机会



## 11.2 MIR 优化

在寄存器分配完成后执行的MIR优化有3个

1. **分支折叠**：通过优化跳转基本块的位置、MIR指令提升等来消除跳转指令
2. **尾代码重复**：将基本块中的代码提升到前驱基本块中，以便消除额外的跳转指令
3. **复制传播**：对COPY指令进行优化，消除冗余复制



### 11.2.1 分支折叠

分支折叠最早出现在硬件设计中，其目的是避免流水线被中断

通过将一些分支指令进行重排，从而达到消除跳转指令或者重排指令后不再中断流水线执行的效果



**分支折叠分为：**

1. **尾代码合并**：与尾代码重复相反，执行与否取决于后端，**如果后端允许修改CFG则可以执行，否则不能执行**

   1. 情况1:将函数中没有后继基本块的基本块（即出口）进行合并

      在所有可以合并的基本块中取尾代码重复最多的基本块，然后合并

      * 合并时会创建一个新的基本块（取尾代码重复的代码到这个统一的基本块中，即将相同代码放置在新的基本块中）
      * 然后设置其中一个位置相邻基本块与新创建的基本块前驱后继的直通关系（不需要跳转指令），另一个基本块则新增无条件跳转指令
      * 再观察新建基本块中放入的重复代码是否与其他未处理的基本块的尾代码继续重复，则继续重复以上操作进行尾代码合并

   2. 情况2:将基本块的多个前驱基本块进行合并

      同情况1一样，都是新建基本块来存重复尾代码，进行合并

      **其中考虑到一种场景：当前基本块T与其前驱基本块B不是位置相邻，而是通过条件跳转得到即不是直通关系——则可以尝试调整其前驱基本块位置，使其相邻（将条件跳转指令的条件逻辑进行反转，使其不会直接跳转到当前基本块T，而是跳转到B原本直通的基本块D，也就是我们可以插入新的基本块AB进来作为基本块B现在的直通），将基本块A和B中的相同指令再合并到基本块AB中，最后AB指向当前基本块T**

      即`if (条件成立)` **跳去 T**；`else` **直通 D** 转变为`if (条件成立)` **跳去 D**；`else` **直通 AB**

   实际上，尾代码合并有诸多细节：

   1. 计算基本块是否可以合并时，不仅仅考虑相同指令数，还会考虑其他因素，用于判断合并后是否有收益，收益可以通过针对场景的分析得到：
      * 两个基本块有部分相同的指令，同时一个基本块被另一个基本块包含（有后继关系，**且后继基本块的指令完全包含在另外一个基本块中**），进行代码合并不仅可以减少代码，还不需要创建新的基本块
      * 当代码合并开启后，如果待合并的相同指令数较少时（通常**阈值**为两条指令，可以通过设置参数来执行**激进的合并**，以减少代码），会**要求两个基本块都在冷路径**中（如果基本块都在热路径中，为热路径增加跳转指令会影响执行效率）
   2. 对于要划分的基本块，目前是找一个执行成本最低的基本块进行划分（这样做相对公平）；对基本块进行划分，**新产生的基本块应该继承所有前驱基本块的执行频率**
   3. 更新新增的基本块的LiveIn等信息

   

2. **基本块优化**：包括死基本块删除、空基本块消除和相同分支基本块合并等

   1. 空基本块消除

      需要保证基本块的相邻关系，而不用引入额外指令

   2. 相同分支基本块合并

      如果br cond两种分支都指向同一个基本块，则可以将分支条件移除（删除`br cond`）

      * 如果两个基本块相邻，则直接删除分支指令，进行直通
      * 如果不相邻，则增加无条件跳转指令（在后续分支折叠中还可以尝试移除该指令进行优化）

   3. 基本块压缩

      要求基本块相邻，且后继基本块的前驱只有一个，则后继基本块中的指令完全可以移入前驱基本块中

   4. 条件分支移除

      如果在基本块中，条件分支指令只在一个分支中存在，而另一个分支为空，则可以移除分支指令或者将其替换为无条件跳转指令

   5. 条件分支的条件化简和反转

      注意冷热代码分离，所以可以考虑通过条件反转来调整代码位置即基本块位置（减少条件跳转的假分支直通的约束即位置相邻的约束）

   6. 连续跳转指令合并

      对于连续跳转的基本块优化后，如果是死基本块则进行删除

      该优化执行约束比较多，可能带有副作用，如若放置跳转指令的基本块是热路径时，经过这样优化会影响后续代码布局，导致性能问题

   7. 循环中条件分支的条件反转

      **因为真分支预测执行效率更高，可以获得更高的执行性能收益**，所以让真分支作为循环体

   8. 无条件跳转指令消除

      我感觉和基本块压缩差不多，如果存在仅包含无条件跳转指令的基本块，则将其删除，并检查前驱基本块是否直通其跳转的基本块，注意为前驱添加跳转指令

      这里注意，假设有基本块A与该基本块相邻，但并不是前驱，需要格外注意重构基本块A的最后分支指令，使基本块A执行完可以跳转到正确的后继基本块中，避免直通该基本块

   9. 调整基本块相邻位置

      如果遍历基本块的顺序，发现存在优化机会，则可以调整基本块的位置，以消除分支指令

      向上调整，让当前基本块与其前驱基本块进行位置相邻；或向下调整，让当前基本块与其后继基本块进行位置相邻

   10. 删除死基本块（没有前驱的基本块除了entry块）

       删除死基本块不仅删除它本身，还会删除其后继基本块

       

3. **代码提升**：将公共代码向上提升，减少代码大小

   在基本块的多个后继基本块中提取公共代码并进行公共代码提升（上移）

   注意约束细节：

   * 代码提升一定会放在基本块的所有跳转指令之前（条件分支指令之前）

     **若跳转指令会修改、使用寄存器，且提升的代码的寄存器和其存在依赖关系**，则不能进行提升，避免产生错误跳转

   * 代码提升不仅要求两个分支基本块中的指令相同，还要求**指令的一些属性也应该相同**，如dead，killed会影响寄存器的生命周期

     如果不同则不能提升

   * 被提升的指令**需要更新的指令状态**，保证状态的正确设置

   * 被提升的指令应该是需要**能安全移动**的（例如volatile类型的内存访问指令一般是不安全的，call指令的移动一般也是不完全的）

   * 代码提升后，还需要**保证两个分支基本块的LiveIn等信息正确**

4. **跳表优化**：针对跳表进行优化

   switch-case优化，对没有使用的跳表项进行移除



### 11.2.2 尾代码重复

虽然会增加代码量，但可能会为后续复制传播优化提高更多机会；同时，与9.1节介绍的相比，**此时执行尾代码重复的限制更少**，可以处理call、ret指令，且不要求MIR保持SSA形式，实现更为简单



### 11.2.3 复制传播

与10.2.14介绍的完全相同，后端进行优化过程中产生了COPY指令，所以这里再次进行复制传播优化了



## 11.3 MIR指令变换和调度

MIR指令变换包括伪指令处理、隐式空指针检查、指令调度

1. **伪指令处理**

   在指令选择和寄存器分配完成后，理论上所有的MIR指令在后端中都有与之对应的指令

   但是LLVM在MIR层面定义了伪指令，这些伪指令并不是真实的后端指令

   因此需要一个额外Pass将伪指令转变为后端对应的指令，如COPY这样的常见伪指令（各个后端可以自定义伪指令，在TD文件中通过isPseudo进行定义）

   此处补充定义伪指令意义：

   * 为了便于栈帧处理以前**统一设置基于偏移的栈对象访问**
   * COPY为了将不同后端的复制、移动指令进行统一，**方便优化和调度**

   不同后端处理伪指令的过程不同，且部分伪指令已经在其他的优化过程中进行了处理，此处处理剩余的伪指令

2. **隐式空指针检查**

   在动态语言（Java、C++）中进行空指针检查很常见，此处引入隐式检查机制，如果指针为空则进行异常处理（通常是NullPointerException异常）

   该Pass为代码插入额外的空指针检查以及进行对应的异常处理

3. **指令调度**

   寄存器分配后再次进行指令调度优化，**此处仅考虑指令的并行性**，不用考虑寄存器压力



## 11.4 MIR信息收集及布局优化

在完成MIR变换以后，会**针对MIR进行信息分析（用于过程间优化）**，并进行**基本块粒度和函数粒度的优化**

进行的功能如下：

1. **垃圾回收信息收集**

   为了支持**运行时**进行垃圾回收，需要两类信息——

   1. 在哪些地方（也称为**安全点**）可以执行垃圾回收动作（目前**LLVM将函数调用视为安全点**，会在函数调用前执行垃圾回收动作）

   2. 识别栈中哪些对象是垃圾回收的**根节点**（通过**Tracing算法**遍历栈，从而**识别堆空间中哪些对象是活跃的**）

2. **基本块布局优化**

   根据**基本块的关系、执行频率等信息**，将基本块按照一定算法原则进行组织

   从而达到较高的缓存利用率，实现高效率的分支跳转

3. **支持静态或动态插桩**

   编译器支持插桩是**为了动态修改编译后的代码**

   目前LLVM支持3种插桩，分别是`FEntry、XRay、PatchableFunction`

   * `FEntry` 

     **允许外部提供_ entry _的函数实现**，在链接时将外部 _ entry _ 链接到二进制文件中，典型的应用是Linux的ftrace模块实现

     FEntry **在函数头中预留了调用 _ entry _ 的指令**，若外部实现了该函数，则可以实现一些特殊功能

   * `XRay`

      是LLVM提供的**对函数调用进行追踪**的功能，在函数入口、出口插入记录运行时信息的函数（**需要配合compiler-rt库使用**）

     插桩阶段主要**在函数入口、出口生成一些辅助指令**，当运行时发现链接了compiler-rt库后，这些辅助指令会被替换为一段功能代码（跳转并执行相关的函数），类似于动态打补丁功能

     如果没有链接compiler-rt库，这些辅助函数的功能基本等价于NOP指令（空指令）

     还可以**自定义相关的运行时函数来重写compiler-rt中相关的库函数**

   * `PatchableFunction`

     允许通过参数控制在函数头预留一定数量的空指令（类似于XRay实现）

     或者通过插桩让函数跳转到别的地方执行（目前仅x86-64平台支持）

     另外，可以通过外部工具（如ftrace）对NOP指令打补丁，从而实现一些特殊功能

4. **寄存器使用分析**

   旨在收集函数中的寄存器使用信息，用于过程间寄存器分配优化

   处理思路是：

   收集函数中的Mask寄存器（即在callee中未被保存的CSR寄存器）和Clobber寄存器信息

   在caller侧分配时，这些信息都可以帮助识别Mask寄存器，从而让caller有更多可用的寄存器（callee中没有使用的CSR可以在caller中使用）

5. **异常基本块布局优化**

   将异常处理基本块放在非异常基本块的后面（因为**异常通常属于冷代码**），从而提高执行效率

6. **动态栈布局信息收集**

   代码支持插桩操作，但执行插桩操作后，可能需要使用栈布局信息，所以要收集栈布局信息

7. **调试指令分析**
   对活跃调试指令（DBG_VALUE）进行分析，计算调试指令的范围

8. **公共代码提取**

   将不同函数中的公共代码提取出来，形成新的函数，然后将公共代码删除，通过call指令访问新函数

   该优化有效减少代码量

9. **函数中冷热代码分离**

   识别函数中的冷、热代码，将热代码放在一起、冷代码放在一起，**提高指令缓存（ICache）和TLB的命中率**，从而提升程序的执行性能

   由于该优化**会将一个函数中的代码分离存放**，为了保证正确性**需要增加额外的跳转指令、函数栈信息、调试信息等**，因此导致代码量增多



以下主要介绍有关代码布局相关的优化，即**基本块布局优化、公共代码提取、函数中冷热代码分离**3个方向的优化算法



### 11.4.1 基本块布局优化

基本块布局一般是指**以CFG为基础**将执行路径中**执行频率高的基本块放在一起，重排基本块的顺序**，以提高指令缓存的命中率

优化算法通常将CFG图中的基本块抽象为顶点（记为V），将基本块之间可达关系抽象为边（记为E），基本块边的执行频率表示边的权重（记为W），因此图G=<V, E, W>，然后对图G进行优化



当前LLVM的基本块布局优化不仅包含了基本块布局功能，还包含了基本块的对齐功能

**基本块对齐旨在让生成的代码尽量与缓存行对齐，从而提高执行效率**。但是基本块对齐可能会导致代码量变大，因为在基本块对齐的过程中会插入用于对齐的NOP指令，因此之后仅讨论基本块布局功能



当前LLVM有两种算法用于基本块布局优化：一种是基于**链合并的思路**，另一种是**基于ExtTSP（扩展TSP）的思路**

默认情况下并不会执行ExtTSP算法，如果要使用，在命令行中设置参数`enable-ext-tsp-block-placement`为true



11.4.1.1 **链合并算法介绍**

最为典型的基本块布局优化算法



思路如下：

1. 将每一个基本块都初始化为一个链
2. 根据CFG和执行的频率尝试将链进行合并，为链（记为C1）的最后一个基本块寻找一条合并后效果最好的链（记为C2），并将C2的第一个基本块接在C1的最好一个基本块，从而达成链的合并
3. **将不能进行合并的链按照一定顺序（如CFG遍历顺序）进行合并**，最后形成基本块的布局
4. 在合并链的过程中，如果发现基本块的位置发生了变化（例如原来相邻或者相通的基本块，现在不再相邻），可能需要插入无条件跳转指令来保证正确性



LLVM在实现中基本没有脱离上述思路，但针对循环做了特殊处理（**优先合并循环构成的链**），同时考虑了很多优化细节

参考Youtube `https://www.youtube.com/watch?v=s9KDITTI0Ro`

大概如下：

1. 为每一个顶点初始化一个链
2. 针对循环优化进行链合并，**内层循环优先级更高**。在合并时先尝试重新确定循环链的顺序，通过**调整循环中基本块的顺序以减少循环中的跳转次数**。另外，在**合并时需要比较其他链和当前链的交叉基本块情况**，然后做出最优选择，最后在合并的时候还会尝试进行**尾代码重复优化（将整个基本块在不同链中重复）**来减少跳转次数
3. 根据CFG图，进行链合并
4. 将没有合并的链，按CFG遍历顺序进行合并



LLVM中实现的增强点：

* 循环调整的目的是调整循环的基本块顺序，从而减少循环体中的跳转次数

  **尽量减少循环中的跳转指令数量**

  `https://reviews.llvm.org/D43256`

* 链路合并优化会考虑链路交叉的情况，假设有三个链C1、C2、C3

  C3中的Succ入口基本块有两个前驱，分别指向C1和C2，如果将C1和C3进行合并，还要考虑C2

  **此时需要比较C1的出口基本块到C3的Succ的执行频率 和 C2的出口基本块到C3的Succ的执行频率**

  如果前者高，那么C1和C3应该放在一起，防止高频率的执行发生在无条件跳转指令上

  * 如果有四个基本块交叉，即两个前驱两个后继的情况：

    此时需要计算4个执行频率，但也就是2个组合的执行频率，设BB为C1的出口基本块，SuccPred为C2的出口基本块，S1和S2分别为C3和C4的入口基本块

    计算BB->S1、SuccPred->S2 和 BB->S2、SuccPred->S1进行执行频率比较，如果前者更高，则C1和C3相邻、C2和C4相邻

* 判定是否可以进行尾代码重复，并根据重复情况为不同的分支安排不同的基本块布局

  考虑情况：

  基本块 `Succ` 是一个汇合点（汇聚了来自 `BB` 和 `C'` 这两个前驱基本块的跳转），也是一个分叉点（跳转到 `V` 或 `E`这两个后继基本块），路径 1（左侧热路径**）**：`BB -> Succ -> V`  路径 2（右侧热路径**）**：`BB -> C -> ... -> C' -> Succ -> E`

  在物理内存中，`Succ` 只有一个身位，它只能紧挨着某一个前驱块（比如放在 `BB` 后面），或者紧挨着某一个后继块

  进行尾代码重复，减少跳转指令，路径 1 (BB -> Succ -> V)：现在可以在物理内存上排成 `[BB][Succ][V]`。CPU 执行这条路时，0 次跳转。路径 2 (C' -> Succ -> E)：现在可以在物理内存上排成 `[C'][Succ_Copy][E]`。CPU 执行这条路时，0 次跳转。

  但要考虑Succ能否进行尾代码重复优化



11.4.1.2 **ExtTSP算法介绍**

基本块布局优化可以抽象为TSP（旅行商问题）模型，假设存在CFG图G = <V, E, W> , 求一个最大值(F), 该最大值用下面公式：
$$
F = \sum_{(s, t)} w(s, t) \times \begin{cases}  1, & \text{如果 } \text{len}(s, t) = 0 \\ 0, & \text{如果 } \text{len}(s, t) > 0  \end{cases}
$$
其中s、t表示基本块，(s, t)表示从基本块s到基本块t的一条边，w表示边的权重即执行频率，len则表示两个基本块之间的指令长度（如果相邻，则不存在指令，长度为0）

**求取指令长度和TSP求最大值F完全相同**，早期基本块布局优化都是以TSP模型为基础求解最优基本块布局



TSP并未考虑基本块中跳转指令的影响，所以会导致个别预测出现较大的偏差

由于高速缓存命中率和缓存行存储基本块有关，执行频率可以说明各个分支的执行概率，对于高概率情况的基本块最好放在一个基本块内进行跳转，这样执行时大概率只需要一个缓存行，大大提高了高速缓存命中率

因此扩展TSP得到ExtTSP模型，其不仅仅考虑基本块的执行频率，还考虑跳转的方向和跳转的距离（看有没有超出一个缓存行的空间）：
$$
F = \sum_{(s, t)} w(s, t) \times \begin{cases}
1, & \text{如果 } \text{len}(s, t) = 0 \\
0.1 \times \left(1 - \frac{\text{len}(s, t)}{1024}\right), & \text{如果 } 0 < \text{len}(s, t) \le 1024, \text{并且 } s < t \\
0.1 \times \left(1 - \frac{\text{len}(s, t)}{640}\right), & \text{如果 } 0 < \text{len}(s, t) \le 640, \text{并且 } t < s \\
0, & \text{其他情况}
\end{cases}
$$

1. len=0 (直通)：系数为 1（最高分）。表示 $s$ 和 $t$ 物理相邻，不需要跳转指令，性能最好。

2. **s < t (前向跳转)**：系数随距离增加而衰减。最大距离限制为 1024 字节。表示虽然不相邻，但距离较近的前向跳转也是可以接受的，优于远距离跳转

3. **t < s (后向跳转/回边)**：通常对应循环。系数随距离增加而衰减。最大距离限制为 640 字节。后向跳转通常对距离更敏感（例如为了适应循环缓冲 Loop Buffer），所以距离容忍度更小（640 < 1024）

4. **其他**：距离太远，系数为 **0**。对性能提升没有贡献

```c++
Function ReorderBasicBlocks
    for v ∈ V do // 为每一个定点生成一个链，完成后，每个链仅仅包含一个定点
        Chains <- Chains U {v};
    // 当链的个数大于1则进行链合并，最后只有一条链，这个链就是排序后的结果
    while |Chains| > 1 do
        for ci, cj ∈ Chains do // 在所有链中选取出两个链，计算合并后的分值
            gain[ci, cj] <- ComputeMergeGain(ci, cj);
        // 选择合并分值最高的两条链进行合并
        src, dst <- max gain[ci, cj];
        // 合并两条链为新的链，并将原来的两条链删除
        Chains <- Chains U Merge(src, dst) - {src, dst};
    // 只有一条链，链中基本块的顺序就是最后的顺序
    return ordering given by the remaining chain;

Function ComputeMergeGain(src, dst) // 计算两条链所有可能合并的分值，并选取分值最大的两条链合并
    // 将链 dst 合并到链 src 中。链 src 中的每一个基本块都要作为链 dst 的插入位置，以计算最大分值
    for i = 1 to blocks(src) do
        // 按照基本块的执行顺序将 src 拆分成 s1 和 s2，在序号 i 处打断链
        s1 <- src[1 : i];
        s2 <- src[i + 1 : blocks(src)];
        
        score_i = max {
            ExtTSP(s1, s2, dst), if Entry ∉ dst
            ExtTSP(s1, dst, s2), if Entry ∉ dst
            ExtTSP(s2, s1, dst), if Entry ∉ s1, dst
            ExtTSP(s2, dst, s1), if Entry ∉ s1, dst
            ExtTSP(dst, s1, s2), if Entry ∉ src
            ExtTSP(dst, s2, s1), if Entry ∉ src
        }
    // 返回合并两条链后的净收益
    return max(score_i) - ExtTSP(src) - ExtTSP(dst);
```

**可以看到src链在与dst链合并时，它进行src链基本块的遍历来进行拆分成两个子链s1和s2，6种组合进行比较取max求最优解（使用之前的公式，算执行频率和两个基本块间的跳转方向和跳转距离）**

而TSP不会拆分链，只是将链的头部和尾部计算合并后的分值进行比较

因此ExtTSP效果更好，但是计算量相应增大，为O(V^5)

参考原始论文 `A Newell and S. Pupyrev, Improved Basic Block Reordering`



### 11.4.2 公共代码提取

指的是**将多个函数中的公共代码片段提取成一个新函数，然后将多个函数中的公共代码片段删除，再调用新函数**

该优化和函数内联刚好相反，所以也称为**外联**

和内联的作用相反，该优化会**降低性能（由于增加了函数调用，调用中可能需要生成函数栈帧相关指令）**，但是会减少代码，所以该优化通常是Os优化等级的组合选项之一，也可以通过enable-machine-outline=always在其他编译级别中启用

其中**对函数末尾相同几行进行公共代码提取，相应的调用指令使用了jmp而不是call**，这是因为进行了尾代码合并优化（因为`funcA`和`funcB`最后几行相同，进行了提取。那么调用时不需要将返回地址压栈和出栈（这样既浪费时间也浪费栈空间），因为后续没有什么指令要执行了，函数最后一个指令是调用指令，调用只需要进行跳转到别的函数执行完，然后不需要再回到`funcA`或`funcB`了，直接返回上一级即可）【`jmp` 指令不会将返回地址压栈。这意味着，当 CPU 跳转到 `OutlinedFunc` 时，栈顶存放的依然是 `funcA` 的返回地址（即当初是谁调用了 A，A的上一级）】

代码提取后还需要考虑在提取的新函数中插入函数栈帧、ret指令等，所以公共代码提取一定要判断收益



代码本质上可以看成字符串，将多个函数组合成一个大的字符串，然后在这个大字符串中寻找重复的代码片段即子串，所以就转换成了大字符串中寻找公共子串的问题（可以使用动态规划、后缀树等方法进行求解，其中后缀树需要较多的内存空间但查询性能优异）

1. **后缀树**

   **后缀树是指字符串的所有后缀子串构成的树形数据结构**

   * 多个字符串可以共享存储空间：例如abc、ab，由于前者包含后者，当两个字符串共享存储空间时，只需要存储字符串abc即可

   * 但是当遍历abc时无法确定它包含了ab，所以为每一个字符串添加一个显示的结束标记符$，这样就变成了ab$和abc$，当共享存储空间时，还能确定每一个独立的字符串，参考图11-31 p358

   * 由于大量节点仅包含一个输入边和输出边，所以可以将这些节点进行压缩

     压缩的后缀树在寻找字符串的公共子串时有非常好的效果

     在后缀树中，从Root节点到任意一个中间节点的字符串都是公共子串（此处中间节点指的是有一后继分支走向$），如图11-33

   构造好后缀树后，**只需要寻找root到中间节点的路径即可找到公共子串**（如ab$、abcab$，则其公共子串就是ab）；如果再辅以字符的位置信息，则还可以很容易定位每一个公共子串的位置信息

2. **为每个函数的指令构造后缀树**

   如果直接以函数代码作为字符串构造后缀树，性能会比较差，主要原因是函数代码中的一条指令包含多个字符，会产生大量冗余

   LLVM的公共代码提取会首先对指令进行处理：

   1. **为每一条指令进行编号**，将指令序列变成指令编号序列，同时**用一个<指令，编号>二元组保存**，在为指令编码时首先查询指令是否已经编号，如果已经编号则直接使用编号，这意味着该指令和前面已经完成编号的指令重复（前面出现过）

      出现**负编号的指令表示不能作为公共指令**

   2. 然后基于编号构建后缀树，寻找公共子串
   3. 接下来公共代码变成函数，并设置函数属性，活跃寄存器信息（LiveIn、LiveOut）、函数栈帧构建、调试信息、ret指令等
   4. 最后在原来函数中删除公共子代码片段，并使用call指令调用新函数或者jmp指令直接跳转新函数



### 11.4.3 函数冷热代码分离







