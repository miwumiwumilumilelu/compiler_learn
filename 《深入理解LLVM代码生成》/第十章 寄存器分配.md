# 第十章 寄存器分配

不同存储介质成本和访问速度不同，采用**层次化存储结构**来让计算机既能高速访问存储又能保持高性价比

程序中定义的访存变量个数远大于寄存器的个数，大多数硬件体系结构在程序执行时总是需要将变量放入寄存器。**将程序执行过程中的访存变量都映射到寄存器中**，这个过程称为**寄存器分配**



LLVM中寄存器分配阶段目的：将MIR中使用的虚拟寄存器映射到目标机器的物理寄存器上

1. 当存在可用的物理寄存器时，将变量映射到物理寄存器中
2. 当没有可用的物理寄存器时，进行**溢出**，即将已经分配寄存器的变量重新放入内存中，得到一个空闲的寄存器，并为当前变量分配寄存器

LLVM中，寄存器分配共**4种分配算法**：

1. **Fast：**默认在O0优化级编译下使用，以**函数为粒度**进行寄存器分配，每个基本块都可以使用全部的物理寄存器。并不考虑变量的活跃区间，遇到变量无法分配的情况则溢出

2. **Basic：**以**函数为粒度**进行寄存器分配，**基于变量活跃区间**进行寄存器分配

   首先对活跃区间按照权重排序

   按照权重**从高到低**逐一分配：

   ​	如果可以为虚拟寄存器分配物理寄存器，则直接分配；

   ​	如果不可以，则选择虚拟寄存器暂存在栈中，并将使用虚拟寄存器的地方重新插入加载指令（从栈中加载数据）

   实验性质的寄存器分配算法，并不用于生产环境中，而是**用于性能基准测试和比较新型寄存器分配算法**

3. **Greedy：**LLVM默认的分配器，以**函数为粒度**进行寄存器分配。和Basic相比，其在寄存器溢出实现上更为复杂，其**目标是生成最小溢出成本的代码**

4. **PBQP：**以**函数为粒度**进行寄存器分配，通过构造一个PBQP来表示寄存器分配问题（**将活跃变量区间等约束转换为方程组**）

   然后通过对PBQP求解来获得结果，再将求解结果映射回寄存器分配



## 10.1 寄存器分配流程解析

寄存器分配需要依赖一些前置Pass，按照实现的依赖特性划分为两类，Fast算法是单独一类，其他三种算法是另一类

### 10.1.1 Fast

`PHI Elimination——>Two Address Instuction——>Fast寄存器分配`

仅依赖以上两个Pass，且不需要依赖变量的生命周期



### 10.1.2 Basic

```
+--------------------------+  +--------------------------+  +--------------------------+
| 寄存器分配的前置依赖Pass |  | Basic算法的独有依赖      |  | 寄存器分配后优化的Pass   |
+==========================+  +==========================+  +==========================+
| Dead和Undef寄存器检测    |  | 调试信息分析             |  | 栈槽着色分配             |
|           ↓              |  |           ↓              |  |           ↓              |
| 隐式定义指令处理         |  | 指令编号                 |  | 寄存器分配后重写处理     |
|           ↓              |  |           ↓              |  |           ↓              |
| 不可达基本块消除         |  | 活跃变量区间分析         |  | 机器复制传播             |
|           ↓              |  |           ↓              |  |           ↓              |
| 活跃变量分析             |  | 寄存器合并               |  | 机器公共子表达式消除     |
|           ↓              |  |           ↓              |  |           ↓              |
| 循环信息分析             |  | 机器指令调度             |  | 机器循环不变代码外提     |
|           ↓              |  |           ↓              |  +--------------------------+
| Phi消除                  |  | 活跃栈变量分析           |
|           ↓              |  |           ↓              |
| 活跃变量区间分析         |  | 别名分析结果使用         |
|           ↓              |  |           ↓              |
| 二地址指令变换           |  | 支配树分析               |
|           ↓              |  |           ↓              |
| 寄存器合并               |  | 循环信息分析             |
|           ↓              |  |           ↓              |
| 无父子寄存器重命名       |  | 虚拟寄存器映射组合信息   |
|           ↓              |  |           ↓              |
| 机器指令调度             |  | Basic寄存器分配算法      |
+--------------------------+  |           ↓              |
                            | 寄存器重写预处理         |
                            |           ↓              |
                            | 虚拟寄存器映射           |
                            |           ↓              |
                            | 寄存器分配评价           |
                            +--------------------------+
```



#### 10.1.2.1 前置依赖分析Pass

1. **Dead 和 Undef 子寄存器检测（`Detect Dead Lane`)**

   对指令进行分析获得子寄存器状态

   **子寄存器**：在CPU中，一个大的物理寄存器通常可以被分解成几个更小的部分来独立访问

   `EAX`, `AX`, `AL` 都是`RAX`的**子寄存器**

   在一些涉及子寄存器使用指令的场景中，指令序列可能存在寄存器死亡或者未定义的情况：

   * 检测到死亡寄存器，其活跃区间变小，更容易合并寄存器；

   * 检测到未定义寄存器，其不用做额外处理，在寄存器分配时选择一个可用的物理寄存器即可；

2. **隐式定义指令处理（`Process Implicit Def`）**

   将所有用到隐式定义的指令的地方设置为Undef（未定义），并且**删除该指令**；在寄存器分配阶段简化**设置为Undef的寄存器**的分配过程

3. **不可达基本块消除（`Unreachable Machine Block Elim`）**

   对MIR进行不可达代码消除，并要保证程序的正确性不被影响，不可达基本块通过分析CFG得到

4. **活跃变量分析（`Live Variables Analysis`）**

   在寄存器分配阶段**仅对活跃变量进行分配**，不活跃变量不需要进行寄存器分配

5. **循环信息分析（`Machine Loop Info`）**

   基于MIR 分析 函数中的循环，循环信息可用于后续的分析和优化Pass（例如基本块频率计算等）

6. **Phi消除（`Phi Elimination`）**

   MIR是SSA形式，存在ø函数，但没有硬件支持ø函数，所以需要将ø函数进行消除才能进行寄存器分配

7. **活跃变量区间分析（`Live Intervals Analysis`）**

   计算活跃变量的生命周期区间，只为生命周期区间内活跃的变量分配寄存器，如果变量不在活跃区间（变量生命周期区间不连续）内，说明此时变量不活跃，不需要进行分配

8. **二地址指令交换（`Two Address Instrucion`）**

   将三地址指令变换为二地址指令，因为一些硬件架构不支持三地址指令，该Pass是否执行取决于TD文件中二地址指令的定义（Constraints属性）

9. **寄存器合并（`Simple Register Coalescing`）**

   对MIR进行寄存器合并处理，指的是将虚拟寄存器在如`%1 = COPY %0`的情况下合并成一个虚拟寄存器，从而减少指令数量和使用的寄存器

10. **无关子寄存器重命名（`Rename Disconnected Independent Subregister`）**

    可能存在多个独立使用的子寄存器

    将子寄存器对应的虚拟寄存器重命名，以减少寄存器压力（为子寄存器分配不同的物理寄存器，以减少寄存器溢出的概率）

    该优化只适用于部分后端，只有在后端支持子寄存器，且子寄存器可以联合使用的场景才有意义

11. **机器指令调度（`Machine Instruction Scheduler`）**

    分析MIR中的数据依赖，按照指令调度算法对MIR重新排序，主要是为了减少寄存器压力



#### 10.1.2.2 不同分配算法依赖的Pass（Basic 为例）

1. **调试信息分析（`Debug Variables Analysis`）**

   因为寄存器分配时不会处理调试相关指令，防止影响寄存器分配

   * 在寄存器分配之前找到调试指令，并记录调试指令的作用域（即指令的活跃区间），然后删除调试指令

   * 在寄存器分配之后，根据调试指令的作用域重新插入调试指令（新插入的调试指令会使用已经分配的物理寄存器替换原指令的虚拟寄存器）

2. **指令编号（`Slot Indexe Analysis`）**

   为指令进行编号，指令的编号在活跃区间中使用

3. **活跃变量区间分析（`Live Interval Analysis`）**

   计算活跃变量的生命周期区间，供寄存器分配使用

4. **寄存器合并（`Simple Register Coalescing`）**

   对MIR进行寄存器合并处理，主要是为了优化ø函数以及二地址指令变换引入的大量COPY指令

5. **机器指令调度（`Machine Instruction Scheduler`）**

   分析MIR中的数据依赖，并按照指令调度算法重新对MIR进行排序

6. **活跃栈变量分析（`Live Stack Slot Analysis`）**

   栈变量是指在溢出时被放入栈空间临时存放的变量，该Pass不需分析活跃变量，**只需分配数据结构，来记录寄存器溢出后虚拟寄存器和栈变量的映射信息即可**

7. **别名分析结果使用（`Alias Analysis Results Wrapper`）**

   使用别名分析的结果，确保移动后的指令正确（若指令使用的变量产生别名，则需在指令移动时确保变量不冲突）

8. **支配树分析（`Machine Dominator Tree`）**

   基于MIR 分析 函数中的支配树信息

   支配树不仅仅在循环信息分析中被使用，在后续多个Pass中也会被使用（例如移动指令时）

9. **循环信息分析（`Machine Natural Loop Analysis`）**

   基于MIR 分析 函数中的循环

10. **虚拟寄存器映射（`Virtual Register Map`）**

    记录寄存器分配过程中虚拟寄存器和物理寄存器之间的映射关系，分配之后进行虚拟寄存器的重写时会使用到这个信息

    不需要对指令进行真正分析，而**仅需分配相关数据结构的内存，用于记录寄存器分配过程中二者的映射关系**

11. **活跃寄存器组合信息（`Live Register Matrix`）**

    **记录虚拟寄存器分配信息**，包含了映射和溢出的栈位置信息，供分配之后虚拟寄存器重写使用

12. **Basic寄存器分配算法（`Basic Register Allocator`）**

    为指令中使用的虚拟寄存器分配物理寄存器，如果遇到无法分配的情况，**还需要选择合适的虚拟寄存器溢出到栈空间**

13. **寄存器重写预处理（`Hook point for PreRewrite`）**

    为不同的后端**提供挂载点**，**允许后端在寄存器映射之前做特殊处理**

14. **寄存器映射（`Virtual Register Rewritter`）**

    虚拟寄存器映射为物理寄存器，并重写指令

15. **寄存器分配评价（`Register Allocation Scoring`）**

    评价方式：计算寄存器分配后的各种指令的总成本，并在计算过程中为**不同的指令设置不同的权重**

    通过机器学习不断迭代以获取最优的寄存器分配结果



#### 10.1.2.3 分配后依赖的Pass

1. 栈槽着色分配（`Stack Slot Coloring`）

   遇到寄存器溢出情况，需要用到栈空间暂存变量

   如果两个栈变量的活跃区间不重叠，则可以重用一个栈槽空间

2. 寄存器分配后重写处理（`Hook Point for PostRewrite`）

   为不同的后端提供挂载点，允许后端在寄存器映射之后进行独有的处理

3. 机器复制传播（`Machine Copy Propagation`）

   在寄存器分配之后，会引入少量COPY指令，经过COPY指令的复制传播优化可以消除

4. 循环不变量外提（`Machine LICM`）

   在寄存器分配之后再次执行循环不变量外提，可能是机器复制传播等Pass执行后出现了新的优化机会



### 10.1.3 依赖 Pass 分类

1. 适用于所有后端的Pass：
   * 修改原始MIR或者生成新MIR的转换类Pass，例如ø函数消除、二地址指令转换等
   * 为寄存器分配算法运行提供用于数据分析的分析类Pass，例如指令编号、活跃变量区间分析
   * 用于资源分配的Pass，例如活跃栈变量分析、寄存器映射，机器指令调度等
2. 适用于部分后端的Pass：



## 10.2 寄存器分配涉及的Pass

### 10.2.1 死亡和未定义子寄存器检测

识别到死亡的寄存器可以不再分配物理寄存器；而未定义的寄存器则可以使用任意一个物理寄存器

```
%0 = soe definition
%1 = IMPLICIT_DEF
%2 = REG_SEQUENCE %0, sub0, %1, sub1
%3 = EXTRACT_SUBREG %2, sub1
	 = use %3
```

* 死亡寄存器检测：

  * 后向数据流分析

  * 没有被使用的寄存器则认为死亡，所以先识别使用中的寄存器，即**寄存器使用信息分析**

    * 从出口指令开始，%3被其他指令使用，所以%3使用的寄存器%2应该是活跃的
    * 但%3仅使用了%2的sub1部分，而%2是由 REG_SEQUENCE 指令定义的%0和%1构成，%0没有被使用，因此%0是死亡的

  * 本质是**活跃变量分析**的数据流方程

    `LiveIn(i)`: 在指令 `i` 执行前保持活跃的寄存器（及其子寄存器部分）

    `LiveOut(i)`: 在指令 `i` 执行后保持活跃的寄存器（及其子寄存器部分）

    `Use(i)`: 指令 `i` 读取的寄存器（及其子寄存器部分）

    `Def(i)`: 指令 `i` 写入的寄存器（及其子寄存器部分）

    * 基本块内传递方程:
      $$
      LiveIn(i) = Use(i) \cup (LiveOut(i) - Def(i))
      $$
      在一条指令之前是活跃的，要么是这条指令本身要用它，要么是它在指令之后也是活跃的且没有被这条指令覆盖

    * 指令间传递:
      $$
      LiveOut(i) = \bigcup_{s \in succ(i)} LiveIn(s)
      $$
      `succ(i)`: 指令 `i` 的所有后继指令

  * 例子分析：

    **`= use %3`**:

    - 这是分析的起点。这条指令使用了 `%3`
    - 因此，在它之前，`%3` 必须是活跃的
    - `LiveIn(use)` = `{%3:all}` (假设 `%3` 的所有位都被使用)

    **`%3 = EXTRACT_SUBREG %2, sub1`**:

    - 这条指令的 `LiveOut` 就是其后继 `use` 指令的 `LiveIn`。所以 `LiveOut` = `{%3:all}`
    - $Use$ = `{%2:sub1}` (只使用了 `%2` 的 `sub1` 部分)
    - $Def$ = `{%3:all}` (定义了整个 `%3`)
    - 应用基本块内传递方程
    - **结论**: 在这条指令之前，只有 `%2` 的 `sub1` 部分是活跃的

    **`%2 = REG_SEQUENCE %0, sub0, %1, sub1`**:

    - 这条指令的 `LiveOut` 是其后继 `EXTRACT_SUBREG` 指令的 `LiveIn`。所以 `LiveOut` = `{%2:sub1}`

    - $Use$ = `{%0:all, %1:all}`

    - $Def$ = `{%2:all}`

    - **分析死亡定义**: 这里的关键是判断定义 `Def` 是否真的“活”到了 `LiveOut`

      - `REG_SEQUENCE` 指令定义了 `%2` 的两个部分：`%2:sub0` (来自`%0`) 和 `%2:sub1` (来自`%1`)。
      - 我们检查 `LiveOut` 集合 `{%2:sub1}`。
      - `%2` 的 `sub1` 部分在 `LiveOut` 中，所以定义 `sub1` 的源操作数 `%1` 是**活的**。
      - `%2` 的 `sub0` 部分**不在** `LiveOut` 中，所以定义 `sub0` 的源操作数 `%0` 是**死的**。

      

* 未定义寄存器检测：

  * 前向数据流分析
  * 使用了隐式定义操作数的寄存器实际上是未定义的，即**寄存器定义信息分析**
    * %0被显示定义
    * %1是隐式定义
    * %2由两个寄存器构成，其中sub1是隐式定义
    * %3仅由%2的sub1部分构成，是隐式定义，这样的隐式定义就是未定义的
  * 本质是**到达定义分析**的数据流方程
    * 略

数据流方程具体参考3.3.1 & 3.3.2



### 10.2.2 隐式定义指令处理

隐式定义的寄存器一般是MIR中未定义的指令，在寄存器分配时需要将这些隐式定义指令删除，避免被其他指令使用

进行以下处理：

1. 如果隐式定义指令定义的寄存器是虚拟寄存器，则将Def-Use链中Use的MO（机器指令操作数）设置为`Undef`状态，同时对类COPY指令进行**复制传播优化**，即递归处理MO的定义寄存器（**传播`Undef`状态**）

   标记了所有使用点，定义点冗余了，然后删除该隐式定义指令

2. 如果隐式定义指令定义的寄存器为物理寄存器，如Def-Use链中Use的寄存器是Def的寄存器或子寄存器，则将Use的寄存器设置为Undef状态，然后删除该指令

3. **如果机器指令中所有MO即操作数都是未定义的，则删除该指令**

   相当于把垃圾搬到了垃圾堆，把垃圾堆删掉

因为隐式定义指令会被删除，而死亡和未定义子寄存器检测需要根据隐式定义信息计算出Undef状态的子寄存器，所以需要先执行死亡和未定义子寄存器检测，然后再执行隐式定义指令删除



### 10.2.3 不可达MBB消除

识别不可达MBB：

​	遍历CFG时，只要**能从Entry开始遍历到的MBB都是可达的**，遍历不到的就是不可达的

不可达的MBB属于**死代码**，当发现不可达MBB时，需要将其删除

如果不可达MBB属于循环，则删除MBB会影响循环结构，所以需要**在删除不可达MBB时 需要更新支配信息、循环结构以及影响的ø函数**



### 10.2.4 活跃变量分析

多个后续Pass直接依赖活跃变量分析，例如寄存器分配类Pass只针对活跃变量进行分配

活跃变量分析需要先找到那些在一条指令结束后立即无效（Dead）的寄存器集合，还需要找出那些在当前指令中使用，但执行这条指令后不再使用的寄存器集合（被当前指令杀死）

对虚拟寄存器和物理寄存器进行何时死亡、何时被杀死进行分析

**活跃变量分析不需要计算寄存器的Def和Use信息，因为MIR是SSA形式，天然包含这些信息**



LLVM采用**不动点算法，前向数据流分析**



规则如下：

1. 寄存器的活跃信息使用一个集合保存，**在集合中存放的是MBB**，表示寄存器在整个MBB都是活跃的
2. **如果寄存器在同一个MBB中定义和使用，在MBB外不再活跃，则不会存放在该集合中**？？？
3. 我们使用一个集合保存寄存器被杀死的信息，在集合中**存放的信息形式是MIR**，表示寄存器在此MIR后不会在被使用

3. **如果ø函数是最后使用寄存器的指令，这条ø函数不会出现在保存杀死信息的集合中**

4. 如果寄存器在同一个MBB中被定义和使用，并且仅在后继基本块的ø函数中被再次使用，则会出现寄存器活跃集合为空，同时寄存器的杀死信息集合也为空的情况

   这是因为寄存器在MBB的最后一条指令仍然都是活跃的，但是在进入后继基本块后不再活跃



实现：

1. 以函数为粒度，依次处理每个MBB中的基本块

2. 遍历MBB中每条机器指令，收集指令中的Def和Use寄存器，**如果是ø函数，仅仅收集Def寄存器**

3. 对所有的Use寄存器进行处理：

   * 通过不动点方式遍历虚拟寄存器前驱基本块
   * 将其前驱基本块加入寄存器的活跃集合中，直到遍历所有的前驱基本块
   * 物理寄存器则还需额外处理其子寄存器

4. 对所有的EC寄存器进行处理：处理物理寄存器可能发生EC的情况

5. 对所有的Def寄存器进行处理：

   虚拟寄存器默认先定义后使用，使用以后寄存器会被杀死

   （所以需要先处理Use，这样**保证最后杀死的信息总是指向最后一条指令**）

   物理寄存器也类似处理其子寄存器

**对于机器指令出现的物理寄存器处理稍微不同：**

1. 在指令选择过程中会生成MBB的LiveIn和LiveOut，二者主要是物理寄存器

   LiveIn通常是放置在寄存器中的函数参数

   LiveOut通常是放置在寄存器中的返回值

   在活跃区间分析时，我们通常会设定一个虚拟指令来定义LiveIn值；如果基本块最后一条指令是return，那么它将被标记为具有LiveOut属性

   LiveIn和LiveOut集合会影响活跃变量的计算

2. 假设物理寄存器只在单一的基本块上存活，则针对局部进行分析

3. 有些物理寄存器不是可分配的（例如栈指针寄存器和条件码寄存器），这些寄存器不会被分析，只在指令选择阶段进行构建

4. 物理寄存器在处理Def和Use时需要考虑子寄存器情况



### 10.2.5 Phi 消除

后端没有支持phi函数生成的机器代码，因此这个Pass所有后端都需要

1. LLVM并没有像Briggs算法一样考虑Swap问题，因为其**不接受ø函数存在循环依赖**的情况，LLVM后端会拒绝为这样的IR生成代码

   这意味着ø函数析构时不需要考虑Swap问题

2. Sreedhar算法LLVM也尝试过，不过因为缺乏维护者，且算法不稳定，所以放弃

3. ø函数析构中，通过参数选项来控制是否执行关键边拆分

   **中断优化中，通常会执行一些优化（如部分冗余消除、循环优化等）来进行关键边拆分，那么此处有必要进行关键边拆分吗？**

   ： LLVM可以接受没有优化的IR作为后端输入，其可能仍存在关键边；其次，指令选择阶段完成后会执行尾代码重复优化等，会改变CFG结构，引入新的关键边

   **为什么提供控制来选择是否拆分关键边，不拆分也没事？**

   ：进行关键边拆分可以为`COPY`指令提供一个孤立的“家”，这可以**缩短寄存器活跃区间**，从而帮助寄存器分配器更好地进行**寄存器合并**并减少寄存器分配过程中的溢出，书中用两个例子来进行比较p247



ø函数消除会新增COPY指令，其等价于引入新变量，意味着执行ø函数消除后很多之前的分析都会无效，如活跃变量、指令编号、变量活跃区间、支配树信息等。**为了减少重复计算和分析这些信息，可以在ø函数消除插入COPY指令的过程中增量更新这些分析信息**



拆分策略：

1. LLVM并不处理循环体中的关键边，因为**循环关键边拆分后会引入新的跳转指令，对代码布局不友好**

2. 在非循环的关键边拆分过程中，如果ø函数引用的变量在关键边对应的前驱基本块的LiveOut中，则不需要拆分关键边

   这是因为：ø函数不会影响变量活跃区间，LiveOut存在，则说明相关变量还会被其他指令使用。即便对关键边进行拆分，在引入的新基本块中插入COPY指令，该指令定义的变量仍是活跃的，仍不会有助于寄存器合并

   `v3 = PHI(v1 from P, ...)`插入`COPY v3, v1`

   拆分关键边的主要收益是缩短`v1`的活跃区间。但如果`v1`因为其他原因，其活跃区间本来就需要延伸到`P`块之外，那么拆分边并把`COPY`放在一个新块里，并不能让`v1`的活跃区间变得更短

3. 如果ø函数中引入的变量不在当前基本块的LiveIn中，说明变量仅仅在其他前驱中活跃。因为变量活跃区间并不冲突，无需拆分

4. 如果ø函数中引入的变量在当前基本块的LiveIn中，则进行关键边拆分

5. 如果进行了拆分，则需要更新活跃变量和活跃变量的活跃区间



### 10.2.6 二地址指令变换

除`函数调用、ø指令`等，**机器指令都是三地址码**

这说明每一条指令最多两个源寄存器并定义一个目的寄存器



为了处理一些目标架构指令集所使用的二地址码指令，LLVM后端需要将三地址码指令转换为二地址码指令

**该Pass执行后，输出的MIR不再是SSA形式**

如:

```
%a = ADD %b, %c

变为

%a = COPY %b
%a = ADD %a, %c
```



以函数为粒度

只有部分MIR指令才需要执行二地址转换（定义在TD文件中，使用`Constraints`来指定哪些指令需要变换，还指定了该如何变换）

对于Constraints约束的指令，**TableGen在处理TD代码时，会为对应的指令生成TiedOperand属性**。
在**指令选择阶段**生成相关的指令时，会**根据指令属性为对应的操作数添加TiedOperand属性**。
这样二地址变换阶段**只需要考虑MIR指令中操作数的属性**就行了。



10.2.6.1 LLVM中二地址变换的执行流程

1. 预处理：将LLVM支持的特殊指令变换成COPY指令；对所有的COPY指令进行收集，便于后续处理COPY链指令
2. 收集MIR中存在TiedOperand属性的操作数：这些操作数包含了可以共用的寄存器，这意味着要插入COPY指令
3. 确认是否需要进行二地址指令变换：看能否取得更好的性能
4. 变换指令：为包含TiedOperand属性的操作数插入COPY指令，同时更新变量活跃区间
5. 后处理：把LLVM中的特殊指令转换为COPY指令，并更新变量活跃区间



10.2.6.2 在二地址变换时的注意点

MIR进行变换需要看TD文件基于指令的isCommutable和isConvertibleToThreeAddress的值来确定是否可以进行二地址指令变换和三地址指令变换

判断能否有利于指令调度优化，从而减少COPY指令生成。例如将待转换指令和最后一条使用该指令的Def寄存器的指令放在一起，这样对寄存器合并更友好



10.2.6.3 LLVM中二地址指令变换的实现

* `vreg0 = opcode vreg1(tied), imm/vreg`

  ```
  vreg0 = COPY vreg1
  vreg0 = opcode vreg0, imm/vreg
  ```

* `vreg0 = opcode vreg1(tied), killed vreg2`

  ```
  vreg0 = COPY vreg2
  vreg0 = opcode vreg1(tied), vreg0
  ```

* `vreg0 = opcode killed vreg1(tied), killed vreg2`

  判断用哪个替换vreg0收益更大：

  1. 确定vreg1和vreg2属性，比较它们的定义位置（较短的生命周期vreg更有吸引力）
  2. 满足收益条件可以进行指令变换，用一个vreg替换vreg0；不满足直接放弃替换

* 后端特殊约定指令，需要进行特定变换

  如：

  `A = SHRD16rri8 B,C,I`——>`A = SHLD16rri8 C,B,(16-I)`



### 10.2.7 指令编号

寄存器分配是基于活跃变量的生命周期，在**计算生命周期之前**需要给每一条指令（MIR）进行编号，之后**基于编号计算变量的活跃区间**

**指令编号逻辑：**

对MachineFunction中的基本块进行遍历，对基本块中的每一条MIR进行编号

其中

1. **特殊机器指令处理：**

   * 在寄存器分配时会将调试指令等特殊指令删除，因此这类指令不需要编号

   * MIR中的MBB承担了管理数据结构的责任，**为MBB赋值一个编号，可以方便计算其他机器指令的范围**

2. **指令编号间隔：**

   * 通常为每一条机器指令编号时，一般按照顺序增量编号，但**在后续的编译优化、指令调度等处理中可能会添加新的机器指令**

     假设为每一条机器指令顺序编号，**则每次添加指令以后都会导致重新计算指令编号**（因为遍历的活跃区间是根据指令编号计算得到的）

   * 为了尽可能地减少添加指令、重新计算指令编号的影响，在编号时并不是顺序编号，而是间隔一定的数量，如4：

     **当要插入新的指令总是从间隔中间开始插入**，所以这个间隔能保证插入的两条新指令都不会与原来指令编号冲突

     另外，在插入超过两条的新指令后，可以从相邻的指令开始调整指令编号，而不是从第一条指令开始调整

3. **指令状态：**

   LLVM为每条指令实现了4种状态——`Slot_Block`基本块、`Slot_EarlyClobber`定义完成前使用、`Slot_Register`寄存器、`Slot_Dead`死亡

   因此每一条指令之间的编号间隔可以从4扩展到16（4x4，每条指令都可能有4种状态）

综上所述，该Pass后的IR会显示0B 16B 32B等标记



### 10.2.8 变量活跃区间分析

**寄存器冲突：**

在寄存器分配过程中所有的物理寄存器都分配完毕（映射一个变量），此时如果有新的变量需要分配寄存器，但是该变量和所有已经分配寄存器的变量都产生活跃区间的重叠或部分重叠，则无法为新变量分配寄存器

此时必须在已经分配的寄存器中挑选一个并将其值暂存放在栈中，这个过程称为**寄存器溢出**



### 10.2.9 寄存器合并

寄存器分配前进行合并优化

由于一些优化Pass，使得产生大量COPY伪指令，此时需要进行合并来消除COPY指令



寄存器不能合并的情况：

1. 存在寄存器冲突，即两个寄存器同时活跃（但可以尝试通过消除冲突来进行合并）
2. 寄存器合并后活跃区间变大，会和其他寄存器活跃区间重叠的概率更高，导致寄存器分配过程中发生寄存器溢出



由于MIR此时已经经过指令选择阶段，此时既存在物理寄存器又存在虚拟寄存器，则需要分别进行处理

**大体实现如下：**

1. 对基本块进行排序，优先处理循环内的基本块（显然循环内的基本块执行寄存器合并获得的效益更高，所以**会按照循环层次对基本块排序**）—— 保证执行效率高的指令能够优先获得执行机会

2. 如果源寄存器和目的寄存器都是物理寄存器，则寄存器不能合并！

   因为**要符合ABI约定**，在指令选择阶段已经指定好了这些物理寄存器

3. 如果源寄存器和目的寄存器中有一个是物理寄存器、另一个时虚拟寄存器，此时可以尝试进行合并

   若不存在寄存器冲突，LLVM就会使用**物理寄存器替代虚拟寄存器**

4. 如果源寄存器和目的寄存器都是虚拟寄存器，当两个寄存器不冲突时可以直接合并，若存在冲突，在满足以下条件情况下仍能进行合并：

   * 源寄存器和目的寄存器可以复制使用，主要指的是：源寄存器和目的寄存器相同，源寄存器和目的寄存器使用了子寄存器且子寄存器相同

   * 两条不同的COPY指令使用了相同的源寄存器，且两个目的寄存器的活跃区间相同，则可以删除一条COPY指令（本质上就是两个目的寄存器进行了合并）

   * 定义了Implicit-Def属性的ø函数可以移除虚拟寄存器，所以需要执行寄存器合并操作

   * 其他一些复杂场景，例如由于子寄存器导致的活跃区间冲突，但是子寄存器没有使用等场景下可以进行合并寄存器

     如：

     考虑合并`COPY %vreg_eax, %vreg_al`。`%vreg_eax`代表一个32位值，`%vreg_al`代表一个8位值

     ```
     ... = some_instr %vreg_eax   ; %vreg_eax 在这里活跃
     ; (假设 %vreg_al 在这里不活跃)
     ...
     COPY %vreg_eax, %vreg_al    ; %vreg_al 在这里活跃
     ```

     如果编译器发现，`%vreg_eax`的生命周期中，真正“活跃”的只有它的低8位（即`AL`部分），而它的高24位要么是`undef`，要么后续从未被读取过。那么，它与`%vreg_al`的生命周期就没有发生真正的冲突

   虚拟寄存器合并方法：**将目的寄存器用源寄存器替代，同时更新源寄存器的活跃区间**



**合并过程如下：**

找到COPY指令然后判断是否可以合并，例如指令`%1:gpr = COPY %9:gpr`

尝试将该指令的%1合并到%9，由于二者都是虚拟寄存器，所以需要判断两个寄存器的活跃区间是否冲突

由活跃区间分析Pass得到的结果可得，%1与%9的活跃区间分别是[80r,224r:0)[336B,352r:0)和[48r,64B:0)[64B,80r:2)[304r,336B:1)

可以看出并不冲突，所以可以合并%1和%9

合并动作包括三步：

1. 删除该COPY指令

2. 使用%9替换所有%1的指令

3. 更新%9的活跃区间，即更新为[48r,64B:0)[64B,224r:2)[304r,336B:1)[336B,352r:0)

   此处要考虑到不是简单的集合并集，而是要考虑完成区间合并，即[80r,224r:0)[64B,80r:2)——>[64B,224r:2)

| **标记**   | **含义**           | **详细解释**                                                 |
| ---------- | ------------------ | ------------------------------------------------------------ |
| **`B`**    | **Block (基本块)** | 这个标记点代表一个**基本块（MBB）的边界**。`64B` 指的不是指令`64`本身，而是紧挨在指令`64`**之前**的那个程序点，即`MBB`的入口。它用来表示一个变量在**整个基本块**的开头就是活跃的 |
| **`r`**    | **Read (读取)**    | 这个标记点代表一条指令**正在读取（使用/use）\**这个寄存器的值。`80r` 指的是在指令`80`处，有一个`use`操作。一个`r`点通常是一个活跃区间的\**终点**，表示“这个值在这里被用完，生命周期到此结束” |
| (隐式) `d` | **Define (定义)**  | 虽然例子中没写，但一个区间的**起点**通常是一个**定义点**。例如，`[48d, ...)`。在LLVM的表示中，如果一个区间的起点没有特殊标记（如`48`），它就默认是一个定义点。`COPY %1, %9`这条指令在它的位置（比如`80`），既是`%9`的一个`use`点，也是`%1`的一个`def`点 |



### 10.2.10 MBB的频率分析

不可避免存在寄存器溢出问题，其溢出成本依赖于指令的执行频率

指令执行频率越高，其涉及的变量越应该保留在寄存器中，那么程序执行的效率将越高

**指令的执行频率和MBB的执行频率完全一致（根据MBB的定义）**，一个基本块中的指令会顺序依次全部执行，所以问题转换为求解MBB的执行频率



求解MBB执行频率的两种方式：

1. 通过perf等工具**为LLVM IR添加元数据**，元数据中包括了分支、循环指令执行的频率，用元数据中的数据计算出MBB的执行频率

   更精确，但过程冗长，需要执行程序并收集数据，再转换为元数据注入IR

2. 根据程序的结构，设计启发式算法“猜测”MBB的执行频率

   存在较大误差，但简单

   * **程序的结构分为3种：**

     1. **顺序：**顺序执行的基本块权重一致

     2. **分支：**主要有if和switch两种，以if分支为例，静态预测（方法2这个启发式方法）并不知道两个分支执行的概率情况，**所以会认为两个分支的执行概率相同**，所以分支会均分父节点权重

        而switch转换的case也一样均等概率，均分权重

     3. **循环：**一般来说，**循环体执行的次数更多，所以循环体应该有更高的权重**，在静态预测中，统一设置循环体的权重是**循环退出边权重的31倍**

        循环还需要考虑嵌套循环的处理，内部循环指令的权重比外部循环指令权重更高（因为执行次数更多）

   * **质量计算：**质量计算完成后会再将质量转换为频率

     在LLVM实现中，质量的计算有一个特点——每一层所有分支的质量总和等于父节点质量

     （质量用Mass表示，在分支概率计算中用Weight表示）

     在实现中**初始MBB质量为0xffff ffff ffff ffff（32位无符号最大值）**，按照以上介绍的3种结构进行处理并计算质量

   书p261-263，例子很清晰



为了体现内部循环的重要性，LLVM实现了稍微有点复杂的算法，算法大概步骤：

1. 针对待处理的函数体，以**RPOT（逆后序遍历）的顺序处理MBB**，主要是给MBB进行编号，确保遍历的执行顺序，同时初始化一些数据结构

2. 初始化循环信息，对函数中的循环信息进行提取。嵌套循环会使用嵌套的数据结构来维持嵌套信息

3. 计算循环中MBB的质量，分别计算循环体和循环退出边的质量。在计算过程中会使用预测分支概率或真实分支概率体现不同分支的权重

   因为RPOT，所以先处理内部循环，再处理外部循环

   处理循环时，需要把循环头的质量按照循环的结构传播到后继基本块中

   内部循环处理完后，折叠成外部循环的一个节点，同时保持一个折叠循环的缩放因子（缩放因子：每进入一次循环，循环体平均会执行多少次），用缩放因子表示内部循环不同分支的频率比值

4. 计算函数体中非循环结构MBB的质量

   1. 计算所有节点的频率，此时遍历是按照**后序遍历**的顺序。此时先处理外部循环，后处理内部循环。在遍历过程中会展开循环，将外部循环的缩放因子作为内部循环缩放因子的放大系数，并更新内部循环的缩放因子

      `Frequency(S) += Frequency(P) * BranchProbability(P -> S)`

   为了保证频率相对分散，设置了频率的最小值为8

5. 将频率归一化到整数进行保存，采用乘法、移位、除法等运算，所以计算结果为float，此时float转换为int数据保存



### 10.2.11 寄存器分配：直接分配与间接分配

* 直接分配中除了完成寄存器的**映射**外，还需要在分配过程中**处理溢出**的情况（溢出通常需要考虑插入 store/load 的位置）

  即直接分配把映射和溢出放在一起处理，从这个角度来看需要一次性处理的工作稍多

* 间接分配——本质上将映射和溢出分开

  一方面在寄存器分配过程中仅保留虚拟寄存器到物理寄存器的直接映射，并没有修改原指令；

  另一方面在处理溢出时考虑最优方案



对一个指令的虚拟寄存器按照变量的活跃区间计算权重，将权重由高到低排序，依次分配物理寄存器，其中规定返回值使用r0寄存器



### 10.2.12 将虚拟寄存器映射到物理寄存器

经过寄存器分配后，所有虚拟寄存器都会映射一个物理寄存器；且已经在合适位置插入st/ld指令处理了寄存器溢出

所以只需将指令中的虚拟寄存器替换成物理寄存器即可



按照映射替换即可，此外该Pass还有几个额外操作：

1. **更新基本块LiveIn信息**：根据活跃区间的覆盖范围计算**基本块LiveIn的物理寄存器**
2. **更新指令的属性**：对于使用子寄存器的指令，在替换为物理寄存器后需要重新更新指令中**操作数的属性**。因为在寄存器分配时，可能为虚拟寄存器分配更大的物理寄存器单元
3. **删除冗余COPY指令**：替换过程中可能产生COPY指令如`%r0 = COPY %r0`，进行删除



### 10.2.13 栈槽着色

其区别于9.3介绍的，那个主要用于分配栈变量，这个主要用于寄存器溢出场景

此处思路与9.3相同，唯一区别是此处需要考虑变量的权重

权重包含静态权重和动态权重：

静态权重——寄存器在分配过程中溢出变量的权重，**越大说明溢出成本越高**

动态权重——根据变量的执行频率计算得到，**越大说明执行过程中变量使用次数越多**

因此尽量少对权重大的变量栈槽作额外处理，尽量让其独占（惹不起）



栈槽着色算法实现如下：

1. 计算每一个栈变量的权重，并根据权重进行排序

2. 按照权重从大到小依次进行栈槽着色

   * 首先判断是否可以进行重用
   * 不能重用，则分配新的栈槽

3. 根据重新分配的槽位更新指令中操作数的信息

   此时槽位变换，指令操作数信息也需要跟着更新

4. 删除无用的槽位信息

5. 可以做一些更为激进的优化：如栈槽分配以后，源寄存器和目的寄存器共用同一个栈槽则可以进行删除；再如store执行以后的load指令都使用同一个栈槽，则store是死指令，可以进行store和load组合删除



### 10.2.14 复制传播

简单认为，复制传播是对COPY指令的窥孔优化

寄存器分配前会进行复制传播，此处是寄存器分配后进行，不再是SSA形式的指令，所以实现更复杂

1. **后向传播**

   针对基本块后向扫描，满足条件的MIR进行删除，**主要处理Def操作数**，当找到COPY指令，且COPY指令符合R1 = COPY R0形式，则满足以下条件可以进行COPY删除：

   1. 两条MIR之间（R0的Def - Use）没有指令对操作数使用过提前占用（early clobber）操作
   2. R1 和 R0 使用相同的寄存器类型

2. **前向传播**

   针对基本块前向扫描，满足条件的MIR进行删除，**主要处理Use操作数**

   可能场景：

   1. 当遇到**两条相同的COPY指令**，且中间没有操作对源寄存器进行覆盖（clobber）；**或存在两条构成循环的COPY指令**，这些指令在执行过程中没有提前占用源寄存器

      此时进行前向传播处理

   2. 当找到COPY指令后，在满足一定条件时可以替换寄存器。要求 源寄存器没有发生提前占用 且 源寄存器和目的寄存器类型相同，且目的寄存器是唯一的定义点

   

### 10.2.15 循环不变量外提

不能进行该Pass优化的情况如下：

1. 隐式定义的寄存器，并且不是死亡的
2. 定义的寄存器可以安全移动，且不能有负面影响，例如不包含volatile store/load、call指令，否则不能外提
3. 指令定义的寄存器在循环（多个基本块）中被重复定义
4. 从栈槽中进行读操作的load指令
5. early clobber定义的指令

此处Pass和循环不变量在SSA形式指令阶段有什么区别？

* 由于此时MIR不再是SSA形式，所以多次定义情况会被考虑，需要遍历整个循环来检查每个MIR定义的变量
* 在基于SSA形式下进行循环不变量外提时，外提操作有可能增加寄存器压力，所以对于循环不变量是否外提会有额外的控制机制。而此处只要识别到循环不变量都会外提



## 10.3 Fast 算法实现

仅有两个必需的Pass，即**ø函数消除和二地址指令变换**

以**基本块为粒度**进行分配

变量仅在当前基本块中活跃，跨基本块的变量通过**栈帧传递**

为虚拟寄存器分配好物理寄存器以后会直接修改原来的指令



### 10.3.1 Fast算法实现思路

为从一个基本块传递到其他基本块的活跃变量（LiveOut）插入store指令

并将该变量对应的寄存器存入栈中，从而确保下游基本块中所有的物理寄存器是可分配的

在下游基本块中，为来自其他基本块的活跃变量（LiveIn）插入load指令，并将这些变量从栈中加载到寄存器



**Fast算法具体实现如下：**

1. **先处理Def寄存器**

   * 如果Def用的是虚拟寄存器，对于首次定义的虚拟寄存器

     * 当有可用物理寄存器时则直接分配
     * 若没有可用的物理寄存器则进行溢出（要求溢出成本最低），然后再分配

     在寄存器分配过程中，若虚拟寄存器是跨基本块活跃的（即是当前基本块的LiveOut变量），则需要插入store指令

     **如果虚拟寄存器在后面的指令中被使用，且后续有reload指令，则说明此时发生了溢出，需要插入store指令，最后再为虚拟寄存器分配物理寄存器**

   * 如果Def用的是物理寄存器，则直接分配（如果指定的物理寄存器被占用，会尝试寻找下一个同类的物理寄存器；否则将会发生溢出）

2. **处理指令中的Use寄存器**

   * 特殊指令：

     * 例如Undef状态，**只需要取任意一个符合分配类型要求的物理寄存器即可，无须考虑物理寄存器是否空闲**
     * 例如，对于`op undef %x %x`，直接选择一个物理寄存器

   * 一般指令：

     如果虚拟寄存器是首次使用：

     * **试让COPY指令使用Def物理寄存器，若不能使用则进行寄存器分配**
     * 非COPY指令则直接进行寄存器分配（可能需要溢出）

     如果虚拟寄存器不是首次使用：

     * 说明指令中使用了至少两次该虚拟寄存器了，则直接使用已经分配了的物理寄存器即可

3. **收集源寄存器和目的寄存器相同的COPY指令，为后续的优化处理做准备**（寄存器全部分配完成后，删除冗余指令）

4. **当寄存器全部分配完成后，不再为前驱基本块的Bundle指令分配虚拟寄存器，直接使用已经分配的物理寄存器**

   **“Bundle指令”**：在LLVM的语境中，这几乎总是指那些为了消除`PHI`而**批量插入**到前驱基本块末尾的`COPY`指令

5. **处理每一个基本块的LiveIn变量，即插入Load指令将栈帧的数据重新加载到物理寄存器中**



Fast在分配过程中为什么采用逆序遍历基本块？

1. 从后向前处理，方便设置寄存器的活跃区间，为后续可能的优化提供帮助：

   如果Def寄存器不是跨基本块活跃，则一定是dead状态；

   如果Use寄存器不发生溢出、不跨基本块活跃，则一定是killed状态

2. 方便处理Bundle指令，已经为前驱基本块中Bundle指令相关的虚拟寄存器分配了物理寄存器，不需要再次分配

   当然，reload和spill指令的逆序遍历处理稍微复杂，其遇到Use时会假设来自栈上，会浪费空闲寄存器和产生大量store/load指令。在溢出物理寄存器时，要插入reload指令，而后在Def寄存器之后恰当的位置为物理寄存器插入spill指令（传统处理方法是在溢出点执行spill操作，在使用点执行reload操作）



### 10.3.2 示例分析 

p271-p275

以基本块bb.0.entry为例

```
%4:gpr = MOV_n 0
%7:gpr = COPY %4:gpr
%8:gpr = COPY %4:gpr
JMP %bb.1
```

逆序遍历，JMP %bb.1 不需要进行寄存器分配，无须进行额外处理

```
JMP %bb.1
```



`%8:gpr = COPY %4:gpr`对Def寄存器%8进行分配，按照TD文件定义的分配顺序选择物理寄存器

```
$r1 = COPY %4:gpr
STD killed %r1, %stack.1, 0
JMP %bb.1
```

选择r1物理寄存器，因为后续在bb.1.for.cond中会被使用，所以进行加载进栈处理（跨基本块进行栈帧传递）

`STD`即store，这里的`killed`是因为此指令之后不再使用r1，因此设置为killed状态，意味着其可在后续再次分配（此处killed看当前基本块逆序遍历该指令之前遍历到的指令（也就是此指令之后）有没有定义这个r1）

接下来是该指令中的Use寄存器%4分配物理寄存器，因为是COPY指令，在后续优化中可以进行冗余删除，所以尽可能使用已经分配过的物理寄存器；且r1是可以被分配的，所以优先为%4分配寄存器r1。此外，后续基本块不再使用%4，即此指令后r1不再活跃，所以r1设置为killed

```
$r1 = COPY killed $r1
STD killed %r1, %stack.0, 0
JMP %bb.1
```



`%7:gpr = COPY %4:gpr`同理进行处理

```
$r2 = COPY %r1
STD killed $r2, %stack.1, 0
$r1 = COPY killed $r1
STD killed %r1, %stack.0, 0
JMP %bb.1
```



`%4:gpr = MOV_n 0`%4由于已经分配了物理寄存器，则无须再分配处理

MIR对应寄存器分配完成后得到：

```
$r1 = MOV_n 0
$r2 = COPY $r1
STD killed $r2, %stack.1, 0
$r1 = COPY killed $r1
STD killed %r1, %stack.0, 0
JMP %bb.1
```



此时进行冗余COPY指令删除：

`$r1 = COPY killed $r1`删除

最终得到：

```
$r1 = MOV_n 0
$r2 = COPY $r1
STD killed $r2, %stack.1, 0
STD killed %r1, %stack.0, 0
JMP %bb.1
```



其中注意区分

1. 源寄存器在后续基本块中或当前基本块当前指令之后的指令被使用

   ```
   $r1 = COPY $r1
   STD $r1, ...
   ```

2. 源寄存器不在后续基本块中或当前基本块当前指令之后的指令中被使用

   ```
   $r1 = COPY killed $r1
   ```

3. 目的寄存器在后续基本块中被使用且逆序遍历该指令之前的指令不再使用$r1

   ```
   $r1 = COPY (killed) $r1 ;这里先不关心killed
   STD killed $r1, ...
   ```






## 10.4 Basic 算法实现

以**线性扫描为基础的**寄存器分配算法是LLVM最重要的分配算法

Basic 和 Greedy算法均以线性扫描为基础，其中Basic展示了如何基于LLVM变量活跃区间实现寄存器分配，因此也作为寄存器分配算法性能的基准

### 10.4.1 Basic算法实现思路

**分配和溢出处理**

* **分配思路：**
  1. 寄存器分配以函数为粒度
  2. 计算函数中活跃变量以及变量的活跃区间
  3. 计算变量区间的权重（让权重高的变量优先分配，权重低的变量后分配，这样能保证寄存器溢出时整体溢出成本最低）
  4. 按照权重从高到低依次对变量的活跃区间进行分配
     1. 获取所有可以被分配的物理寄存器，依次尝试为虚拟寄存器分配物理寄存器
        * 如果物理寄存器空闲，则直接分配
        * 如果占用，则计算物理寄存器的活跃区间和待分配变量活跃区间是否冲突
          * 如果不冲突，则可以为变量分配该物理寄存器，并返回
          * 如果冲突，则无法分配物理寄存器，并且该物理寄存器不是ABI约定的寄存器，则将物理寄存器**加入优先待溢出的寄存器队列**中
     2. 使用优先待溢出的寄存器进行分配，如果发现**当前变量活跃区间的权重**大于**优先待溢出寄存器的权重（占用该物理寄存器的变量的活跃区间权重）**，则优先分配该物理寄存器给权重高的变量，并将已经分配了物理寄存器的活跃变量进行溢出
     3. 如果当前变量已经溢出，则说明无法完成寄存器分配
     4. 当前变量尚未溢出，则溢出当前变量，并且将**溢出过程中产生的新变量添加到待分配队列**
     5. 如果发生寄存器溢出，对溢出过程中**插入的代码位置进行优化**，保证溢出代码的成本最低

* **溢出处理思路：**

  1. 在Def寄存器处直接添加store指令，在Use寄存器前添加load指令

  2. 找到真正需要溢出的虚拟寄存器

     **主要考虑COPY指令，直接溢出最初定义处的虚拟寄存器，中间的COPY指令都变成load指令，这可以有效缩短变量的活跃区间**

  3. 判断使用虚拟寄存器的指令是否可以重新物化（即在Use处重新执行该指令，用新的虚拟寄存器存储结果）

     * 如果可以，则无须溢出虚拟寄存器，而是重新执行指令

       此时可以定义新的虚拟寄存器，这些新的虚拟寄存器重新物化后需要重新分配

     * 如果不可以，则仍然要溢出原来的虚拟寄存器

  4. 溢出时首先分配栈槽，并更新**栈槽的活跃区间**（其在后向优化中还会使用），然后遍历所有操作数

     1. 在Def处插入store指令
     2. 在Use处先生成一个新的虚拟寄存器，再插入load指令，最后使用新的寄存器重写/替换原始指令的Use寄存器



### 10.4.2 示例分析

P277-p288

**变量的活跃区间权重计算思路：**

首先计算每一个区间的权重，然后将该变量组成的多个区间权重进行累加，最后进行归一化处理

分配算法会根据**基本块执行的频率**来作为权重计算的依据

除了执行频率还会根据一些其他情况来调整权重的计算方式：

1. 如果发现指令**位于循环内并且变量活跃区间跨越基本块**，会将权重提升`3倍`（说明需要优先分配虚拟寄存器）

2. 如果指令**是COPY指令**，且在分配过程中**有提示**，可以稍微提升分配的优先级，将权重提高`%1`

   有分配提示的虚拟寄存器，应该尽量满足提示的要求，性能会更好

3. 如果指令有**可重新物化属性**，则将权重减少`50%`

   以低成本加载，说明即使溢出都可以压低成本，所以分配优先级放在后面

按照以上思路，计算权重并进行归一化后，从高到低排序进行分配

权重相同时，按照区间顺序进行排序



在**TD文件**中定义了相关后端的物理寄存器分配顺序

对于函数调用的指令，根据相关**后端的调用约定**，也会限定物理寄存器的使用（此时也要考虑到相关物理寄存器即使没有被使用也要被占用，因为调用约定决定，属于调用者保存寄存器）



LLVM实现溢出称为`InlineSpiller`，含义是在溢出处理中直接进行store和load指令的插入，而不是先暂存溢出指令，最后进行指令插入和替换

对于`%12:gpr = COPY %7:gpr`这种指令，%7溢出到栈槽，后续在如该COPY指令这个Use处只需变为`%12:gpr = LDD %stack.0 0`即可，不需要先加载到新生成的虚拟寄存器中后使用（进行了复制传播消除）

对于如%7这样的虚拟寄存器溢出后，使用点指令进行处理完后，对于新生成的虚拟寄存重新插入待分配队列中（**新增的虚拟寄存器权重应该无穷大**，因为是用于栈中重新加载数据，不可以再次溢出，若再次溢出会导致死循环）



另外，由于指令之间的编号默认间隔为16，当新插入一个指令时，其编号是足够的，无须再重新为指令进行编号，指令的活跃区间都不需要进行更新



`%11:gpr = LD_imm64 -4294967296`

因为BPF后端文件对LD_imm64指令做了标记，设置了重新物化属性，**所以暂时不处理该定义指令**

而是先处理两条使用%11的指令，在该指令之前进行新生成的虚拟寄存器重新执行上面的指令，如`%44:gpr = LD_imm64 -4294967296`，再将原先使用指令的%11替换为%44即可，并将%44插入到待分配队列

最后处理完所有使用处的指令后，删除定义处的指令

接下来处理待分配队列中的新增虚拟寄存器，方法同上



Basic最后还会针对**溢出指令进行优化**：

基于支配树进行

确保正确的前提下，**将溢出产生的store指令移动到执行频率低的基本块中**



思考——Basic算法的不足

因为调用约定导致有些物理寄存器被占用，但是调用函数仅两个入参，所以造成了占用但未使用的浪费情况，伴随而来的是寄存器的溢出，造成性能损失

本质上可以避免，需要对调用机制进行优化





## 10.5 Greedy 算法实现

寄存器分配算法在设计之初侧重于如何能够使所有变量都分配到寄存器中，尽可能少地溢出

实际上，寄存器分配过程中肯定会产生大量溢出，因此LLVM重心进行了微调，此时更侧重于如何才能**高效溢出**

Greedy算法在溢出前会尝试进行寄存器拆分（Spilt 和 Spilt2）

### 10.5.1 Greedy 算法实现思路

1. 计算活跃区间的权重，同Basic算法一样

2. 对活跃区间进行排序（同Basic一样，使用优先队列自动完成排序）

   在优先队列中，优先级高的活跃区间先分配，优先级低的活跃区间后分配

   Basic算法使用活跃区间的权重作为优先级，而Greedy算法**以活跃区间覆盖范围为基础，再辅以执行状态做调整**，最后以得到的结果作为优先级

   * 设计思路：活跃范围越广的变量（如全局）越优先分配，因为活跃区间越大则发生冲突的概率越大，优先分配可以减少大范围活跃区间溢出的概率；覆盖范围越小（例如局部变量）越后分配，因为发生冲突的概率小

3. Greedy算法在分配时，首先按照优先队列的顺序对活跃区间优先进行分配，当发生溢出时通过活跃区间的权重挑选溢出成本最小的变量进行溢出。如循环中使用的变量，其活跃区间可能比较小，但权重比较大（在计算权重时会对循环中的活跃区间进行权重放大），在无法分配寄存器时，需要找个物理寄存器中已被分配的权重低的变量进行溢出，空闲的让给权重大的变量

   Greedy 算法 与 Basic 算法最大的两个区别如下：

   * Greedy算法**将已经分配变量的溢出过程称为剔除**

   * Greedy算法会尝试对无法分配的变量进行拆分，**将一个变量变成两个或者多个变量，由此缩短变量的活跃区间，减少区间冲突，然后再分配**

4. 依次从优先队列获取活跃区间进行分配，获取物理寄存器分配顺序，根据分配顺序计算每一个物理寄存器和活跃区间冲突的情况

   1. 如果物理寄存器和变量活跃区间没有冲突，则直接分配
   2. 如果有冲突，比较变量活跃区间和物理寄存器中已经分配的变量活跃区间权重
      * 剔除，并将剔除的变量重新加入到分配队列，并为待分配变量分配该物理寄存器（待分配变量权重较高的情况）
      * or 重新计算待分配变量的优先级，并将待分配变量标记为拆分状态，重新插入到分配队列中（待分配变量权重较低的情况）
   3. 如果待分配变量是拆分状态，计算对变量拆分是否有收益
      * 如果有收益，则选择合适的算法进行拆分，将一个变量拆分成两个或者多个变量，同时先计算每一个变量活跃区间的权重，然后计算变量的队列优先级，再将变量插入到待分配队列中，然后重复分配过程
      * 如果没有收益，则进行溢出，在Def处插入store指令，并在使用处插入load指令，执行load指令插入操作会引入新的虚拟寄存器（store无须引入新的虚拟寄存器），需要重新计算活跃区间、队列优先级，并将新的虚拟寄存器插入到待分配队列，然后重复分配过程

Greedy算法额外包含了剔除和拆分操作

其中，剔除比较简单，拆分比较复杂



### 10.5.2 算法实现的核心：拆分

Greedy拆分方式分为两种：**局部拆分**和**全局拆分**

局部拆分主要处理活跃区间落在一个基本块的情况，需要对活跃区间或者单挑指令进行拆分

全局拆分主要处理活跃区间跨基本块的情况，需要对活跃区间或者单个基本块进行拆分



1. **单基本块局部拆分**

   局部拆分思路如下：

   1. 计算虚拟寄存器在基本块的信息，包括**指令数、定义点（Def）、使用点（Use）、循环信息**等
   2. 如果基本块中**Use的数量小于2**，则不会进行局部拆分，只有**一条Def-Use链的情况**也无须进行局部拆分，因为**强行拆分会导致成本高**
   3. 以虚拟寄存器的**Def、Use为依据**，假设每两条指令形成一个拆分区间，**计算区间已经分配变量的权重**，该权重记为**`GapWeight`**
   4. 针对待分配变量的新区间权重（记为**`EstWeight`**），如果其大于已经分配的GapWeight，说明该区间可以拆分，即将该区间已经分配的变量进行剔除
   5. 尽可能地扩大溢出区间。如果连续多个区间的权重都大于已经分配变量的权重GapWeight，说明**连续区间可以放在一起拆分**
   6. **拆分区间需要添加新的变量，并且更新变量的区间、权重，并且重写相关指令**
   7. 将新的变量重新插入到待分配队列，重新进行分配

   

   局部拆分：优先找一个权重更大的区间，然后对该区间尽可能地扩展，形成更大的空间（**以权重为依据，对权重最大的进行拆分!!!**）

   

   假设一个基本块：

   ```
   %var = ...
   ... = %var
   ... = %var
   ... = %var
   ```

   1个Def 3个Use

   仅演示一个物理寄存器R1进行分配，且R1已经分配给了两个变量——V1和V2 的情况

   **拆分R1的“时间表”：**

   * 1个Def 3个Use因此3条Def-Use链，形成3个区间，分别记为Gap1、Gap2、Gap3

     `Gap1`: 从 `Def` 到 `Use1`

     `Gap2`: 从 `Use1` 到 `Use2`

     `Gap3`: 从 `Use2` 到 `Use3`

     把`%var`的**整个生命周期**（`Gap1`+`Gap2`+`Gap3`）都塞进`R1`

   * 分别计算它们的权重，并和GapWeight（V1和V2 的权重）进行比较

     **检查`Gap1`**: 发现`R1`被`V1`占用了。

     - 比较权重：`Weight(%var)` > `Weight(V1)` 吗？

     **检查`Gap2`**: 发现`R1`是空闲的。

     - 比较权重：`Weight(%var)` > `Weight(Empty) = 0`。（显然成立）

     **检查`Gap3`**: 发现`R1`被`V2`占用了。

     - 比较权重：`Weight(%var)` > `Weight(V2)` 吗？

   * 如果权重大于GapWeight，则说明拆分性能更好

   * 由于Gap2和R1无冲突（p292图），即和V1 & V2 的活跃区间没有交集，因此可以**将Gap2的权重设置为V1的权重**???，这样Gap1（V1活跃的区间）和Gap2可以进行合并区间操作

   * 因此形成两个可拆分区间（Gap1 + Gap2、Gap3）

     * 假设两个区间的权重均比V1和V2 的GapWeight要大 —— 则V1和V2均进行剔除，此时R1空闲，即可分配给待分配变量%var

     * 假设Gap3权重更大且大于GapWeight，Gap1+Gap2权重小于GapWeight —— 对可分配的物理寄存器进行分析，找到一个比R1更大的权重且能溢出Gap3的物理寄存器，尝试进一步扩展Gap3的区间（本例中，Gap3为最后一个区间，不会再进一步扩展了）

     * 最后对Gap3所在的区间进行拆分，插入COPY指令

       算法在为 `%var` 寻找“家”的过程中，给它在不同的时间段分配了两个不同的“家”（物理寄存器），所以必须在“搬家”的那个点插入一条 `COPY` 指令来完成“交接”——**这就是拆分的本质**

       ```
       %new = COPY %var
       ... = %new
       ```

   总结整个结果就是：

   Gap12区间，%var抢占不了R1，去找其他在Gap12空闲的物理寄存器了，因为区间合并，所以使得其溢出区间更加集中广泛，最后找到了R2（假设是Gap12区间空闲的物理寄存器）

   Gap3区间，%var则货比三家，找已被分配寄存器中，各个溢出成本最低的那个，然后抢占

   ???猜的

   ```
   ... = %var 
   ... = %var         ; (此时 %var 在 R2 中)
   ... (Gap1+Gap2 结束)
   
   ... (Gap3 开始)
   %new = COPY %var
   ... = %new         ; (此时相当于 %var 在 R1 中)
   ```

   

   

   在区间拆分时可能存在无限循环的问题，严格约束：**若拆分前的指令数大于拆分后的指令数，则拆分过程一定是可以收敛的**

   但是这样太严格，会导致很多区间无法拆分，因此设计了一个状态Spilt2，即进行第二次拆分，只允许Spilt2之前的状态进行拆分；在Spilt2状态下，只允许接受拆分后产生更少指令数的处理

   

   2. **指令局部拆分**

      处理局部拆分无法进行的情况

      **仅在寄存器类型可以提升的情况**下插入COPY指令，将有助于溢出处理

      

   3. **区域拆分**

      由于变量活跃区间跨多个基本块，拆分目的是尽量生成小的活跃区间，让这些小的活跃区间能够分配到物理寄存器

      问题在于如何划分，可以使生成的总代价最小

      

   4. **基本块全局拆分**

      主要针对无法进行区域全局拆分的情况，尝试进行基本块全局拆分，如处理基本块中有调用、异常处理、汇编跳转等指令

      在这些指令之前进行活跃区间拆分，可以减少ABI约定导致的冲突

   

### 10.5.3 区域拆分之Hopfield网络详解

区域拆分是Greedy算法的“贪婪”所在

Greedy算法解决冲突的粒度是**基本块**，当一个基本块中有多个冲突点时可以合并成一个冲突点，所以问题就变成了寻找一个合适的基本块进行溢出

合适——最有效的方法是**评估溢出后总体执行成本最低**（溢出发生后增加了store或者load指令，因此执行成本会增加）

**判断最佳基本块**——非常困难，所以LLVM采用了Hopfield网络求解极值来作为最值



Hopfield是一个全连接网络（每一个神经元都和其他所有的神经元相连接），属于离散型神经网络。其与连续型神经网络的区别在于激励函数不同

离散型神经网络是二值神经网络，神经元的输出值只取（1，0）或者（+1，-1）
$$
f(x) = \begin{cases} +1 & \text{if } x \ge ∆ \\ -1 & \text{if } x < ∆ \end{cases}
$$


激励函数是符号函数，其含义：

* 如果神经元的输出信息大于阈值∆，神经元输出取值为+1
* 如果神经元的输出信息小于阈值∆，神经元输出取值为-1

**输出函数：**
$$
y_i = f(\sum_{j = 1}^{n} w_{ji}y_j + ∆_i)
$$
w_ji是Hopfield网络的权重（由矩阵表示），∆是神经元输出节点的阈值

**存在的问题 (不稳定性)**:

- 想象一下 $w_{ii}$ 是一个很大的正数。如果神经元 $i$ 的当前状态 $y_i$ 是 +1，那么在计算下一状态时，$w_{ii}y_i$ 这一项会产生一个**极强的正反馈**，使得 $f(...)$ 的结果几乎必然还是 +1。
- 这就像**把一个麦克风对准了它自己所连接的音箱**。一点点信号都会被无限放大，导致刺耳的啸叫（即系统振荡或锁死）。
- 在神经网络中，这意味着一旦一个神经元变成了+1（或-1），它就会被自己的反馈“锁死”在这个状态，**再也无法根据其他神经元的输入来改变自己的主意**。
- 这样的网络**无法“收敛”**到一个有意义的解，因为它根本没有一个动态演化的过程。它在第一步就“僵死”了。



由于Hopfield网络是反馈型神经网络（输出是下一次的输入），如果没有对网络加以约束，该神经网络会一直迭代计算下去，所以需要去排除自反馈

使得迭代停止，神经元状态都不再改变，此时就是Hopfield网络的稳定状态

Hopfield网络最关键的工作就是**证明yi经过迭代能收敛，并且yi收敛于极小值或者最小值**

因此其对矩阵w的约束是：矩阵w是以i=j为对角线的对称矩阵，**且w_ii为0**，则可以证明Hopfield网络经过有限次迭代后一定可以收敛

因此可以将输出函数修改为：
$$
y_i = f(\sum_{j \neq i}^{n} w_{ji}y_j + ∆_i)
$$


证明过程略，参考书p295-296



通过构造Hopfield网络、设计相应的系数矩阵、对能量进行迭代求解，经过有限次迭代后，网络能量最后达到一个极值或者最值

而寄存器分配过程中的拆分**也是计算一个最合适的拆分位置，也是一个求最值的过程**，因此可以近似地将Hopfield的极值（最值）解作为寄存器拆分的最优解



### 10.5.4 使用Hopfield网络求解拆分

LLVM使用Hopfield网络实现区域拆分需要如下3步：

1. 将变量活跃区间拆分并转换为Hopfield网络，定义网络连接方式、权重、能量函数
2. 对能量函数迭代求解，当网络收敛时获得极值或者最小值
3. 将求解结果再映射到寄存器拆分的位置



**构建Hopfield网络**

进入寄存器拆分阶段的前提是，变量活跃区间一定是跨基本块（才有权重的差别，才需要拆分），且和所有可使用的物理寄存器都发生了冲突

1. **选择网络节点**

   假设以CFG中的基本块作为网络节点，用基本块之间的控制信息作为边，网络节点有输入、输出两个字段，分别表示该基本块在输入、输出时**使用寄存器或者发生溢出**

   * 若以基本块为粒度，即以基本块为网络节点，由于CFG存在回边，基本块不同输入边状态不同时，基本块的输入状态就无法确定

     因此LLVM引入了“边束”（EdgeBundle）

     > 随便举个例子结论
     >
     > **在`LoopHead`的入口，`v_init`是活跃的吗？**
     >
     > - 从`Preheader`路径看，**是**
     > - 从`LoopLatch`路径看，**否**
     >
     > **在`LoopHead`的入口，`v_prev`是活跃的吗？**
     >
     > - 从`Preheader`路径看，**否**
     > - 从`LoopLatch`路径看，**是*
     >
     > 以基本块入口为主进行了判断

   * 以边束为粒度，将同一个基本块的输入划分到一个边束，同一个基本块的输出划分到一个边束，然后将边束作为网络节点

     > 以边的集合为主进行了判断
     >
     > 在`Preheader -> LoopHead`这条**边**上，`v_init`是活跃的
     >
     > 在`LoopLatch -> LoopHead`这条**边**上，`v_prev`是活跃的

     边束网络节点的实现算法：

     * 为每一个基本块定义输入、输出两个编号，两个相邻的基本块的输出等于下一个基本块的输入，由此将该基本块的输入编号和其他基本块的输出编号划分成一个等价类，并重新编号

       ```
       
       					┌─────────┐0
       					│ entry   │
       					└────┬────┘1
                      │  					
                      │	 ┌───────────────────┐
                      │   │                   │
                      ▼   ▼                   │
                  ┌─────────┐2                │
                  │LoopCond │                 │
                  └────┬────┘3                │
                ┌──────┴──────┐               │
                │             │               │
                ▼            ▼                │ 
            ┌─────────┐6 ┌─────────┐4         │
            │LoopBody │  │   ret   │          │
            └────┬────┘7 └─────────┘5         │
                 │                            │
                 └────────────────────────────┘
       
       
       编号后进行等价类划分：
       编号0没有等价类，新编号#EB0
       编号1、2、7是等价类，新编号#EB1
       编号3、4、6是等价类，新编号#EB2
       编号5没有等价类，新编号#EB3
       ```

     * 然后以边束作为网络节点构建Hopfield网络，对以边束形成的Hopfield网络进行求解后得到的是**边束的最优值**，后续还需要将边束再映射到基本块

   

   有了网络节点，接下来需要考虑如何进行节点连接以形成边，**网络是以边束进行构建，首先需要定义每个边束节点的阈值**

   * 以基本块的频率作为阈值，因为边束节点包含多个基本块，所以应该**将边束中所有基本块的频率都累加到边束的阈值中**

   * 为了区别**边束使用寄存器还是栈**，设计两个阈值，即偏置，记为BiasP、BiasN

     * BiasP——节点使用寄存器，累加到BiasP
     * BiasN——节点使用栈，累加到BiasN

     将基本块输入映射到一个边束中时，如果可以建立基本块输入时的寄存器状态（使用寄存器还是使用栈），那么就可以把该基本块的输入状态对应到边束的状态，根据状态来更新阈值

     通过以下规则来定义基本块的状态：

     1. 如果变量从一个基本块流出到另一个基本块，对于流出的基本块或者流入的基本块来说，使用寄存器可以获得较好的性能
     2. 如果变量和物理寄存器发生冲突，那么可以根据基本块指令的定义和使用情况来确定状态：
        * 冲突区间指令开始位置在基本块开始之前，使用栈
          - 意思是：变量 `a`在**进入BB2之前**就已经存在了（可能是在BB1定义的）。
          - 决策：对于BB2来说，`a`是一个“外来户”。如果寄存器紧张，优先把车位让给在BB2内部“土生土长”的变量。因此，`a`应该被标记为**使用栈**。
        * 冲突区间指令开始位置在基本块指令定义之前，推荐使用栈
        * 冲突区间指令结束位置在基本块结束指令后，使用栈
          - 意思是：变量 `a`在**离开BB2之后**还会被使用（比如在BB3中还要用到）。
          - 决策：`a`的生命线超出了BB2的范围。如果BB2内部有另一个变量 `b`，它的生存区间完全在BB2内部，那么把宝贵的寄存器给 `b`会带来更大的性能提升（因为 `b`在BB2内会被频繁使用）。而 `a`可以存到栈上，虽然之后用的时候慢点，但可能总体效益更高。
        * 冲突区间指令结束位置在基本块指令使用之后，推荐使用栈

     这里定义的状态是基本块的输入和输出状态

     在基本块内部还可能存在冲突，这种冲突时局部冲突，**Hopfield网络中优化不考虑局部冲突，而是在网络训练完成后重新计算执行总成本**（其中局部冲突会在基本块中增加额外指令，导致执行成本增加），并根据总成本来决定是否选择该网络

     为此LLVM定义了5种状态：

     `DontCare`：基本块不关心该变量，或者该变量已经死亡

     `PrefReg`：优先使用寄存器

     `PrefSpill`：优先使用栈

     `PrefBoth`：使用寄存器或栈都可以

     `MustSpill`：必须使用栈

   * 根据边界约束更新BiasP或者BiasN：

     当边界约束为PrefReg时，将基本块执行频率更新到BiasP；当边界约束为PrefSpill，更新到BiasN；当边界约束为MustSpill，将BiasN设置为最大

     如果BiasP大于BiasN，则为+1；

     如果BiasN大于BiasP，则为-1；

     （实际上Value值还有0，为防止迭代过程的误差放大，最后0也被当作-1对待）

     

2. **选择网络边、权重**

   以边束建立Hopfield的网络节点，但这些节点还是孤立的点，建立边并进行关联

   Hopfield网络边的关联是以边束为粒度构建的，但是边束又依赖基本块，所以需要**先将边束信息转换为基本块，再根据基本块的边界约束情况将基本块映射到边束，最后再为边束建立关联**
   
   通常一个边束包含多个基本块，当各个基本块的边界约束为寄存器时，说明这些基本块的边束可以和其他的基本块边束直接相连
   
   具体如下：
   
   1. 根据 **UsedBlocks（定义和使用基本块）中每一个块** 的边界约束，找到所有使用寄存器的边束（这些边束在初始情况下使用了寄存器）
   
   2. 将**边束中包含的LiveThroughBlocks**（活跃基本块，但未定义和使用）都找出来，再分析LiveThroughBlocks中的每个基本块和物理寄存器的区间冲突情况
   
      **`LiveThroughBlocks`**: 这是指那些变量的生命周期“路过”了，但没有被`Def`或`Use`的基本块，与UsedBlocks相对的
   
      1. 对于所有没有冲突的基本块，找到对应的边束，并为这些边束建立关联，同时更新频率
      2. 对于有冲突的基本块，更新边束的频率
   
   ```
   
   					┌─────────┐0
   					│ entry   │
   					└────┬────┘1
                  │  					
                  │	 ┌───────────────────┐
                  │   │                   │
                  ▼   ▼                   │
              ┌─────────┐2                │
              │LoopCond │                 │
              └────┬────┘3                │
            ┌──────┴──────┐               │
            │             │               │
            ▼            ▼                │ 
        ┌─────────┐6 ┌─────────┐4         │
        │LoopBody │  │   ret   │          │
        └────┬────┘7 └─────────┘5         │
             │                            │
             └────────────────────────────┘
   
   ```
   
   **UsedBlock 为基本块entry和ret**（真正进行了定义和使用待拆分虚拟寄存器的基本块）
   
   entry的输入输出边界约束为DontCare、PrefReg；
   
   ret的输入输出边界约束为PrefReg、DontCare；
   
   根据边界约束为寄存器找到边束EB1、EB2
   
   再根据EB1、EB2找**`LiveThroughBlocks`**: 找到了所有相关的“途经块”：`LoopCond` 和 `LoopBody`
   
   * 查看`#EB1`：这个边束代表了从`entry`到`LoopCond`的路径。它还包含了`LoopCond`的输出边`2`和`LoopBody`的回边`7`。这些边所连接的基本块`LoopCond`和`LoopBody`，就是变量的“途经之地”，但都未Def或Use
   * 查看`#EB2`：这个边束代表了从`LoopCond`到`ret`的路径，以及从`LoopBody`到`LoopCond`的路径
   
   然后对基本块和物理寄存器的区间进行冲突分析
   
   * **问题**: `LoopCond` 和 `LoopBody` 只是“途经点”。如果我们决定让变量在`#EB1`和`#EB2`（即在`LoopCond`和`LoopBody`的边界上）都使用寄存器，这个决策是否安全？
   * **安全检查**: 算法必须检查，在`LoopCond`和`LoopBody`**内部**，我们想要分配的那个物理寄存器，是否已经被其他不相关的指令给占用了？
   
   为了简单，假设基本块LoopCond和LoopBody 与 物理寄存器不冲突，让变量在`LoopCond`和`LoopBody`中全程使用寄存器是安全的
   
   所以它们对应的边束EB1和EB2会关联
   
   **边的权重也是基本块的执行频率，边的权重被设置为它们共同关联的那些基本块的执行频率之和**
   
   权重 ($w_{EB1, EB2}$) = `Freq(LoopCond)` + `Freq(LoopBody)`
   
   
   
   **构建后的状态：**
   
   **节点`#EB1`**: 有一个很高的`BiasP`（来自`entry`和`LoopCond`等的高频率）。
   
   **节点`#EB2`**: 有一个很高的`BiasP`（来自`ret`和`LoopCond`等的高频率）。
   
   **边`(#EB1, #EB2)`**: 有一个**非常高的正权重**（来自`LoopCond`和`LoopBody`的循环频率）。
   
   当网络开始迭代时，`#EB1`的高`BiasP`使它倾向于输出`+1`（使用寄存器）。这个`+1`的状态会通过那条高权重的正向边，**极其强烈地**“鼓励”`#EB2`也输出`+1`
   
   **最终结果**: 网络会迅速收敛到 `y_{EB1} = +1` 和 `y_{EB2} = +1` 的稳定状态
   
   在`#EB1`和`#EB2`所代表的所有基本块边界上，都使用寄存器，而不是栈。这是一个成本最低的最优决策



**选择能量函数以及迭代求解极值**

能量函数：
$$
E = -\frac{1}{2}\sum_{i \neq j} w_{ji}x_i x_j - \sum_i \theta_i x_i
$$
wji为节点xi和节点xj之间边的执行频率

每次根据能量函数计算E和∆E，如果∆E满足一定条件，则迭代终止

LLVM记录所有边束节点的状态，迭代计算每个**节点的输出**，当所有节点的输出不再变化时，则说明迭代可以终止，能量收敛于极小值（意味着执行成本最小），此时节点的输出值表示边束节点使用寄存器或者溢出



**将Hopfield网络的解映射到寄存器拆分位置**

当迭代终止，将**边束的输出值**映射到`LiveThroughBlocks`中的每一个基本块的边界约束上

如果所有边束节点的输出都不是寄存器，说明无法进行贪婪分配；

如果存在边束节点的输出为寄存器，说明有基本块的输入或输出直接使用寄存器，不需要溢出；

* 举例：

  **迭代终止**: 网络收敛了，我们得到了一组最终的、稳定的状态值 `(x_1, x_2, ..., x_n)`。

  **映射**: 编译器会遍历这个结果：

  - 节点 i（即边束 `#EB_i`）的最终输出是`+1`吗？
    - **是**: 这意味着网络找到的最低成本方案是让`#EB_i`**使用寄存器**。编译器会将其对应的基本块（如`LoopCond`）的边界约束设置为`PrefReg`（优先使用寄存器）
  - 节点 i 的最终输出是`-1`吗？
    - **是**: 这意味着网络发现，为了避免在别处产生更大的冲突（更高的成本），在`#EB_i`处**溢出到栈**是最好的选择。编译器将其边界约束设置为`PrefSpill`（优先使用栈）





### 10.5.5 示例分析

变量优先级的计算方式以**活跃区间的范围**为基础，当遇到拆分等情况，会调整变量优先级的计算方式（进行分别计算然后累加）

然后进行PriotityQueue的排序，依次分配

其中有**寄存器提示**的待分配的虚拟寄存器，优先级会被提升

若选出待分配队列中的变量权重均小于已分配变量的权重，那么还会被放回待分配队列而不是直接溢出。此时需要修改变量的优先级，否则会反复选择变量导致无限循环。Greedy算法引入状态Split来设置，对于拆分状态的虚拟寄存器，其优先级会降低

优先级和权重不同，优先级是每个虚拟寄存器的值，靠活跃区间范围来计算得到



每个虚拟寄存器的优先级布局

按优先级顺序进行优先级布局（32位）

1. **31-30 Split状态位：** 如果状态为Split，则该位为0，否则为1
2. **30-29 分配提示位：** 有分配提示则设置为1
3. **29-28 跨基本块的活跃区间信息：** 1表示跨多个基本块，0表示活跃区间在一个基本块内
4. **28-23 寄存器类型的分配优先级：** 占5位，最大值63
5. **23-0 基于活跃区间的范围优先级：** 占23位， 意味着一个函数最大支持100万条IR

默认跨基本块的活跃区间信息优先级更高，分配策略优先级默认值为0

但是，可以通过GreedyRegClassPriorityTrumpsGlobalness来指定两者的优先级先后，即3和4调换位置



若此时有%42权重大于%7，则先剔除%7到待分配队列中并重新计算优先级，此时并不直接设置状态，而是等%7分配时，若还冲突且%7权重最小，才设置状态为Split，重新插入待分配队列。等到下一次分配时，若状态为Split，则表示对%7进行拆分，然后再分配寄存器



使用物理寄存器拆分%7，需要计算其拆分成本，选出最小的来进行

因为%7存在COPY指令，且COPY指令涉及物理寄存器r2和r1，所以优先分配r2、r1中

先使用r2拆分%7，再使用r1，再依次。。。

对每个物理寄存器需要先计算其拆分前的静态执行成本

然后根据UsedBlocks中每个基本块的Def、Use指令和r2已经分配的区间确定冲突的存在情况。如果存在冲突，则需要分别增加一条store、load指令，而**增加指令会导致其所在的基本块相应地根据其执行频率增加静态执行成本**

增加指令后的成本大于初始静态成本，则会放弃考虑，继续下一个物理寄存器

若小于，则继续计算动态成本（假设此时是r3）：

1. 为UsedBlocks基本块初始化边界约束
2. 建立边束，并根据基本块的执行频率为边束更新BiasP和BiasN
3. 边界约束为DontCare，表示边束并不影响Hopfield网络，则相应边束可以再网络构建中忽略
4. 边界约束为MustSpill，也可以进行忽略
5. 根据边束找覆盖到的LiveThroughBlocks基本块（7、2、6）
6. 因为物理寄存器r3被部分占用，所以需要计算r3和基本块726的冲突情况，来决定是否添加边束的关联
   * 7和r3不冲突，对应边束EB1和EB4，建立关联
   * 2和r3不冲突，对应边束EB2和EB3，建立关联
   * 6和r3不冲突，对应边束EB3和EB5，建立关联
7. 此时构建出Hopfield网络图初始状态
8. 然后进行迭代，本质是计算能力，跟踪是否有节点发生变化
9. 最后得到一个稳定的结果，发现输出结果是+1，表示对应的基本块的输入和输出使用了寄存器，得到动态成本
10. 计算总成本=静态成本+动态成本



依次计算各个物理寄存器的总成本，最后发现r4的总成本最低，因此用r4对%7进行拆分

1. 对UsedBlocks进行拆分（对应静态执行成本）

2. 对LiveThroughBlocks进行拆分（对应动态成本），对存在区间冲突的，插入store、load指令

   如有call指令发生冲突，需要在该指令之前和之后分别插入一条指令，此时还不知道插入指令使用的虚拟寄存器是否需要溢出（活跃区间特别小，可能存在一个可用的物理寄存器），所以更通用做法是：引入新的虚拟寄存器并插入COPY指令（后续再为虚拟寄存器分配物理寄存器）——在call指令之前声明一个新的虚拟寄存器：%43 = COPY %44 以保存44的值，在其后面恢复44，%44 = COPY %43，同时需要为新的指令进行编号

3. 最后使用新引入的虚拟寄存器重新更新指令，然后加入待分配队列



```c++
// %7进行分配
selectOrSplit GPR:%7 [16r,1424B:0) @016r weight:5.732281e-01 w=5.732281e-01
// %7 优先分配到 r2、r1 中，这是因为 %7 来自参数，而该参数使用 r2 传递
hints: $r2 $r1
// 由于前面已分配过 %7，所以此时 %7 的状态为 RS_Split
RS_Split Cascade 1
// %7 对 %7 的活跃区间进行分析，Def、Use 指令分别在三个基本块 0、1、3 中，基本块 2、4、5、6、7
// 属于 LiveThrough Blocks
Analyze counted 3 instrs in 3 blocks, through 5 blocks.
// 本节并没有介绍压缩的概念，它涉及使用 UsedBlocks 和 LiveThroughBlocks 直观构建 Hopfield
// 网络(暂时不考虑物理寄存器的具体分配)。通过 Hopfield 网络的迭代计算，理论上能够促进 CFG 的结构
// 简化或“压缩”。尽管这并非其直接目的，而是一种潜在效应。本例并不会真正地执行压缩步骤。
Compact region bundles, v=4, none.
// 计算 %7 的初始静态执行成本(仅仅依赖于 UsedBlocks 所在的基本块的频率)
Cost of isolating all blocks = 1025.0
// 用 r2 拆分 %7，首先计算静态执行成本，依赖于 UsedBlocks 和 r2 是否冲突。如果冲突，说明要插入新
// 的指令，由此计算静态执行成本，为 2016，大于初始静态成本，所以不会选择 r2 拆分(因此也不会进一
// 步构建 Hopfield 网络)
$r2 static = 2016.0 worse than no bundles
// 用 r1 拆分 %7，静态执行成本为 1025，也不会使用 r1 拆分 %7
$r1 static = 1025.0 worse than no bundles
// 用 r3 拆分 %7，静态执行成本为 992，进一步构建 Hopfield 网络，然后计算总执行成本为 1984
// Hopfield 网络的输出结果为 EB1、EB2 和 EB3，输出结果为 +1。r3 总成本大于 1025，所以也不会使用
// r3 拆分 %7
$r3 static = 992.0, v=5, total = 1984.0 with bundles EB#1 EB#2 EB#3.
// 用 r4 拆分 %7，静态执行成本为 0，进一步构建 Hopfield 网络，然后计算总执行成本为 961。Hopfield
// 网络的输出结果为 EB1、EB2、EB3、EB4 和 EB5，输出结果为 +1。r4 总成本大于 961，所以 r4 是拆分
// %7 的候选之一
$r4 static = 0.0, v=5, total = 961.0 with bundles EB#1 EB#2 EB#3 EB#4 EB#5.
// 用 r5 拆分 %7，和 r4 的过程相同。r5 也是拆分 %7 的候选之一
$r5 static = 0.0, v=5, total = 961.0 with bundles EB#1 EB#2 EB#3 EB#4 EB#5.
// 用 r0 拆分 %7，和 r4 的过程相同。r0 也是拆分 %7 的候选之一
$r0 static = 0.0, v=5, total = 961.0 with bundles EB#1 EB#2 EB#3 EB#4 EB#5.
// 用 r6 拆分 %7，其静态执行成本过大，不会成为候选寄存器
$r6 static = 1984.0 worse than $r4
// 用 r7 拆分 %7，在构建 Hopfield 网络过程中发现所有边束的输出都是 -1，说明使用 r7 拆分也不会取得
// 更好的收益
$r7 no positive bundles
// 用 r8 拆分 %7，其静态执行成本过大，不会成为候选寄存器
$r8 static = 1984.0 worse than $r4
// 用 r9 拆分 %7，在构建 Hopfield 网络过程中发现所有边束的输出结果都是 -1，r9 也不会成为候选寄存器
$r9 no positive bundles
// 因为 r4 是第一个候选寄存器，并且总体执行成本最低，所以选择 r4 来拆分 %7
Split for $r4 in 5 bundles, intv 1.
// 拆分后会引入两个新的虚拟区间
splitAroundRegion with 2 globals.
// 因为基本块 0 和 r4 不冲突，所以不会引入新的指令
%bb.0 [0B,96B), uses 16r-16r, reg-out 1, enter after invalid, defined in block after interference.
selectIntv 1 -> 1
useIntv [16r,96B): [16r;96B):1
// 基本块 1 和 r4 不冲突，所以不会引入新的指令
%bb.1 [96B,320B) intf invalid-invalid, live-through 1 -> 1, straight through.
selectIntv 1 -> 1
useIntv [96B,320B): [16r;320B):1
// 因为基本块 3 和 r4 不冲突，所以不会引入新的指令
%bb.3 [384B,688B) intf invalid-invalid, live-through 1 -> 1, straight through.
selectIntv 1 -> 1
useIntv [384B,688B): [16r;320B):1 [384B;688B):1
// 因为基本块 7 和 r4 不冲突，所以不会引入新的指令
%bb.7 [1344B,1424B) intf invalid-invalid, live-through 1 -> 1, straight through.
selectIntv 1 -> 1
useIntv [1344B,1424B): [16r;320B):1 [384B;688B):1 [1344B;1424B):1
// 因为基本块 2 和 r4 不冲突，所以不会引入新的指令
%bb.2 [320B,384B) intf invalid-invalid, live-through 1 -> 1, straight through.
selectIntv 1 -> 1
useIntv [320B,384B): [16r;688B):1 [1344B;1424B):1
// 因为基本块 6 和 r4 不冲突，所以不会引入新的指令
%bb.6 [1216B,1344B) intf invalid-invalid, live-through 1 -> 1, straight through.
selectIntv 1 -> 1
useIntv [1216B,1344B): [16r;688B):1 [1216B;1424B):1
// 因为基本块 4 和 r4 不冲突，所以不会引入新的指令
%bb.4 [688B,992B) intf invalid-invalid, live-through 1 -> 1, straight through.
selectIntv 1 -> 1
useIntv [688B,992B): [16r;992B):1 [1216B;1424B):1
// 因为基本块 5 和 r4 冲突，所以需要在此基本块中引入拆分指令。冲突位置是 [1184r,1184d),
// 所以会插入新的虚拟寄存器，插入位置在 1176r (1184 编号对应 call 指令，前面一条指令的编号为 1168，
// 所以插入新的指令编号为 1184 和 1168 之间的位置：1176)
%bb.5 [992B,1216B) intf 1184r-1184d, live-through 1 -> 1, create local intv for interference.
selectIntv 1 -> 1
enterIntvAfter 1184d: valno 0
useIntv [1192r,1216B): [16r;992B):1 [1192r;1424B):1
selectIntv 1 -> 1
leaveIntvBefore 1184r: valno 0
useIntv [992r,1176r): [16r;1176r):1 [1192r;1424B):1
single complement def at 1176r
// 因支配关系而简化插入的 COPY 指令，在本例中不涉及该类指令的优化
Removing 0 back-copies.
// 重写指令，将原来 %7 替换为 index 虚拟寄存器 %44，并新插入 %43 用于解决冲突
blit [16r,1424B:0): [16r;1176r):1 = %44(1)*%bb.0 %bb.1 %bb.2 %bb.3 %bb.4 %bb.5
[1176r,1192r:0) = %43(1) 0:%bb.5 %bb.6 %bb.7
rewr %bb.0 16r:1 %44:gpr = COPY $r2
rewr %bb.3 480B:1 %18:gpr = ADD_rr %18:gpr(tied-def 0), %44:gpr
rewr %bb.1 129B:1 %12:gpr = COPY %44:gpr
rewr %bb.5 1192r:0 %44:gpr = COPY %43:gpr
rewr %bb.5 1176r:1 %43:gpr = COPY %44:gpr
Main interval covers the same 8 blocks as original.
// 将新的虚拟寄存器 %43、%44 重新入栈，用于后续分配
queuing new interval: %43 [1176r,1192r:0) @01176r weight:2.333197e+00
Enqueuing %43
queuing new interval: %44 [16r,96B:0) [96B,384B:1) [384B,1176r:2) [1192r,1216B:3) [1216B,1344B:4) [1344B,1424B:2) @016r 1@96B-phi 2@384B-phi 3@1192r 4@1216B-phi
weight:1.120592e+00
Enqueuing %44
```

**1. 阶段一：决策（为 `%7` 选择最佳物理寄存器）**

算法的目标是为虚拟寄存器 `%7`（一个生命周期很长的GPR）找到一个物理寄存器。

- **`selectOrSplit GPR:%7 ...`**
  - `%7` 是我们当前的主角。
  - `[16r,1424B:0)`：`%7` 的活跃区间（生命周期）非常长，从指令`16r`（r=Read）开始，一直持续到`1424B`（B=Block，基本块边界）。
  - `hints: $r2 $r1`：算法被“提示”优先考虑`$r2`或`$r1`（很可能因为`%7`是一个函数参数，通过`$r2`传入）。
  - `RS_Split Cascade 1`：`%7` 的状态是“需要拆分”，这是第一轮尝试。
  - `Analyze ... 3 blocks, through 5 blocks`：`%7` 在3个基本块中有`Def/Use`，并在另外5个基本块中“活跃贯穿”（LiveThrough）。这是一个非常复杂的、跨越8个块的变量。
- **`Cost of isolating all blocks = 1025.0`**
  - 这是**基准成本**。它代表如果放弃治疗，将`%7`在它的每一个`Use`点前都`Reload`（加载）、在每一个`Def`点后都`Spill`（存储）所需的总成本。任何优化方案的成本都必须低于这个值。
- **遍历所有物理寄存器（“货比三家”）**
  - **`$r2 static = 2016.0 worse...`**
  - **`$r1 static = 1025.0 worse...`**
    - 算法首先检查“提示”的`$r2`和`$r1`。发现如果强行分配给它们，解决冲突的成本（`2016.0`和`1025.0`）都**不低于**基准成本。**失败**。
  - **`$r3 static = 992.0, v=5, total = 1984.0...`**
    - 算法尝试`$r3`。`static`（静态）成本`992.0`看起来有希望（低于1025.0）。
    - 于是，它进一步**“构建Hopfield网络”**（`with bundles EB#1...`）来进行更精密的成本计算。
    - `total = 1984.0`：Hopfield网络计算出的**真实总成本**是`1984.0`，远高于基准。**失败**。
  - **`$r4 static = 0.0, v=5, total = 961.0...`**
  - **`$r5 static = 0.0, v=5, total = 961.0...`**
  - **`$r0 static = 0.0, v=5, total = 961.0...`**
    - **“Aha！”时刻**：算法尝试`$r4`。
    - `static = 0.0`：**静态成本为0**。这说明在`%7`的`Def/Use`块（0, 1, 3）中，`$r4`是完全空闲的，没有任何冲突！
    - `total = 961.0`：算法依然构建Hopfield网络来计算在`LiveThrough`块中解决冲突的成本，发现总成本是`961.0`。
    - **`961.0 < 1025.0`**。这是一个**可行**的方案！`$r4`、`$r5`、`$r0`都是可行的候选者。
  - **`$r6`, `$r7`, `$r8`, `$r9`...**
    - 算法检查了剩下的寄存器，发现它们要么成本太高（`worse than $r4`），要么Hopfield网络找不到任何收益（`no positive bundles`，即网络输出全为-1，建议全部溢出）。
- **最终决策：`// 因为 r4 是第一个候选寄存器...所以选择 r4 来拆分 %7`**
  - 在所有成本最低的方案（`$r4`, `$r5`, `$r0` 都是`961.0`）中，算法选择了它找到的第一个，即 **`$r4`**。

**2. 阶段二：执行拆分（用`$r4`拆分`%7`）**

现在，算法开始执行这个拆分决策，它会遍历`%7`活跃的8个基本块，并根据与`$r4`的冲突情况来重写代码。

- **`%bb.0, %bb.1, %bb.3, %bb.7, %bb.2, %bb.6, %bb.4`**

  - `// ... 和 r4 不冲突，所以不会引入新的指令`
  - 在所有这些块中，`$r4`都是空闲的。因此，算法什么也不用做，`%7`可以“免费”地在这些块中保持活跃（它将被分配给`$r4`）。

- **`%bb.5 [992B,1216B) intf 1184r-1184d... create local intv...`**

  - **发现冲突！** 在基本块5（`%bb.5`）中，算法发现在指令`1184`（注释说是`call`指令）附近，`%7`的生命周期与`$r4`（或`$r4`的别名寄存器）发生了**冲突**（`intf` = interference）。

- **执行拆分（`Split`）**

  - **`// ...插入位置在 1176r (1184 和 1168 之间的位置...)`**

    - 算法决定在冲突点`1184`**之前**的`1176r`处，将`%7`的生命周期“切断”。

  - **`// 重写指令，将原来 %7 替换为... %44，并新插入 %43 用于解决冲突`**

    - 这是拆分的关键一步！原始的`%7`被“杀死”了。

  - **`blit [16r,1424B:0): ... = %44(1)\*%bb.0... [1176r,1192r:0) = %43(1) 0:%bb.5...`**

    ！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！

    - `blit`（块传输）操作显示，`%7`的长生命周期`[16r,1424B:0)`被**替换**为了两个**新的、更短的**生命周期：
      1. **`%44`**: 继承了`%7`在冲突点**之前**的生命周期 (`[16r, 1176r)`)。
      2. **`%43`**: 继承了`%7`在冲突点**之后**的生命周期 (`[1176r, 1192r:0)`)。

    ！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！

- **插入`COPY`指令（“桥接”拆分点）**

  - `rewr %bb.5 1176r:1 %43:gpr = COPY %44:gpr`
    - 在基本块5的`1176r`位置，算法插入了一条新的`COPY`指令。
    - 这条指令的作用是“桥接”这个拆分：`%44`（“之前”的变量）在它生命周期的最后一刻，将它的值复制给了`%43`（“之后”的变量）。
  - `rewr %bb.0 ... %44:gpr = COPY $r2`
  - `rewr %bb.1 ... %18:gpr = ADD_rr %18:gpr, %44:gpr`
  - `rewr %bb.3 ... %44:gpr = COPY %44:gpr`
    - 所有在拆分点**之前**使用`%7`的地方，现在都被**重写 (rewr)**为使用新的 **`%44`**。
  - `rewr %bb.5 1192r:0 %44:gpr = COPY %43:gpr`

**3. 阶段三：重新入队（迭代**

- **`Main interval covers the same 8 blocks as original.`**
  - `%7`（Main interval）被成功处理了。
- **`// 将新的虚拟寄存器 %43、%44 重新入栈，用于后续分配`**
  - **`queuing new interval: %43 [1176r,1192r:0) ... Enqueuing %43`**
  - **`queuing new interval: %44 [16r,96B:0) ... [384B,1176r:2) ... Enqueuing %44`**
  - **核心步骤**：算法**没有**立即将`%43`和`%44`分配给`$r4`。它只是将这两个新的、更简单的虚拟寄存器，连同它们（现在更低）的权重，**重新添加回**待分配的优先队列中。
  - **为什么？** 因为“拆分”这个动作本身，可能改变了寄存器压力的全局图景。也许现在有比`$r4`更好的选择。
  - **最终结果**：在下一轮迭代中，当轮到`%44`和`%43`时，算法会发现它们与`$r4`**不再有任何冲突**，于是可以**零成本**地将它们都分配给`$r4`，从而完美地完成了这次优化。



## 10.6 PBQP 算法实现

NP完全优化问题，求最优解或次优解应用于寄存器分配问题

### 10.6.1 PBQP 介绍

假设有n个工厂，工厂之间需要运输货物，不同货物的运输成本不同

任意两个工程i和j，它们之间运输成本用矩阵C_ij表示，运输的货物分别使用X_i和X_j表示，那么i和j工厂之间的最小成本是：
$$
\min (X_i^T C_{ij} X_j)
$$
n个工厂之间的最小成本则是：
$$
\min \left( \sum_{i=1}^{n}\sum_{j=1}^{n} X_i^T C_{ij} X_j \right)
$$
向量X_i和X_j有限制：

**其任意的元素阈值只能是0或1，且整个向量的和为1**

C_ij矩阵中成本值可以是任意数，分3种情况：

1. 大于0，表示两工厂之间的运输成本
2. 小于0，运输成本一般不会为负数，但如果两工厂发生合并，因规模效益导致成本降低，此时合并获得收益更大，等价于将运输成本设置为负数
3. ∞，表示无法进行运输



假设每一个节点本身都有构建成本，第i个节点的成本用S_i表示，那么再考虑节点的构建成本后，最小成本公式如下所示：
$$
\min \left( \sum_{i=1}^{n}\sum_{j=1}^{n} X_i^T C_{ij} X_j+  \sum_{i=1}^{n}S_iX_i\right)
$$


### 10.6.2 寄存器分配和PBQP的关系

1. **分配**

   如果活跃区间冲突，无法使用一个物理寄存器，则说明它们之间的成本为∞无穷大；如果可以使用，则成本为0

   因此可根据变量活跃区间情况构建成本矩阵，矩阵的维度为物理寄存器的个数，假设物理寄存器有k个，则任意两个变量之间的成本矩阵为C_kk

2. **溢出**

   由于每个变量都可能溢出，可以根据基本块的执行频率等情况计算溢出成本，假设记为C_0

   通过数学变换，**将溢出成本C_0设计为k+1长度的向量，记为S_i(C_0,0,...,0)**，同时将分配成本矩阵**C_kk变换为C_k+1k+1（并且成本矩阵的第一行和第一列都是0**），这样溢出成本和分配矩阵维度相同，可以进行矩阵运算

3. **寄存器合并**

   此处的合并是指寄存器分配过程中的合并，其**本质是将两个变量分配到同一个物理寄存器**，如果发生了寄存器合并，则说明可以减少指令数，从而降低分配成本

   当发生寄存器合并时，可以设计一个合并矩阵，记为M_k+1k+1，将矩阵中可以发生合并的物理寄存器的位置记为负值

综合以上三种情况，可以给出寄存器分配成本的表示：
$$
\min \left( \sum_{i=1}^{n}\sum_{j=1}^{n} X_i^T (C_{ij}+M_{ij}) X_j+  \sum_{i=1}^{n}S_iX_i\right)
$$
合并
$$
C_{ij}+M_{ij}
$$
则可以得到式（39），即转换为了PBQP问题进行求解



### 10.6.3 PBQP问题求解

采用启发式算法获得近似最优解，例如经典的**单纯形算法**，但其复杂性较高

本节讲解**通过规约**和**反向传播**求解PBQP的方法

3种情况可以进行规约：

1. **零度规约（也称为R_0）**

   指的是图中节点没有边与之关联，从节点的构建成本中取min作为节点的最小值

2. **一度规约（R_1）**

   指的是图中节点只有一条边与其他节点关联，那么可以将节点的构建成本和系数矩阵转移到另一个节点中

   一度规约的关键是如何将前置节点的成本合并到当前节点，然后移除两者之间的关联边（即获得在消除关联边后的成本）
   $$
   \min \left( \sum_{i=1}^{n}\sum_{j=1}^{n} X_i^T C_{ij} X_j+  \sum_{i=1}^{n}S_iX_i\right)
   $$
   使用该式进行计算

   如

   ```
   [2,0]———————————— [2,4]
   node0		[2 1			node1
   				 1 4]
   ```

   节点1成本更新：

   [2+min(2+2,0+1)		[3

   4+min(2+1,0+4)]      =.        7]

   最终得到：[3,7]

3. **二度规约（R_2）**

   指的是图中节点只有两条边与其他节点关联，那么可以将节点的构建成本和系数矩阵转移到另外两个节点中

   **初始状态:**

   - 节点 0 成本 ($C_0$)：`[2, 0]`

   - 节点 1 成本 ($C_1$)：`[1, 3]`

   - 节点 2 成本 ($C_2$)：`[2, 3]`

   - 边 (0, 1) 矩阵 ($C_{01}$)：

     ```
     [2  2]
     [1  4]
     ```

   - 边 (1, 2) 矩阵 ($C_{12}$)：

     ```
     [2  1]
     [1  4]
     ```

   **计算连接 0 和 2 的新矩阵 (C_{02})，即关联边成本**：

   - C_{02}[0] [0] (当 节点0 选择0, 节点2 选择0):

     = min(

       (节点1选0的成本): C₁[0] + C₀₁[0] [0] + C₁₂[0] [0],

       (节点1选1的成本): C₁[1] + C₀₁[0] [1] + C₁₂[1] [0]

     )

   - C_{02}[0] [1] (当 节点0 选择0, 节点2 选择1):

     = min(

       (节点1选0的成本): C₁[0] + C₀₁[0] [0] + C₁₂[0] [1],

       (节点1选1的成本): C₁[1] + C₀₁[0] [1] + C₁₂[1] [1]

     )

   - C_{02}[1] [0] (当 节点0 选择1, 节点2 选择0):

     = min(

       (节点1选0的成本): C₁[0] + C₀₁[1] [0] + C₁₂[0] [0],

       (节点1选1的成本): C₁[1] + C₀₁[1] [1] + C₁₂[1] [0]

     )

   - C_{02}[1] [1] (当 节点0 选择1, 节点2 选择1):

     = min(

       (节点1选0的成本): C₁[0] + C₀₁[1] [0] + C₁₂[0] [1],

       (节点1选1的成本): C₁[1] + C₀₁[1] [1] + C₁₂[1] [1]

     )

   **代入数值计算：**

   - $$
     C_{02}'[0][0] = \min(1 + 2 + 2, \quad 3 + 2 + 1) = \min(5, 6) = 5
     $$

     

   - $$
     C_{02}'[0][1] = \min(1 + 2 + 1, \quad 3 + 2 + 4) = \min(4, 9) = 4
     $$

     

   - $$
     C_{02}'[1][0] = \min(1 + 1 + 2, \quad 3 + 4 + 1) = \min(4, 8) = 4
     $$

     

   - $$
     C_{02}'[1][1] = \min(1 + 1 + 1, \quad 3 + 4 + 4) = \min(3, 11) = 3
     $$

   **最终结果：** 节点 1 被消除，其成本被合并为一条连接节点 0 和 2 的新边，该边的成本矩阵 C_{02} 为：

   ```
   [5  4
    4  3]
   ```

4. 对于大于二度的节点，采用反向传播的处理方法，思路如下：

   1. * 对于关联边大于2的节点，首先按照一定的规则选择节点（也可以随机选择）
      * 将选择的节点放入一个栈中，然后将与节点相关联的边都删除
        * 如果出现因为边删除而可以使用R_0、R_1和R_2规约方法进行处理的节点，则先进行处理，并将这些节点也压入栈中；
        * 如果没有可规约的节点了，则继续选择图中节点并删除相关联的边，直到最后剩余的节点可以使用R_0、R_1、R_2规约方法进行处理
   2. 此时栈顶存放的节点可以规约，依次从栈顶弹出节点，并且反向依次重构图，在重构的过程中根据已经处理的节点计算栈顶节点的成本，从而得到最小成本



### 10.6.4 寄存器分配问题建模示例

假设有4个变量：XYZW

只有2个物理寄存器R0和R1

并且XY、XW活跃区间冲突，ZY、ZW活跃区间冲突，YW活跃区间冲突



每个变量可能有3种选择——溢出、R0、R1，所以每个成员变量有3个元素，如X：[X0,X1,X2]，分别表示溢出成本，选择R0的成本以及选择R1的成本

PBQP构建图规则：当变量之间有冲突，两个变量有边进行关联

接下来需要为关联边添加矩阵：由于有2个寄存器，便于矩阵计算，将矩阵行列设置为物理寄存器个数+1，即3（第一行第一列为0）

接下来判断变量XYZW和可用的物理寄存器是否冲突，假设都可以使用R0和R1，则此时对应系数矩阵如下：

```
[0 0 0]
[0 ∞ 0]
[0 0 ∞]
```

将其作为关联边矩阵，举XY边（XY冲突）例子：

| **（CXY）**      | **Y 选择 Spill** | **Y 选择 R0** | **Y 选择 R1** |
| ---------------- | ---------------- | ------------- | ------------- |
| **X 选择 Spill** | `C[0][0] = 0`    | `C[0][1] = 0` | `C[0][2] = 0` |
| **X 选择 R0**    | `C[1][0] = 0`    | `C[1][1] = ∞` | `C[1][2] = 0` |
| **X 选择 R1**    | `C[2][0] = 0`    | `C[2][1] = 0` | `C[2][2] = ∞` |



### 10.6.5 PBQP实现原理以及示例分析

Basic和PBQP算法前置依赖都相同，都会计算活跃变量、变量活跃区间、支配树、基本块执行频率等信息

使用PBQP方法求解寄存器分配问题分为4步：

1. **将寄存器分配问题映射为PBQP**

   **构建成本向量**构成：与该变量不冲突的物理寄存器个数+一个溢出成本（第一个元素是溢出成本，后面元素都是物理寄存器按优先级顺序排的）

   LLVM对其做了优化，如果发现冲突，说明永远不可能将物理寄存器分配给该向量，所以构建成本以及相关系数矩阵都**可以移除该物理寄存器相关的信息**

   构建成本**若为负值**，表示发生了寄存器合并，PBQP默认不启用，可设置参数`pbqp-coalescing`来启动

   * 如`$r2 = COPY %38`
   * %38对应r2的成本减去基本块的执行频率（溢出成本）得到负值，说明%38优先选择r2
   * **如果COPY指令的目的和源寄存器都是虚拟寄存器，会将成本计算到系数矩阵中**

   构建成本向量的溢出成本元素值基本上是根据**基本块的执行频率**得到，该值越大说明溢出成本越大；若存在元素为1，大概率是为了区分物理寄存器中的Caller-Saved、Callee-Saved（将Callee-Saved寄存器成本设置为1，从而**保证PBQP优先使用Caller-Saved寄存器类型**）

   

   构建完每个变量的成本向量后

   接下来根据变量的活跃区间为变量构建PBQP图，如果两个变量存在冲突，则为它们构建关联边

   同时需要同步构建关联边的系数矩阵（和成本向量一样长度的行列（已经加了溢出成本的行列了））

   如果两个变量的成本向量分别是5和10，那系数矩阵就是10行5列

   

2. **求解PBQP**

   按照一定顺序，具体为：

   1. **处理图中节点度小于3的可归约节点**

      首先将节点压入栈，然后进行归约计算，更新成本或系数矩阵

      初始阶段若没有任何节点小于3，则不会进行归约

   2. **处理可分配节点（优先进行寄存器分配的变量节点即溢出成本最低的节点）**

      可分配节点是LLVM实现中的一种优化方案

      在处理可分配节点时，首先将节点压入栈，然后将节点相关的边从图中删除，并对关联节点进行状态更新，如果发现节点度小于3，则将其加入可归约节点中，等待处理

   3. **处理溢出节点**

      变量大于最大物理寄存器个数后，后续变量需要进行溢出处理

      将溢出成本从小到大排序后，依次压入栈中（并非全部），并删除关联边，直至所以剩余节点度都小于3，停止压栈，剩下节点当作可归约节点进行处理

   4. **进行反向传播**

      依次访问栈中元素，重构图，并计算、更新节点的成本

      * 栈先进后出，处理栈顶元素（之前剩下的可归约节点先被处理，分配相应物理寄存器）

      * 处理溢出节点时，将删除的关联边都添加上，因为连接关联边的节点都已经完成归约和分配，所以边的系数矩阵都已计算完成，**然后计算节点0的系数矩阵，并且进行构建成本求和**，取最小的元素作为节点0的物理寄存器

      * 依次类推

        举例节点1的成本计算如下：（其与节点0345有关联边，其这四者都已处理了）

        ```
        [11.71968, 1, 1, 1, 1] + M₁₀[Node0.Selection] + M₁₃[Node3.Selection] + M₁₄[Node4.Selection] + M₁₅[Node5.Selection]
        ```

        Node0.Selection表示选择边系数矩阵0选择寄存器对应的那一行（因为此时关联边对应的节点已完成分配，所以可以精准定位到选择的物理寄存器那一行，如节点0 选择了 r9 ，那么给出节点0对应的r9那一行的成本）

        [11.71968, 1, 1, 1, 1]则是节点1的构建成本

        最后计算得到[11.71968, ∞, ∞, ∞, ∞]表示节点1进行溢出处理

3. **将PBQP求解得到的结果映射为寄存器分配的结果**

   在求解PBQP后，所有变量都已得到处理

4. **如果需要执行寄存器溢出，插入store/load指令**

   进行溢出时，和Basic算法一致，都可以先考虑是否进行溢出，如有物化属性等

   如果溢出，会产生新的虚拟寄存器，所以会继续迭代执行上述过程，直到PBQP求解过程不再出现溢出，则迭代终止



