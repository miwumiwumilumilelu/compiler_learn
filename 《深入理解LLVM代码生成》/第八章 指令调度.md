# 第八章 指令调度

一个典型的流水线**取指令——>译码——>执行——>回写**四个阶段

假设每个阶段是一个时钟周期，单CPU从第一周期开始会不断进行取指令，从第二周期开始会不断进行译码，第三周期开始会不断进行执行，第四周期开始会不断进行回写。也就是说每个单元都会从第五周期开始进入满荷负载工作状态，不断地执行一条条指令

但是4个单元刚好能存下一个指令的所有阶段，**所以平均下来一条指令只需一个时钟周期，CPU性能在引入流水线后提升近3倍**

流水线本质是**空间换时间**，不同指令各步并行操作，从而实现CPU各单元的并行处理



但前提是各个指令之间没有依赖。若有依赖关系，则需要等待上一条指令回写

LLVM中常见3种依赖：1. data(数据依赖)，当前操作数是上一条指令输出结果 2. chain(链依赖)，固定访存操作顺序 3. glue(铰链依赖),指令序列在调度时不能被分开



指令调度的**作用就是通过调整指令的顺序，减少指令间依赖对流水线的影响**



* 根据调度发生阶段：
  1. 动态调度：发生在**运行时**，需要相应的硬件支持——处理器会在运行时对指令序列进行重排，**并乱序地发送到处理器功能单元**，以便处理器能够同时处理更多的指令
  2. 静态调度：发生在**编译阶段**——对指令进行重排，消除指令间依赖，提升指令并行度（本书只关注静态调度）
* 根据指令调度的工作范围：
  1. 局部调度：针对单基本块进行调度，适用于所有后端
  2. 全局调度：跨多个基本块进行调度
  3. 循环调度：针对循环体内的基本块进行指令调度优化，这主要是针对软流水的优化，目前仅适用于ARM、PPC、Hexagon后端



## 8.1 LLVM指令调度

指令调度和寄存器分配会相互影响，因此LLVM实现了**基于MIR的寄存器分配前指令调度和寄存器分配后指令调度**，同时还提供了基于DAG IR的调度（即DAG生成和匹配阶段到MIR这个阶段间进行了指令调度）

### 8.1.1 指令调度算法

算法思路：**构建指令间依赖图，基于依赖图进行拓扑排序**



* 指令调度会**调整寄存器的位置、影响寄存器的生命周期**，从而影响寄存器分配：

  ```
  // 原始顺序
  r1 = load [A]
  r2 = add r1, 10  // r1在此使用
  r3 = load [B]
  
  // 调度后顺序
  r1 = load [A]
  r3 = load [B]    // 插入其他指令
  r2 = add r1, 10  // r1的生命周期被延长了
  ```

  改变寄存器值的使用时间点，这里r1需要保持活跃的时间更长，可能影响后续寄存器分配

  - 定义点到使用点的距离拉长
  - 寄存器必须保持活跃的周期数增加
  - 可能产生更多的寄存器压力

  ```
  // 调度前分散使用
  r1 = calc_A
  use r1
  r1 = calc_B  // 可重用
  use r1
  
  // 调度后密集使用
  r1 = calc_A
  use r1
  use r1       // 不能立即重用
  r1 = calc_B
  ```

  这可能导致需要更多物理寄存器

* 寄存器分配**选择物理寄存器会影响指令依赖，**从而影响指令调度：

  * **举例：**

    ```cpp
    // 原始循环
    for (int i = 0; i < N; i++) {
        A[i] = B[i] + C[i];
    }
    
    // 展开后（2次迭代）
    for (int i = 0; i < N; i+=2) {
        A[i]   = B[i]   + C[i];
        A[i+1] = B[i+1] + C[i+1];
    }
    ```

    若每次迭代寄存器分配器都为其分配不同的寄存器——调度器可以自由重排指令，甚至让两次迭代的部分指令并行执行

    ```
    r1 = load B[i]
    r2 = load C[i]
    r3 = add r1, r2    // 迭代 1
    store r3, A[i]
    
    r4 = load B[i+1]
    r5 = load C[i+1]
    r6 = add r4, r5    // 迭代 2
    store r6, A[i+1]
    ```

    若每次迭代，寄存器都进行复用

    ```
    r1 = load B[i]
    r2 = load C[i]
    r1 = add r1, r2    // 复用 r1
    store r1, A[i]
    
    r1 = load B[i+1]   // WAW 依赖！
    r2 = load C[i+1]
    r1 = add r1, r2
    store r1, A[i+1]
    ```

    这里 `r1`的复用导致 WAW 依赖，使得两次迭代必须串行执行，降低了并行度

  

因此在多个阶段需要配置指令调度算法，三个阶段的**调度算法（又叫调度器）**实现略有不同（原因是输入不同），但是实现算法原理相似，代码可复用



**MIR生成后，寄存器分配前的阶段**需要着重考虑到**指令顺序对寄存器分配压力的影响**，且LLVM的循环调度SMS也处于这个阶段

**基于寄存器分配后MIR调度的阶段**，则只需主要考虑**并行性能**



### 8.1.2 拓扑排序算法

**拓扑排序的本质：偏序关系的线性扩展，得到合理的线性序列**

**指令调度以拓扑排序为基础，每条指令按照依赖关系构成了DAG节点**

指令调度在拓扑排序的第3-4步进行增强，**通过多种启发式因素计算出队列中调度优先级最高的节点，然后将该节点作为调度结果**



**拓扑次序的序列：**对有向无环图（DAG, Directed Acyclic Graph）的顶点进行线性排序的算法，使得对于图中的每一条有向边 (*u*,*v*)，顶点 *u*在排序中总是位于顶点 *v*的前面
**拓扑排序：**使得所有的依赖关系符合拓扑次序

```
A → B → C
 \   ↘
  → D → E
```

可能的拓扑排序：

- `[A, B, D, C, E]`
- `[A, D, B, C, E]`
- `[A, B, C, D, E]`

**步骤**：

1. 遍历图中所有节点，计算所有顶点的 **入度**（即有多少边指向该顶点）。
2. 将所有入度为 0 的顶点加入队列。
3. 从队列中取出顶点 *u*，并输出到拓扑序列。
4. 对于 *u*的每个邻接顶点 *v*，减少 *v*的入度-1。如果 *v*的入度变为 0，则加入队列。
5. 重复步骤 3-4，直到队列为空。
6. 如果输出的顶点数等于总顶点数，则成功；否则，图中存在环（无法拓扑排序）。





## 8.2 Linearize 调度器

LLVM中实现最简单的调度器

Linearize调度器是**以基本块为调度单元**，对SelectionDAG的SDNode做一次**自底向上的拓扑排序**，生成SDNode序列

步骤：

1. 构造SDNode依赖图
2. 根据依赖图，**自底向上深度优先遍历**进行拓扑排序，**具有glue属性的节点序列会被当做一个整体进行调度，从而保证具有glue属性的节点序列不会被拆开**
3. 重复以上步骤，直至所有节点调度完成

通过 `-pre-RA-sched = Linearize` 来选择使用Linearize调度器



### 8.2.1 构造依赖图

自上而下依次遍历SelectionDAG的指令，根据指令之间的依赖关系在依赖图中添加相关依赖（如建立数据依赖），**并计算入度**

建立数据依赖时，相应可能会增加相关节点入度

在基本块遍历完成后，**会增加一个虚拟的Graph Root节点，让Graph Root指向基本块的最后一条指令**，标记基本块的退出位置，用来作为自底向上指令调度的起点



### 8.2.2 对依赖图进行调度

从Graph Root节点出发，自底向上按深度优先进行拓扑排序。

举例：p154

因为Graph Root是虚拟节点，不依赖任何节点，所以从Graph Root开始调度。t30依赖Graph Root，故t30是第一个被调度节点，将调度结果存入一个数组（这里使用Sequence表示），同时将t30从依赖图中移除，更新入度，即将t45入度-1（t30依赖t45）

`(t30)`

接下来t45入度为0，但t45和t64具有glue属性，且t64仅被t45依赖，所以二者作为整体进行调度

`(t30 t45 t64)`

接下来是t64的操作数，从右向左遍历，首先处理节点t43，然后处理t27

`(t30 t45 t64 t43 t27)`



LInearize算法直接对SDNode进行调度，得到的结果即为**指令执行顺序**

调度后，易于发现指令与其依赖者或被依赖者距离更近



## 8.3 Fast 调度器

Fast 叫 Linearize 有以下三点不同

1. 用SUnit封装SDNode，并以SUnit为节点来构造指令依赖图（**可以将影响指令调度的启发式因素提取出来进行封装，从而避免在SDNode和MIR中进行重复定义和实现**）
2. 在构建依赖图前，会做一些优化，**为地址相近的内存操作的SDNode序列设置glue属性**，以提升数据局部性
3. 对**物理寄存器依赖场景**做了特殊处理，以减小物理寄存器活跃区间范围

通过 `-pre-RA-sched = fast` 来选择使用Fast调度器，调度实现算法放在Schedule-DAGFast类



`llvm/lib/CodeGen/SelectionDAG/ScheduleDAGFast.cpp`



### 8.3.1 Fast 调度器实现

SUnit有两个字段，分别是**SDNode指针类型**的`Node`和**MachineInstr指针类型**的`Instr`，分别保存对应的SelectionDAG形式的SDNode节点和MIR节点，以达到封装二者的目的

```c
/// Scheduling unit. This is a node in the scheduling DAG.
  class SUnit {
  private:
    enum : unsigned { BoundaryID = ~0u };

    SDNode *Node = nullptr;        ///< Representative node.
    MachineInstr *Instr = nullptr; ///< Alternatively, a MachineInstr.
    
    public:
    ...
    unsigned NumSuccsLeft = 0;         ///< # of succs not scheduled.
    ...
```

**步骤：**

1. SUnit引入`NumSuccsLeft`字段来描述其入度（用于做拓扑排序）。**以SUnit为节点构造依赖图**
   1. 具有glue属性的SDNode节点序列被合并成一个SUnit；
   2. 若SDNode没有glue属性但包含**机器操作数**，则为该SDNode生成一个SUnit。
2. 基于以上依赖图进行调度（从Graph Root出发，自底向上拓扑排序，加入待调度队列AvailableQueue）
3. 重复步骤1-2，直至所有即节点调度完成



Fast调度器和后续介绍的调度器采用AvailableQueue队列，其在Fast调度器中是普通队列，每个SUnit优先级一样；但在后续调度器中，其是优先级队列，会根据启发式因素来决定队列中节点的优先级



### 8.3.2 物理寄存器依赖场景处理

**指令之间存在物理寄存器的依赖关系**

调度器使用两个数组`LiveRegDefs[TRI->getNumRegs()]`和`LiveRegGens[TRI->getNumRegs()]`，分别记录某个物理寄存器相关指令序列的**开始和结束指令的索引**（其中`TRI->getNumRegs()`是目标后端物理寄存器的数量）

```c
class ScheduleDAGFast : public ScheduleDAGSDNodes {
private:
  /// AvailableQueue - The priority queue to use for the available SUnits.
  FastPriorityQueue AvailableQueue;

  /// LiveRegDefs - A set of physical registers and their definition
  /// that are "live". These nodes must be scheduled before any other nodes that
  /// modifies the registers can be scheduled.
  unsigned NumLiveRegs;
  std::vector<SUnit*> LiveRegDefs;
  std::vector<unsigned> LiveRegCycles;
public:
	...
}
```



通过索引判断其长度，针对由于物理寄存器依赖导致的活跃区间太长的情况——两种处理方法**将活跃区间拆开，从而提升寄存器分配的性能**

* CopyAndMoveSuccessors——插入重复指令缩短活跃区间

  * 建立一个新的复制节点，并构建依赖指向原先节点的前驱节点；

  * 调整后续指令的调度，使原变量的活跃区间提前结束；原先指令的后继节点中已经调度过的指向新节点，当前调度的设置为新节点的前驱节点（SDep::Artificial依赖类型，即先调度后继节点即新节点）

  * 举例：

    * ```
      %v1 = load %addr      ; 定义 %v1
      ...                   ; 其他指令（%v1 仍然活跃）
      use %v1               ; 最后一次使用 %v1
      ```

    * ```
      %v1 = load %addr      ; 定义 %v1
      ...                   ; 其他指令
      %v2 = copy %v1        ; 复制 %v1 到 %v2
      use %v2               ; 使用 %v2 替代 %v1
      ```

      `%v1`的活跃区间在 `copy`之后结束，而 `%v2`的活跃区间较短，减少了寄存器压力

* InsertCopieAndMoveSuccs——插入COPY指令缩短活跃区间 p161

  * 会插入两条即一对新的指令CopyFromSU 和 CopyToSU，会带来额外开销



CopyAndMoveSuccessors会复制指令，InsertCopieAndMoveSuccs会插入一对copy指令，前者生成更少指令数，因此优先使用前者来处理物理寄存器依赖；但在如涉及到指令具有glue属性的特殊场景会选择后者



Fast三大辅助数据结构：

* **`AvailableQueue`**——存储当前**可被调度执行**的指令（即所有前置依赖已满足的指令），先进先出

* **`NotReady`（未就绪指令集合）**——**存放因为物理寄存器依赖被干扰暂时无法进行调度的SUnit节点**

  ```c
  /*
  这个循环的目标是从 AvailableQueue（所有数据依赖已满足的指令队列）中，找到一个不会与当前活跃的物理寄存器冲突的指令。如果所有可用指令都存在冲突，这个循环就会将它们全部识别出来，并移入一个临时的 NotReady 列表
  */
  	while (!AvailableQueue.empty()) {
      bool Delayed = false;
      LRegsMap.clear();
      SUnit *CurSU = AvailableQueue.pop(); //取当前候选指令
      while (CurSU) {
        // 检查是否与当前活跃物理寄存器冲突
        SmallVector<unsigned, 4> LRegs;
        if (!DelayForLiveRegsBottomUp(CurSU, LRegs)) 
          break;
        // 标识
        Delayed = true;
        LRegsMap.insert(std::make_pair(CurSU, LRegs));
  
        CurSU->isPending = true;  // This SU is not in AvailableQueue right now.
        // 加入NotReady
        NotReady.push_back(CurSU);
        CurSU = AvailableQueue.pop();
      }
      ...
    }
  ```

  

* **`Sequence`（已调度指令序列）**——按顺序存储**已调度完成的指令**，生成最终的指令序列

  ```c
  void ScheduleDAGFast::ListScheduleBottomUp() {
  	...
  	 // While Available queue is not empty, grab the node with the highest
    // priority. If it is not ready put it back.  Schedule the node.
    SmallVector<SUnit*, 4> NotReady;
    DenseMap<SUnit*, SmallVector<unsigned, 4> > LRegsMap;
    Sequence.reserve(SUnits.size());
    ...
  }
  ```
  
  

NotReady需要等到AvailableQueue元素为0后才会被处理，重新放入AvailabQueue，并进行物理寄存器依赖处理

```c
    // Add the nodes that aren't ready back onto the available list.
    for (unsigned i = 0, e = NotReady.size(); i != e; ++i) {
      NotReady[i]->isPending = false; // 标识改为false，表示正在被考虑
      // May no longer be available due to backtracking.
      if (NotReady[i]->isAvailable)
        AvailableQueue.push(NotReady[i]);
    }
    NotReady.clear();

    if (CurSU)
      ScheduleNodeBottomUp(CurSU, CurCycle);
    ++CurCycle;
```

p162



## 8.4 BURR List 调度器

`llvm/lib/CodeGen/SelectionDAG/ScheduleDAGRRList.cpp`

先构造基于SUnit节点的依赖图；不再单纯基于深度优先拓扑排序来调度指令，而是引入了考虑因素来计算AvailableQueue中元素的优先级，选择优先级最高的指令，而不是先入先出

LLVM通过`-pre-RA-sched=list-burr`来选择使用该调度器



### 8.4.1 影响指令调度的关键因素

**（寄存器活跃区间越小，寄存器分配压力越小）**

1. **SuccsNumLeft（SUnit后继节点数量）**

   在相同条件下，该值越小越应该先调度，调度后可能会**缩小寄存器的活跃区间**

   主动避免创建需要长期维持的活跃值：

   ​	优先调度“扇出”少的指令，是一种避免引入长活跃区间的防御性策略。它倾向于先完成那些依赖关系简单的、可以“速战速决”的计算，推迟那些会引入复杂、长期依赖的计算

2. **PredsNumLeft（SUnit前驱节点数量）**

   在相同条件下，该值越大越应该先调度，调度后可能会**缩小寄存器的活跃区间**

   被动但高效地一次性终结尽可能多的活跃值：

   ​	优先调度“扇入”多的指令，是一种最大化释放寄存器的贪心策略。它倾向于优先处理那些能一次性“收尾”最多计算依赖的指令，从而快速降低寄存器压力

3. **Latency（节点的指令时延）**

   带有机器操作数的SDNode节点，一般默认时延的值为1，有一些特殊的SDNode则不是这样，可能为0

   在相同条件下，该值越大越应该先调度，调度后可以**充分利用流水线的能力**

   我的理解是：高延迟总要执行，会产生停顿即"插入气泡"，这个阶段我们如果很早就调度高延迟的指令，那么可以通过在原本插入气泡的阶段放入其他指令的调度，那么就可以充分利用流水线了，这叫早预防早干预，减少插入气泡

4. **Height（自底向上从ExitEntry到当前SUnit节点的最长路径）**

   计算方法：遍历当前SUnit节点的后继节点，对每个后继节点的height和latency求和，取max

   ```c
   /// closestSucc - Returns the scheduled cycle of the successor which is
   /// 通过递归地跳过连续的 CopyToReg 操作，来更精确地确定一个计算结果的“最终用户”离当前指令有多远
   /// closest to the current cycle.
   static unsigned closestSucc(const SUnit *SU) {
     unsigned MaxHeight = 0;
     for (const SDep &Succ : SU->Succs) {
       if (Succ.isCtrl()) continue;  // ignore chain succs
       unsigned Height = Succ.getSUnit()->getHeight();
       // If there are bunch of CopyToRegs stacked up, they should be considered
       // to be at the same position.
       if (Succ.getSUnit()->getNode() &&
           Succ.getSUnit()->getNode()->getOpcode() == ISD::CopyToReg)
         Height = closestSucc(Succ.getSUnit())+1;
       if (Height > MaxHeight)
         MaxHeight = Height;
     }
     return MaxHeight;
   }
   
   /// 求和取max的相关方法应该在基础文件中
   ```

   在相同条件下，该值越大越应该先调度，调度后可以**充分利用流水线的能力**

   优先处理剩余关键任务最长的指令，避免它被延后

5. **Depth（自顶向下从开始节点到当前SUnit节点的最长路径）**

   计算方法：遍历当前SUnit节点的前驱节点，对每个后继节点的depth和latency求和，取max

   在相同条件下，该值越小越应该先调度，调度后可以**充分利用流水线的能力**

   优先启动依赖链的源头，以尽快解锁后续所有指令

6. **Sethi-Ullman数值（计算这个指令未来所需要的寄存器峰值，越小越先调度）**

   Sethi-Ullman算法可以帮助编译器将AST转为机器指令时，尽可能少地使用寄存器

   即优先处理“寄存器复杂度低的任务"，为了留出更多寄存器给""复杂度高的任务""

   调度器将其数值作为评判寄存器压力的指标

   两种递归计算情况：
   
   1. 前驱节点中Sethi-Ullman只有一个最大值，Sethi-Ullman新 = Sethi-UllmanMax
   2. 前驱节点中Sethi-Ullman有n个相同最大值，Sethi-Ullman新 = n + Sethi-UllmanMax - 1



### 8.4.2 指令优先级计算方法(`BURRSort`函数)

优先级排序工作有`BURRSort`函数实现

算法依次比较两个SUnit节点的HasRegDef、Priority、ClosestSucc等属性

```c
static bool BURRSort(SUnit *left, SUnit *right, RegReductionPQBase *SPQ) {
  // Schedule physical register definitions close to their use. This is
  // motivated by microarchitectures that can fuse cmp+jump macro-ops. But as
  // long as shortening physreg live ranges is generally good, we can defer
  // creating a subtarget hook.
  if (!DisableSchedPhysRegJoin) {
    bool LHasPhysReg = left->hasPhysRegDefs;
    bool RHasPhysReg = right->hasPhysRegDefs;
    if (LHasPhysReg != RHasPhysReg) {
      #ifndef NDEBUG
      static const char *const PhysRegMsg[] = { " has no physreg",
                                                " defines a physreg" };
      #endif
      LLVM_DEBUG(dbgs() << "  SU (" << left->NodeNum << ") "
                        << PhysRegMsg[LHasPhysReg] << " SU(" << right->NodeNum
                        << ") " << PhysRegMsg[RHasPhysReg] << "\n");
      return LHasPhysReg < RHasPhysReg;
    }
  }

  // Prioritize by Sethi-Ulmann number and push CopyToReg nodes down.
  unsigned LPriority = SPQ->getNodePriority(left);
  unsigned RPriority = SPQ->getNodePriority(right);
	...
  // This creates more short live intervals.
  unsigned LDist = closestSucc(left);
  unsigned RDist = closestSucc(right);
  ...
  // How many registers becomes live when the node is scheduled.
  unsigned LScratch = calcMaxScratches(left);
  unsigned RScratch = calcMaxScratches(right);
  ...
  if ((left->isCall && RPriority > 0) || (right->isCall && LPriority > 0))
    return (left->NodeQueueId > right->NodeQueueId);
  ...
}	
```

* `HasRegDef`——`bool`该SUnit节点是否定义了物理寄存器，会优先选择true的节点，以减少该寄存器活跃区间
* `Priority`——也就是节点的`Sethi-Ullman`数值，**越小越先调度**
* `ClosestSucc`——基于SuccsNumLeft（SUnit后继节点数量）计算得到
* `MaxScratches`——基于PredsNumLeft（SUnit前驱节点数量）计算得倒
* `Height Depth Latency`——之前提到的三个因素，处理路径长度的节点，提高指令的并行能力（提高流水线性能）
* `NodeQueueID`——表示存入AvailableQueue的ID序号，越早入AvailableQueue的节点ID越小



最后得到的Sequence需要倒序反转过来，因为是以基本块为调度单元，自底向上遍历



## 8.5 Source List 调度器 8.6 Hybrid List 调度器

二者均和BURR List调度器共用ScheduleDAGRRList类，仅在计算AvailableQueue中可调度的SUnit节点的优先级有差异

* **Source List**调度器优先级**会优先比较与SUnit节点对应的LLVM IR的顺序**，优先调度在源码中比较靠前的指令

  如果无法比较出优先级，后续使用BURR List的BURRSort来选择

  使用`-pre-RA-sched=source`来使用该调度器

* **Hybrid List**调度器会优先比较**SUnit是否会造成较高的寄存器压力**，自底向上地优先选择没有造成高寄存器压力的指令

  如果无法比较出优先级，**则继续比较指令时延**，自底向上地优先选择时延较小的指令

  如果仍无法比较出优先级，后续使用BURR List的BURRSort来选择

  使用`-pre-RA-sched=list-hybrid`来使用该调度器



8.7 Pre-RA-MISched 调度器

之前都是基于SelectDAG进行指令调度，这个调度器及之后介绍的则是基于MIR指令进行调度

Pre-RA-MISched调度器支持自顶向下、自底向上以及双向拓扑三种调度顺序

使用`-enable-misched`来使用该调度器，由`Schedule-DAGMILive`类实现

```c
/// llvm/include/llvm/CodeGen/MachineScheduler.h
/// ScheduleDAGMILive is an implementation of ScheduleDAGInstrs that schedules
/// machine instructions while updating LiveIntervals and tracking regpressure.
class ScheduleDAGMILive : public ScheduleDAGMI {
protected:
	...
}
```



### 8.7.1 Pre-RA-MISched 调度器实现

Pre RA——在寄存器分配前进行调度，MIR指令中会有虚拟寄存器和物理寄存器

​	因此会优先考虑调度后带来的寄存器压力，要尽量减少

​	此外还会考虑指令并行的能力（会考虑到Latency）



拓扑排序时，会对入度为0的节点通过**Use-Def依赖边的时延**计算**最快执行需要等待的指令周期**

如果这个时延超过了一定的阈值，就说明该指令的Stall Cycles比较大，会存入pending队列；相反小于阈值，存入AvailableQueue

（这里的“阈值”指的是**已调度指令执行所需的时延，会随着指令调度的结果而增长**）

（每当调度器决定发射一条或多条指令，或者当流水线因为没有可执行指令而停顿时，这个时钟周期就会向前推进）



### 8.7.2 调度区域

以**调度区域**为调度单元，通常一个基本块可划分为一个或多个调度区域

**调度区域的划分：**按照顺序遍历基本块的指令，遇到边界指令则生成一个新的调度区域

**原因：**一些指令会给程序**执行时延、寄存器压力**等带来不确定性，所以要将这些指令识别出来，作为调度边界，从而形成调度区域

调度区域的边界涉及3类指令：

1. 基本块的边界指令，如ret、branch、jmp等
2. 函数调用指令，如call（**因为指令调度不能跨函数调用**）
3. 修改堆栈指针的指令



### 8.7.3 影响Pre-RA-MISched调度器的关键因素

* **物理寄存器**

  根据指令是否包含物理寄存器来设置优先级，目的是获得更小的物理寄存器活跃区间

* **时延**

  一般使用SUnit节点的Depth和Height属性表示

  SUnit中的SDNode指令时延多数默认为1

  SUnit中的MIR指令时延则**需要根据TD文件的描述计算得到**（8.7.4会讲）

* **寄存器压力**

  SUnit会有Pressure Diff属性——以描述**当前指令被调度时**产生的**寄存器压力变化**（8.7.5会讲基于Pressure Diff的寄存器压力计算）

* **停滞周期**

  指令访存所占用的时钟周期——反映了CPU因为执行某些指令需要等待的时钟周期



### 8.7.4 MIR指令时延的计算

1. **基于SUnit节点的时延计算**

   用于SDNode或MIR生成SUnit节点时，**反映了指令执行消耗的时钟周期**

   LLVM实现了两种SUnit节点的时延计算方法：

   1. **基于指令行程模型的计算方法**

      指令行程模型信息由TD文件描述

      ```
      InstrItinData<II_CSRrr , 		[InstrStage<1,		[ISSUE],		0>,
      														 InstrStage<1,		[ALU],			2>,
      														 InstrStage<1,		[CSR]>,			0],		[4,		4]
      ```

      CSRrr指令有三个执行单元(stage)，[]中的

      它们的执行周期分别时1，1，1

      其中`InstrStage<1, [ALU], 2>`的2表示`[ALU]`到`[CSR]`功能单元需要经过2个额外的时钟周期（ISSUE和ALU之间TD定义时延则为0，因此不需要额外时钟周期）

      即

      ```
      时钟周期1						时钟周期2					时钟周期3
      ISSUE
      ALU		
      																		CSR
      ```

      因此CSRrr指令的时延为3

   2. **基于指令调度模型的计算方法**

      指令调度模型信息也由TD文件描述

      TD中会有`def : ... { let latency = xxx; }`的描述，只需**遍历当前指令所有执行单元的时延`xxx`，并取max作为指令的时延即可**

2. **基于Use-Def依赖边的时延计算**

   用于构建SUnit节点的依赖关系时，会计算有Use-Def依赖边的调度时延，**反映了数据从Def节点流向Use节点所需的时钟周期**

   LLVM实现了两种Use-Def依赖边的时延计算方法：

   1. **基于指令行程模型的计算方法**

      分别获取Def寄存器的DefCycle属性和Use寄存器的UseCycle属性，然后计算**DefCycle-UseCycle+1**得到依赖边时延

      ```
      ADD r3,	r3,	r2
      MUL r4,	r3,	r2
      ```

      以寄存器r3为例，Def和Use分别对应ADD和MUL指令

      ADD和MUL都是TD中的ALUrr定义的指令

      ```
      InstrItinData<II_ALUrr,		[InstrStage<1,		[ISSUE]>,
      													 InstrStage<1,		[ALU]>],	[2,	2, 2]>,
      ```

      数组`[2, 2, 2]`描述了各寄存器索引对应的时钟周期：

      ADD中r3对应数组索引为0的元素：DefCycles = 2

      MUL中r3对应数组索引为1的元素：UseCycles = 2

      因此Use-Def依赖边时延 = 2 - 2 + 1 = 1

   2. **基于指令调度模型的计算方法**

       **依赖边时延 = Def指令的WriteRes的时延 — Use指令的ReadAdvance的时延**

      ReadAdvance可以理解为Use指令何时需要Def指令的输出



### 8.7.5 寄存器压力的计算

由`RegPressureTrack类`实现

在**SUnit节点依赖图构造**和**指令调度**两个阶段进行计算

* **构建依赖图并计算相关属性**

  自底向上顺序计算指令被调度时造成的**寄存器压力变化**、**寄存器压力**以及**调度到当前指令造成的最大寄存器压力**

  (PressureDiff、CurrentSetPressure、MaxSetPressure)

  

  `clang++ -mllvm -entable-misched --target=riscv32-unknown-elf -o main.o -c xx.cpp -O2`

  可在Pre-RA-MISched调度前生成与以上代码对应的MIR指令（以RISCV32为编译后端）

  该后端有11种寄存器类型，因此PressureDiff、CurrentSetPressure、MaxSetPressure是3个长度为11的数组，初始所有元素为0

  自底向上调度指令时，

  ​	如果是Def寄存器，表明该寄存器活跃区间从当前指令结束，寄存器压力减少；

  ​	如果是Use寄存器，表明该寄存器的活跃区间从当前指令开始，寄存器压力增加

  （一般，32位寄存器压力增加值（weight表示）为1，64位为2，以此类推）

  

  **举例：**

  ```c++
  void test(int a, int *x, int *y) {
      int b = a * x[0] + y[0];
      int c = b + x[1];
      int d = c * y[1];
      y[2] = b + c + d;
  }
  ```

  ```
  bb.0.entry
    liveins: $x10, $x11, $x12
    SU[0]    %2:gpr = COPY $x12
    SU[1]    %1:gpr = COPY $x11
    SU[2]    %0:gpr = COPY $x10
    SU[3]    %3:gpr = LW %1:gpr, 0
    SU[4]    %4:gpr = MULW %3:gpr, %0:gpr
    SU[5]    %5:gpr = LW %2:gpr, 0
    SU[6]    %6:gpr = ADDW %4:gpr, %5:gpr
    SU[7]    %7:gpr = LW %1:gpr, 4
    SU[8]    %8:gpr = ADDW %6:gpr, %7:gpr
    SU[9]    %9:gpr = LW %2:gpr, 4
    SU[10]   %10:gpr = MULW %8:gpr, %9:gpr
    SU[11]   %11:gpr = ADDW %8:gpr, %6:gpr
    SU[12]   %12:gpr = ADDW %11:gpr, %10:gpr
    SU[13]   SW %12:gpr, %2:gpr, 8
            PseudoRET
  ```

  

  第一条指令：`SU[13]   SW %12:gpr, %2:gpr, 8`

  * 该指令没有Def寄存器，有两个Use虚拟寄存器，它们的寄存器压力变化值Weight都为1，只影响该后端定义的11种类型寄存器中的GPR类型

  * 因此目前

    所有寄存器压力影响值之和: 	`PDiff[GPR] = 1 + 1 = 2 `

    每个寄存器当前压力值: 	`CurrentSetPreesure[GPR] = CurrentSetPreesure[GPR] + PDiff[GPR] = 0 + 2 = 2`

    最大寄存器压力：	`MaxSetPdiffPressure[GPR] = max(MaxSetPdiffPressure[GPR], CurrentSetPreesure[GPR]) = 2`

  第二条指令：`SU[12]   %12:gpr = ADDW %11:gpr, %10:gpr`

  * %12在此处Def，其Weight = -1；新增两个Use寄存器（%11 和 %10），其Weight = 1

  * 因此目前

    `PDiff[GPR] = 1 + 1 - 1 = 1`

    `CurrentSetPreesure[GPR] = 2 + 1 = 3`

    `MaxSetPdiffPressure[GPR] = 3`

  ...同理

  !!!

  `  SU[10]   %10:gpr = MULW %8:gpr, %9:gpr
    SU[11]   %11:gpr = ADDW %8:gpr, %6:gpr`

  %8 在两条指令中都具有相同的Def`SU[8]    %8:gpr = ADDW %6:gpr, %7:gpr`，SU[10]中的%8作为Use寄存器时对`CurrentSetPreesure`和`MaxSetPdiffPressure`的影响已经包含在上一条指令中了（也就是此指令中的%8不产生新的寄存器活跃区间），而`PDiff`只受当前指令影响，因此`PDiff`正常进行计算

  !!!

  ...同理

  

  **还需要处理LiveIn和LiveOut寄存器集合对压力值的影响**

  自底向上时，LiveOut寄存器会作为Use寄存器而计算初始化的压力值；自顶向下时，LiveIn则作为Use寄存器而计算初始化的压力值

  该示例中LiveOut为空，就不再具体叙述

  

  **TD文件还会给出一类寄存器压力的参考阈值(Limit)**

  当调度完后，MaxSet超出了当前参考阈值，会把它记录到长度为11 的`RegionCriticalPSet`数组（记录寄存器压力超出阈值的过载量）,其在后续调度中会用到

  

* **指令调度**

  自底向上调度依赖图中节点，如果AvailableQueue中出现多个可调度的节点，寄存器压力将作为计算优先级的重要因素

  节点调度时，仍然要计算`CurrentSetPreesure`和`MaxSetPdiffPressure`的变化

  LLVM通过以下3种指标来描述MIR指令被调度后对寄存器压力的影响：

  1. **RegPressureDelta.Excess**——描述指令调度后，CurrentSet是否超出参考阈值
  2. **RegPressureDelta.CriticalMax**——描述指令调度后，MaxSet是否超出RegionCriticalPSet相关索引对应的值
  3. **RegPressureDelta.CurrentMax**——描述指令调度后，是否超出了默认顺序遍历过程中出现的最大的寄存器压力值
  
  **具体Pre-RA-MISched算法按照BasPhysReg、RegPressure、停滞周期、指令时延依次比较出优先级**
  
  调度过程中CurCycle会记录当前的阈值（AvailableQueue中元素被调度后的数量？？？）[因此其是动态增大的]
  
  Pending 则会存储时延超过了这个阈值的可调度节点
  
  每次更新阈值后，都会先判断Pending中元素的调度时延是否超过了阈值，如果小于等于，则放回AvailableQueue
  
  当AvailableQueue中的值优先级一样时，则按自底向上的调度顺序依次放入result	
  
  



