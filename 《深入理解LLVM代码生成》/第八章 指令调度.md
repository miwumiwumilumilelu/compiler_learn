# 第八章 指令调度

一个典型的流水线**取指令——>译码——>执行——>回写**四个阶段

假设每个阶段是一个时钟周期，单CPU从第一周期开始会不断进行取指令，从第二周期开始会不断进行译码，第三周期开始会不断进行执行，第四周期开始会不断进行回写。也就是说每个单元都会从第五周期开始进入满荷负载工作状态，不断地执行一条条指令

但是4个单元刚好能存下一个指令的所有阶段，**所以平均下来一条指令只需一个时钟周期，CPU性能在引入流水线后提升近3倍**

流水线本质是**空间换时间**，不同指令各步并行操作，从而实现CPU各单元的并行处理



但前提是各个指令之间没有依赖。若有依赖关系，则需要等待上一条指令回写

LLVM中常见3种依赖：1. data(数据依赖)，当前操作数是上一条指令输出结果 2. chain(链依赖)，固定访存操作顺序 3. glue(铰链依赖),指令序列在调度时不能被分开



指令调度的**作用就是通过调整指令的顺序，减少指令间依赖对流水线的影响**



* 根据调度发生阶段：
  1. 动态调度：发生在**运行时**，需要相应的硬件支持——处理器会在运行时对指令序列进行重排，**并乱序地发送到处理器功能单元**，以便处理器能够同时处理更多的指令
  2. 静态调度：发生在**编译阶段**——对指令进行重排，消除指令间依赖，提升指令并行度（本书只关注静态调度）
* 根据指令调度的工作范围：
  1. 局部调度：针对单基本块进行调度，适用于所有后端
  2. 全局调度：跨多个基本块进行调度
  3. 循环调度：针对循环体内的基本块进行指令调度优化，这主要是针对软流水的优化，目前仅适用于ARM、PPC、Hexagon后端



## 8.1 LLVM指令调度

指令调度和寄存器分配会相互影响，因此LLVM实现了**基于MIR的寄存器分配前指令调度和寄存器分配后指令调度**，同时还提供了基于DAG IR的调度（即DAG生成和匹配阶段到MIR这个阶段间进行了指令调度）

### 8.1.1 指令调度算法

算法思路：**构建指令间依赖图，基于依赖图进行拓扑排序**



* 指令调度会**调整寄存器的位置、影响寄存器的生命周期**，从而影响寄存器分配：

  ```
  // 原始顺序
  r1 = load [A]
  r2 = add r1, 10  // r1在此使用
  r3 = load [B]
  
  // 调度后顺序
  r1 = load [A]
  r3 = load [B]    // 插入其他指令
  r2 = add r1, 10  // r1的生命周期被延长了
  ```

  改变寄存器值的使用时间点，这里r1需要保持活跃的时间更长，可能影响后续寄存器分配

  - 定义点到使用点的距离拉长
  - 寄存器必须保持活跃的周期数增加
  - 可能产生更多的寄存器压力

  ```
  // 调度前分散使用
  r1 = calc_A
  use r1
  r1 = calc_B  // 可重用
  use r1
  
  // 调度后密集使用
  r1 = calc_A
  use r1
  use r1       // 不能立即重用
  r1 = calc_B
  ```

  这可能导致需要更多物理寄存器

* 寄存器分配**选择物理寄存器会影响指令依赖，**从而影响指令调度：

  * **举例：**

    ```cpp
    // 原始循环
    for (int i = 0; i < N; i++) {
        A[i] = B[i] + C[i];
    }
    
    // 展开后（2次迭代）
    for (int i = 0; i < N; i+=2) {
        A[i]   = B[i]   + C[i];
        A[i+1] = B[i+1] + C[i+1];
    }
    ```

    若每次迭代寄存器分配器都为其分配不同的寄存器——调度器可以自由重排指令，甚至让两次迭代的部分指令并行执行

    ```
    r1 = load B[i]
    r2 = load C[i]
    r3 = add r1, r2    // 迭代 1
    store r3, A[i]
    
    r4 = load B[i+1]
    r5 = load C[i+1]
    r6 = add r4, r5    // 迭代 2
    store r6, A[i+1]
    ```

    若每次迭代，寄存器都进行复用

    ```
    r1 = load B[i]
    r2 = load C[i]
    r1 = add r1, r2    // 复用 r1
    store r1, A[i]
    
    r1 = load B[i+1]   // WAW 依赖！
    r2 = load C[i+1]
    r1 = add r1, r2
    store r1, A[i+1]
    ```

    这里 `r1`的复用导致 WAW 依赖，使得两次迭代必须串行执行，降低了并行度

  

因此在多个阶段需要配置指令调度算法，三个阶段的**调度算法（又叫调度器）**实现略有不同（原因是输入不同），但是实现算法原理相似，代码可复用



**MIR生成后，寄存器分配前的阶段**需要着重考虑到**指令顺序对寄存器分配压力的影响**，且LLVM的循环调度SMS也处于这个阶段

**基于寄存器分配后MIR调度的阶段**，则只需主要考虑**并行性能**



### 8.1.2 拓扑排序算法

**拓扑排序的本质：偏序关系的线性扩展，得到合理的线性序列**

**指令调度以拓扑排序为基础，每条指令按照依赖关系构成了DAG节点**

指令调度在拓扑排序的第3-4步进行增强，**通过多种启发式因素计算出队列中调度优先级最高的节点，然后将该节点作为调度结果**



**拓扑次序的序列：**对有向无环图（DAG, Directed Acyclic Graph）的顶点进行线性排序的算法，使得对于图中的每一条有向边 (*u*,*v*)，顶点 *u*在排序中总是位于顶点 *v*的前面
**拓扑排序：**使得所有的依赖关系符合拓扑次序

```
A → B → C
 \   ↘
  → D → E
```

可能的拓扑排序：

- `[A, B, D, C, E]`
- `[A, D, B, C, E]`
- `[A, B, C, D, E]`

**步骤**：

1. 遍历图中所有节点，计算所有顶点的 **入度**（即有多少边指向该顶点）。
2. 将所有入度为 0 的顶点加入队列。
3. 从队列中取出顶点 *u*，并输出到拓扑序列。
4. 对于 *u*的每个邻接顶点 *v*，减少 *v*的入度-1。如果 *v*的入度变为 0，则加入队列。
5. 重复步骤 3-4，直到队列为空。
6. 如果输出的顶点数等于总顶点数，则成功；否则，图中存在环（无法拓扑排序）。





## 8.2 Linearize 调度器

LLVM中实现最简单的调度器

Linearize调度器是**以基本块为调度单元**，对SelectionDAG的SDNode做一次**自底向上的拓扑排序**，生成SDNode序列

步骤：

1. 构造SDNode依赖图
2. 根据依赖图，**自底向上深度优先遍历**进行拓扑排序，**具有glue属性的节点序列会被当做一个整体进行调度，从而保证具有glue属性的节点序列不会被拆开**
3. 重复以上步骤，直至所有节点调度完成

通过 `-pre-RA-sched = Linearize` 来选择使用Linearize调度器



### 8.2.1 构造依赖图

自上而下依次遍历SelectionDAG的指令，根据指令之间的依赖关系在依赖图中添加相关依赖（如建立数据依赖），**并计算入度**

建立数据依赖时，相应可能会增加相关节点入度

在基本块遍历完成后，**会增加一个虚拟的Graph Root节点，让Graph Root指向基本块的最后一条指令**，标记基本块的退出位置，用来作为自底向上指令调度的起点



### 8.2.2 对依赖图进行调度

从Graph Root节点出发，自底向上按深度优先进行拓扑排序。

举例：p154

因为Graph Root是虚拟节点，不依赖任何节点，所以从Graph Root开始调度。t30依赖Graph Root，故t30是第一个被调度节点，将调度结果存入一个数组（这里使用Sequence表示），同时将t30从依赖图中移除，更新入度，即将t45入度-1（t30依赖t45）

`(t30)`

接下来t45入度为0，但t45和t64具有glue属性，且t64仅被t45依赖，所以二者作为整体进行调度

`(t30 t45 t64)`

接下来是t64的操作数，从右向左遍历，首先处理节点t43，然后处理t27

`(t30 t45 t64 t43 t27)`



LInearize算法直接对SDNode进行调度，得到的结果即为**指令执行顺序**

调度后，易于发现指令与其依赖者或被依赖者距离更近



## 8.3 Fast 调度器

Fast 叫 Linearize 有以下三点不同

1. 用SUnit封装SDNode，并以SUnit为节点来构造指令依赖图（**可以将影响指令调度的启发式因素提取出来进行封装，从而避免在SDNode和MIR中进行重复定义和实现**）
2. 在构建依赖图前，会做一些优化，**为地址相近的内存操作的SDNode序列设置glue属性**，以提升数据局部性
3. 对**物理寄存器依赖场景**做了特殊处理，以减小物理寄存器活跃区间范围

通过 `-pre-RA-sched = fast` 来选择使用Fast调度器，调度实现算法放在Schedule-DAGFast类

​	核心实现文件：`llvm/lib/CodeGen/ScheduleDAG.cpp`

​	相关头文件：`llvm/include/llvm/CodeGen/ScheduleDAG.h`

没找到？！



### 8.3.1 Fast 调度器实现

SUnit有两个字段，分别是**SDNode指针类型**的`Node`和**MachineInstr指针类型**的`Instr`，分别保存对应的SelectionDAG形式的SDNode节点和MIR节点，以达到封装二者的目的

```c
/// Scheduling unit. This is a node in the scheduling DAG.
  class SUnit {
  private:
    enum : unsigned { BoundaryID = ~0u };

    SDNode *Node = nullptr;        ///< Representative node.
    MachineInstr *Instr = nullptr; ///< Alternatively, a MachineInstr.
    
    public:
    ...
    unsigned NumSuccsLeft = 0;         ///< # of succs not scheduled.
    ...
```

**步骤：**

1. SUnit引入`NumSuccsLeft`字段来描述其入度（用于做拓扑排序）。**以SUnit为节点构造依赖图**
   1. 具有glue属性的SDNode节点序列被合并成一个SUnit；
   2. 若SDNode没有glue属性但包含**机器操作数**，则为该SDNode生成一个SUnit。
2. 基于以上依赖图进行调度（从Graph Root出发，自底向上拓扑排序，加入待调度队列AvailableQueue）
3. 重复步骤1-2，直至所有即节点调度完成



Fast调度器和后续介绍的调度器采用AvailableQueue队列，其在Fast调度器中是普通队列，每个SUnit优先级一样；但在后续调度器中，其是优先级队列，会根据启发式因素来决定队列中节点的优先级



### 8.3.2 物理寄存器依赖场景处理

**指令之间存在物理寄存器的依赖关系**

调度器使用两个数组`LiveRegDefs[TRI->getNumRegs()]`和`LiveRegGens[TRI->getNumRegs()]`，分别记录某个物理寄存器相关指令序列的**开始和结束指令的索引**（其中`TRI->getNumRegs()`是目标后端物理寄存器的数量）



通过索引判断其长度，针对由于物理寄存器依赖导致的活跃区间太长的情况——两种处理方法**将活跃区间拆开，从而提升寄存器分配的性能**

* CopyAndMoveSuccessors——插入重复指令缩短活跃区间

  * 建立一个新的复制节点，并构建依赖指向原先节点的前驱节点；

  * 调整后续指令的调度，使原变量的活跃区间提前结束；原先指令的后继节点中已经调度过的指向新节点，当前调度的设置为新节点的前驱节点（SDep::Artificial依赖类型，即先调度后继节点即新节点）

  * 举例：

    * ```
      %v1 = load %addr      ; 定义 %v1
      ...                   ; 其他指令（%v1 仍然活跃）
      use %v1               ; 最后一次使用 %v1
      ```

    * ```
      %v1 = load %addr      ; 定义 %v1
      ...                   ; 其他指令
      %v2 = copy %v1        ; 复制 %v1 到 %v2
      use %v2               ; 使用 %v2 替代 %v1
      ```

      `%v1`的活跃区间在 `copy`之后结束，而 `%v2`的活跃区间较短，减少了寄存器压力

* InsertCopieAndMoveSuccs——插入COPY指令缩短活跃区间 p161

  * 会插入两条即一对新的指令CopyFromSU 和 CopyToSU，会带来额外开销



CopyAndMoveSuccessors会复制指令，InsertCopieAndMoveSuccs会插入一对copy指令，前者生成更少指令数，因此优先使用前者来处理物理寄存器依赖；但在如涉及到指令具有glue属性的特殊场景会选择后者



Fast三大辅助数据结构：

* **`AvailableQueue`**——存储当前**可被调度执行**的指令（即所有前置依赖已满足的指令），先进先出

* **`NotReady`（未就绪指令集合）**——**存放因为物理寄存器依赖被干扰暂时无法进行调度的SUnit节点**

* **`Sequence`（已调度指令序列）**——按顺序存储**已调度完成的指令**，生成最终的指令序列

  

NotReady需要等到AvailableQueue元素为0后才会被处理，重新放入AvailabQueue，并进行物理寄存器依赖处理

p162





