# 第八章 指令调度

一个典型的流水线**取指令——>译码——>执行——>回写**四个阶段

假设每个阶段是一个时钟周期，单CPU从第一周期开始会不断进行取指令，从第二周期开始会不断进行译码，第三周期开始会不断进行执行，第四周期开始会不断进行回写。也就是说每个单元都会从第五周期开始进入满荷负载工作状态，不断地执行一条条指令

但是4个单元刚好能存下一个指令的所有阶段，**所以平均下来一条指令只需一个时钟周期，CPU性能在引入流水线后提升近3倍**

流水线本质是**空间换时间**，不同指令各步并行操作，从而实现CPU各单元的并行处理



但前提是各个指令之间没有依赖。若有依赖关系，则需要等待上一条指令回写

LLVM中常见3种依赖：1. data(数据依赖)，当前操作数是上一条指令输出结果 2. chain(链依赖)，固定访存操作顺序 3. glue(铰链依赖),指令序列在调度时不能被分开



指令调度的**作用就是通过调整指令的顺序，减少指令间依赖对流水线的影响**



* 根据调度发生阶段：
  1. 动态调度：发生在**运行时**，需要相应的硬件支持——处理器会在运行时对指令序列进行重排，**并乱序地发送到处理器功能单元**，以便处理器能够同时处理更多的指令
  2. 静态调度：发生在**编译阶段**——对指令进行重排，消除指令间依赖，提升指令并行度（本书只关注静态调度）
* 根据指令调度的工作范围：
  1. 局部调度：针对单基本块进行调度，适用于所有后端
  2. 全局调度：跨多个基本块进行调度
  3. 循环调度：针对循环体内的基本块进行指令调度优化，这主要是针对软流水的优化，目前仅适用于ARM、PPC、Hexagon后端



## 8.1 LLVM指令调度

指令调度和寄存器分配会相互影响，因此LLVM实现了**基于MIR的寄存器分配前指令调度和寄存器分配后指令调度**，同时还提供了基于DAG IR的调度（即DAG生成和匹配阶段到MIR这个阶段间进行了指令调度）

### 8.1.1 指令调度算法

算法思路：**构建指令间依赖图，基于依赖图进行拓扑排序**



* 指令调度会**调整寄存器的位置、影响寄存器的生命周期**，从而影响寄存器分配：

  ```
  // 原始顺序
  r1 = load [A]
  r2 = add r1, 10  // r1在此使用
  r3 = load [B]
  
  // 调度后顺序
  r1 = load [A]
  r3 = load [B]    // 插入其他指令
  r2 = add r1, 10  // r1的生命周期被延长了
  ```

  改变寄存器值的使用时间点，这里r1需要保持活跃的时间更长，可能影响后续寄存器分配

  - 定义点到使用点的距离拉长
  - 寄存器必须保持活跃的周期数增加
  - 可能产生更多的寄存器压力

  ```
  // 调度前分散使用
  r1 = calc_A
  use r1
  r1 = calc_B  // 可重用
  use r1
  
  // 调度后密集使用
  r1 = calc_A
  use r1
  use r1       // 不能立即重用
  r1 = calc_B
  ```

  这可能导致需要更多物理寄存器

* 寄存器分配**选择物理寄存器会影响指令依赖，**从而影响指令调度：

  * **举例：**

    ```cpp
    // 原始循环
    for (int i = 0; i < N; i++) {
        A[i] = B[i] + C[i];
    }
    
    // 展开后（2次迭代）
    for (int i = 0; i < N; i+=2) {
        A[i]   = B[i]   + C[i];
        A[i+1] = B[i+1] + C[i+1];
    }
    ```

    若每次迭代寄存器分配器都为其分配不同的寄存器——调度器可以自由重排指令，甚至让两次迭代的部分指令并行执行

    ```
    r1 = load B[i]
    r2 = load C[i]
    r3 = add r1, r2    // 迭代 1
    store r3, A[i]
    
    r4 = load B[i+1]
    r5 = load C[i+1]
    r6 = add r4, r5    // 迭代 2
    store r6, A[i+1]
    ```

    若每次迭代，寄存器都进行复用

    ```
    r1 = load B[i]
    r2 = load C[i]
    r1 = add r1, r2    // 复用 r1
    store r1, A[i]
    
    r1 = load B[i+1]   // WAW 依赖！
    r2 = load C[i+1]
    r1 = add r1, r2
    store r1, A[i+1]
    ```

    这里 `r1`的复用导致 WAW 依赖，使得两次迭代必须串行执行，降低了并行度

  

因此在多个阶段需要配置指令调度算法，三个阶段的**调度算法（又叫调度器）**实现略有不同（原因是输入不同），但是实现算法原理相似，代码可复用



**MIR生成后，寄存器分配前的阶段**需要着重考虑到**指令顺序对寄存器分配压力的影响**，且LLVM的循环调度SMS也处于这个阶段

**基于寄存器分配后MIR调度的阶段**，则只需主要考虑**并行性能**



### 8.1.2 拓扑排序算法

**拓扑排序的本质：偏序关系的线性扩展，得到合理的线性序列**

**指令调度以拓扑排序为基础，每条指令按照依赖关系构成了DAG节点**

指令调度在拓扑排序的第3-4步进行增强，**通过多种启发式因素计算出队列中调度优先级最高的节点，然后将该节点作为调度结果**



**拓扑次序的序列：**对有向无环图（DAG, Directed Acyclic Graph）的顶点进行线性排序的算法，使得对于图中的每一条有向边 (*u*,*v*)，顶点 *u*在排序中总是位于顶点 *v*的前面
**拓扑排序：**使得所有的依赖关系符合拓扑次序

```
A → B → C
 \   ↘
  → D → E
```

可能的拓扑排序：

- `[A, B, D, C, E]`
- `[A, D, B, C, E]`
- `[A, B, C, D, E]`

**步骤**：

1. 遍历图中所有节点，计算所有顶点的 **入度**（即有多少边指向该顶点）。
2. 将所有入度为 0 的顶点加入队列。
3. 从队列中取出顶点 *u*，并输出到拓扑序列。
4. 对于 *u*的每个邻接顶点 *v*，减少 *v*的入度-1。如果 *v*的入度变为 0，则加入队列。
5. 重复步骤 3-4，直到队列为空。
6. 如果输出的顶点数等于总顶点数，则成功；否则，图中存在环（无法拓扑排序）。





## 8.2 Linearize 调度器

LLVM中实现最简单的调度器

Linearize调度器是**以基本块为调度单元**，对SelectionDAG的SDNode做一次**自底向上的拓扑排序**，生成SDNode序列

步骤：

1. 构造SDNode依赖图
2. 根据依赖图，**自底向上深度优先遍历**进行拓扑排序，**具有glue属性的节点序列会被当做一个整体进行调度，从而保证具有glue属性的节点序列不会被拆开**
3. 重复以上步骤，直至所有节点调度完成

通过 `-pre-RA-sched = Linearize` 来选择使用Linearize调度器



### 8.2.1 构造依赖图

自上而下依次遍历SelectionDAG的指令，根据指令之间的依赖关系在依赖图中添加相关依赖（如建立数据依赖），**并计算入度**

建立数据依赖时，相应可能会增加相关节点入度

在基本块遍历完成后，**会增加一个虚拟的Graph Root节点，让Graph Root指向基本块的最后一条指令**，标记基本块的退出位置，用来作为自底向上指令调度的起点



### 8.2.2 对依赖图进行调度

从Graph Root节点出发，自底向上按深度优先进行拓扑排序。

举例：p154

因为Graph Root是虚拟节点，不依赖任何节点，所以从Graph Root开始调度。t30依赖Graph Root，故t30是第一个被调度节点，将调度结果存入一个数组（这里使用Sequence表示），同时将t30从依赖图中移除，更新入度，即将t45入度-1（t30依赖t45）

`(t30)`

接下来t45入度为0，但t45和t64具有glue属性，且t64仅被t45依赖，所以二者作为整体进行调度

`(t30 t45 t64)`

接下来是t64的操作数，从右向左遍历，首先处理节点t43，然后处理t27

`(t30 t45 t64 t43 t27)`



LInearize算法直接对SDNode进行调度，得到的结果即为**指令执行顺序**

调度后，易于发现指令与其依赖者或被依赖者距离更近
